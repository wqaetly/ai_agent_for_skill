"""
ç»†ç²’åº¦ç´¢å¼•å™¨ - æ„å»ºè¡Œçº§/è·¯å¾„çº§ç´¢å¼?æ‰©å±•ç°æœ‰skill_indexerï¼Œæ”¯æŒActionçº§åˆ«çš„ç²¾ç¡®å®šä½?"""

import json
import hashlib
from typing import Dict, List, Any, Optional
from pathlib import Path
from datetime import datetime
import re


class FineGrainedIndexer:
    """ç»†ç²’åº¦ç´¢å¼•å™¨ - è®°å½•æ¯ä¸ªActionçš„è·¯å¾„ã€è¡Œå·å’Œå‚æ•°"""

    def __init__(self, skills_dir: str = "../../ai_agent_for_skill/Assets/Skills"):
        """
        Args:
            skills_dir: æŠ€èƒ½æ–‡ä»¶ç›®å½?        """
        self.skills_dir = Path(skills_dir)
        self.index_file = Path("../Data/fine_grained_index.json")
        self.index_data = self._load_index()

    def index_all_skills(self, force_rebuild: bool = False) -> Dict[str, Any]:
        """
        ä¸ºæ‰€æœ‰æŠ€èƒ½æ„å»ºç»†ç²’åº¦ç´¢å¼•

        Args:
            force_rebuild: å¼ºåˆ¶é‡å»ºæ‰€æœ‰ç´¢å¼?
        Returns:
            ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
        """
        if not self.skills_dir.exists():
            raise FileNotFoundError(f"æŠ€èƒ½ç›®å½•ä¸å­˜åœ¨: {self.skills_dir}")

        stats = {
            "total_files": 0,
            "indexed_files": 0,
            "total_actions": 0,
            "skipped_files": 0,
            "errors": []
        }

        skill_files = list(self.skills_dir.glob("*.json"))
        stats["total_files"] = len(skill_files)

        for skill_file in skill_files:
            try:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–?                if not force_rebuild and self._is_file_indexed(skill_file):
                    stats["skipped_files"] += 1
                    continue

                # æ„å»ºç»†ç²’åº¦ç´¢å¼?                file_index = self._index_single_file(skill_file)

                if file_index:
                    self.index_data["files"][str(skill_file)] = file_index
                    stats["indexed_files"] += 1
                    stats["total_actions"] += file_index["total_actions"]

            except Exception as e:
                stats["errors"].append({
                    "file": str(skill_file),
                    "error": str(e)
                })

        # æ›´æ–°å…¨å±€å…ƒæ•°æ?        self.index_data["metadata"]["last_updated"] = datetime.now().isoformat()
        self.index_data["metadata"]["total_files"] = stats["indexed_files"]
        self.index_data["metadata"]["total_actions"] = stats["total_actions"]

        # ä¿å­˜ç´¢å¼•
        self._save_index()

        return stats

    def _index_single_file(self, file_path: Path) -> Dict[str, Any]:
        """
        ä¸ºå•ä¸ªæŠ€èƒ½æ–‡ä»¶æ„å»ºç»†ç²’åº¦ç´¢å¼•

        Returns:
            {
                "file_hash": "md5...",
                "skill_name": "...",
                "total_actions": 12,
                "tracks": [
                    {
                        "track_name": "Damage Track",
                        "track_index": 2,
                        "track_path": "tracks.$rcontent[2]",
                        "actions": [
                            {
                                "action_type": "DamageAction",
                                "action_index": 0,
                                "json_path": "tracks.$rcontent[2].actions.$rcontent[0]",
                                "line_number": 145,
                                "frame": 10,
                                "duration": 20,
                                "parameters": {...},
                                "summary": "..."
                            }
                        ]
                    }
                ]
            }
        """
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        file_hash = hashlib.md5(content.encode('utf-8')).hexdigest()

        # ä¿®å¤Unity JSONæ ¼å¼
        content_fixed = self._fix_unity_json(content)

        # è§£æJSON
        data = json.loads(content_fixed)

        # æå–åŸºç¡€ä¿¡æ¯
        skill_name = data.get("skillName", "Unknown")

        # ç´¢å¼•æ‰€æœ‰è½¨é“å’ŒAction
        tracks_index = []
        total_actions = 0

        tracks_data = data.get("tracks", {})
        if isinstance(tracks_data, dict) and "$rcontent" in tracks_data:
            tracks_list = tracks_data["$rcontent"]

            for track_idx, track in enumerate(tracks_list):
                track_name = track.get("trackName", f"Track {track_idx}")
                track_path = f"tracks.$rcontent[{track_idx}]"

                actions_index = []

                # ç´¢å¼•è½¨é“ä¸­çš„Action
                actions_data = track.get("actions", {})
                if isinstance(actions_data, dict) and "$rcontent" in actions_data:
                    actions_list = actions_data["$rcontent"]

                    for action_idx, action in enumerate(actions_list):
                        action_info = self._index_action(
                            action,
                            track_idx,
                            action_idx,
                            track_name,
                            content
                        )

                        if action_info:
                            actions_index.append(action_info)
                            total_actions += 1

                if actions_index:
                    tracks_index.append({
                        "track_name": track_name,
                        "track_index": track_idx,
                        "track_path": track_path,
                        "actions": actions_index
                    })

        return {
            "file_hash": file_hash,
            "skill_name": skill_name,
            "total_actions": total_actions,
            "last_modified": datetime.fromtimestamp(file_path.stat().st_mtime).isoformat(),
            "tracks": tracks_index
        }

    def _index_action(
        self,
        action_data: Dict[str, Any],
        track_idx: int,
        action_idx: int,
        track_name: str,
        file_content: str
    ) -> Optional[Dict[str, Any]]:
        """ç´¢å¼•å•ä¸ªAction"""
        # æå–Actionç±»å‹
        action_type = self._extract_action_type(action_data.get("$type", ""))
        if not action_type:
            return None

        # æ„å»ºJSONè·¯å¾„
        json_path = f"tracks.$rcontent[{track_idx}].actions.$rcontent[{action_idx}]"

        # ä¼°ç®—è¡Œå·ï¼ˆé€šè¿‡æœç´¢JSONç‰‡æ®µï¼?        line_number = self._estimate_line_number(action_data, file_content)

        # æå–å‚æ•°ï¼ˆæ’é™¤å…ƒæ•°æ®å­—æ®µï¼?        parameters = {
            k: v for k, v in action_data.items()
            if not k.startswith("$") and k not in ["frame", "duration"]
        }

        # ç”Ÿæˆæ‘˜è¦
        summary = self._generate_action_summary(
            action_type,
            action_data,
            track_name
        )

        return {
            "action_type": action_type,
            "action_index": action_idx,
            "json_path": json_path,
            "line_number": line_number,
            "frame": action_data.get("frame", 0),
            "duration": action_data.get("duration", 0),
            "parameters": parameters,
            "summary": summary
        }

    def _extract_action_type(self, type_str: str) -> Optional[str]:
        """
        ä»Odinç±»å‹å­—ç¬¦ä¸²æå–Actionç±»å‹åç§°

        Args:
            type_str: "4|SkillSystem.Actions.DamageAction, Assembly-CSharp"

        Returns:
            "DamageAction"
        """
        if "|" in type_str:
            type_name = type_str.split("|")[1].split(",")[0]
            return type_name.split(".")[-1]
        return None

    def _estimate_line_number(
        self,
        action_data: Dict[str, Any],
        file_content: str
    ) -> int:
        """
        ä¼°ç®—Actionåœ¨æ–‡ä»¶ä¸­çš„è¡Œå?
        é€šè¿‡æœç´¢Actionçš„ç‰¹å¾å­—æ®µï¼ˆå¦?idæˆ–ç‰¹æ®Šå‚æ•°å€¼ï¼‰æ¥å®šä½?        """
        # ä½¿ç”¨$idä½œä¸ºé”šç‚¹
        action_id = action_data.get("$id")
        if action_id is not None:
            pattern = f'"\\$id":\\s*{action_id}'
            match = re.search(pattern, file_content)
            if match:
                # è®¡ç®—åŒ¹é…ä½ç½®ä¹‹å‰çš„è¡Œæ•?                line_number = file_content[:match.start()].count('\n') + 1
                return line_number

        # å›é€€ï¼šä½¿ç”¨frameå€¼ä½œä¸ºé”šç‚?        frame = action_data.get("frame")
        if frame is not None:
            pattern = f'"frame":\\s*{frame}'
            # æœç´¢æ‰€æœ‰åŒ¹é…ï¼Œå–ç¬¬ä¸€ä¸ªï¼ˆç®€åŒ–å¤„ç†ï¼‰
            match = re.search(pattern, file_content)
            if match:
                line_number = file_content[:match.start()].count('\n') + 1
                return line_number

        return -1  # æ— æ³•ç¡®å®š

    def _generate_action_summary(
        self,
        action_type: str,
        action_data: Dict[str, Any],
        track_name: str
    ) -> str:
        """ç”ŸæˆActionçš„å¯è¯»æ‘˜è¦?""
        parts = [f"[{track_name}]"]

        frame = action_data.get("frame", 0)
        duration = action_data.get("duration", 0)
        parts.append(f"ç¬¬{frame}å¸?)

        if duration > 0:
            parts.append(f"æŒç»­{duration}å¸?)

        # æ ¹æ®ç±»å‹æå–å…³é”®å‚æ•°
        if action_type == "DamageAction":
            damage = action_data.get("baseDamage", action_data.get("damage", "?"))
            damage_type = action_data.get("damageType", "")
            parts.append(f"é€ æˆ{damage}ç‚¹{damage_type}ä¼¤å®³")

            radius = action_data.get("damageRadius", 0)
            if radius > 0:
                parts.append(f"èŒƒå›´{radius}ç±?)

        elif action_type == "MovementAction":
            speed = action_data.get("moveSpeed", action_data.get("speed", "?"))
            parts.append(f"ç§»åŠ¨é€Ÿåº¦{speed}")

            distance = action_data.get("moveDistance", 0)
            if distance > 0:
                parts.append(f"ç§»åŠ¨{distance}ç±?)

        elif action_type == "AnimationAction":
            clip = action_data.get("animationClipName", "")
            if clip:
                parts.append(f"æ’­æ”¾: {clip}")

        elif action_type == "HealAction":
            heal = action_data.get("healAmount", "?")
            parts.append(f"æ²»ç–—{heal}ç‚¹ç”Ÿå‘?)

        elif action_type == "ShieldAction":
            shield = action_data.get("shieldAmount", "?")
            parts.append(f"æŠ¤ç›¾{shield}ç‚?)

        elif action_type == "ControlAction":
            control_type = action_data.get("controlType", "")
            control_duration = action_data.get("controlDuration", 0)
            parts.append(f"{control_type} {control_duration}ç§?)

        return " - ".join(parts)

    def _is_file_indexed(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç´¢å¼•ä¸”æœªä¿®æ”¹"""
        file_key = str(file_path)

        if file_key not in self.index_data["files"]:
            return False

        # æ£€æŸ¥æ–‡ä»¶å“ˆå¸?        with open(file_path, 'r', encoding='utf-8') as f:
            current_hash = hashlib.md5(f.read().encode('utf-8')).hexdigest()

        indexed_hash = self.index_data["files"][file_key].get("file_hash")

        return current_hash == indexed_hash

    def _load_index(self) -> Dict[str, Any]:
        """åŠ è½½ç´¢å¼•æ–‡ä»¶"""
        if self.index_file.exists():
            with open(self.index_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return {
                "metadata": {
                    "version": "1.0",
                    "created": datetime.now().isoformat(),
                    "last_updated": None,
                    "total_files": 0,
                    "total_actions": 0
                },
                "files": {}
            }

    def _save_index(self):
        """ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»?""
        self.index_file.parent.mkdir(parents=True, exist_ok=True)

        with open(self.index_file, 'w', encoding='utf-8') as f:
            json.dump(self.index_data, f, ensure_ascii=False, indent=2)

    def get_index(self) -> Dict[str, Any]:
        """è·å–å®Œæ•´ç´¢å¼•æ•°æ®"""
        return self.index_data

    def get_file_index(self, file_path: str) -> Optional[Dict[str, Any]]:
        """è·å–æŒ‡å®šæ–‡ä»¶çš„ç´¢å¼?""
        return self.index_data["files"].get(file_path)

    def _fix_unity_json(self, json_str: str) -> str:
        """
        ä¿®å¤Unityç”Ÿæˆçš„éæ ‡å‡†JSONæ ¼å¼
        ä¸»è¦å¤„ç†Vector3ã€Colorç­‰ç±»å‹çš„ç®€å†™æ ¼å¼?        """
        # å¤„ç† Color (4ä¸ªå€? r, g, b, a)
        pattern_color = r'("\$type":\s*"[^"]*UnityEngine\.Color([^"]*)")\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)'

        def replace_color(match):
            type_str = match.group(1)
            r = match.group(3)
            g = match.group(4)
            b = match.group(5)
            a = match.group(6)
            return f'{type_str}, "r": {r}, "g": {g}, "b": {b}, "a": {a}'

        json_str = re.sub(pattern_color, replace_color, json_str)

        # å¤„ç† Vector3 (3ä¸ªå€? x, y, z)
        pattern_vector3 = r'("\$type":\s*"[^"]*UnityEngine\.Vector3([^"]*)")\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)'

        def replace_vector3(match):
            type_str = match.group(1)
            x = match.group(3)
            y = match.group(4)
            z = match.group(5)
            return f'{type_str}, "x": {x}, "y": {y}, "z": {z}'

        json_str = re.sub(pattern_vector3, replace_vector3, json_str)

        # å¤„ç† Vector2 (2ä¸ªå€? x, y)
        pattern_vector2 = r'("\$type":\s*"[^"]*UnityEngine\.Vector2([^"]*)")\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)'

        def replace_vector2(match):
            type_str = match.group(1)
            x = match.group(3)
            y = match.group(4)
            return f'{type_str}, "x": {x}, "y": {y}'

        json_str = re.sub(pattern_vector2, replace_vector2, json_str)

        return json_str


# ==================== ä¾¿æ·å‡½æ•° ====================

def build_fine_grained_index(skills_dir: str = None, force_rebuild: bool = False) -> Dict[str, Any]:
    """
    æ„å»ºç»†ç²’åº¦ç´¢å¼•ï¼ˆä¾¿æ·å‡½æ•°ï¼?
    Args:
        skills_dir: æŠ€èƒ½ç›®å½•ï¼ˆå¯é€‰ï¼‰
        force_rebuild: å¼ºåˆ¶é‡å»º

    Returns:
        ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
    """
    if skills_dir:
        indexer = FineGrainedIndexer(skills_dir)
    else:
        indexer = FineGrainedIndexer()

    return indexer.index_all_skills(force_rebuild=force_rebuild)
