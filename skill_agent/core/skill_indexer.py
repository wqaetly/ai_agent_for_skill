"""
æŠ€èƒ½ç´¢å¼•æ¨¡å?
è´Ÿè´£è¯»å–æŠ€èƒ½JSONæ–‡ä»¶ï¼Œæå–ä¿¡æ¯å¹¶å»ºç«‹ç´¢å¼•
"""

import os
import json
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path
from datetime import datetime
import hashlib

logger = logging.getLogger(__name__)


class SkillIndexer:
    """æŠ€èƒ½ç´¢å¼•å™¨ï¼Œå¤„ç†æŠ€èƒ½æ•°æ®çš„è¯»å–å’Œç´¢å¼?""

    def __init__(self, config: dict):
        """
        åˆå§‹åŒ–æŠ€èƒ½ç´¢å¼•å™¨

        Args:
            config: ç´¢å¼•é…ç½®å­—å…¸
        """
        self.config = config
        self.skills_directory = config.get("skills_directory", "../../ai_agent_for_skill/Assets/Skills")
        self.index_cache_path = config.get("index_cache", "../Data/skill_index.json")
        self.index_fields = config.get("index_fields", ["skillName", "skillDescription", "skillId", "actions"])
        self.index_action_details = config.get("index_action_details", True)

        # ç¡®ä¿æŠ€èƒ½ç›®å½•å­˜åœ?
        if not os.path.exists(self.skills_directory):
            logger.warning(f"Skills directory not found: {self.skills_directory}")

        # åŠ è½½ç¼“å­˜ç´¢å¼•
        self.cached_index = self._load_index_cache()

    def _load_index_cache(self) -> Dict[str, Any]:
        """åŠ è½½ç¼“å­˜çš„ç´¢å¼•ä¿¡æ?""
        if os.path.exists(self.index_cache_path):
            try:
                with open(self.index_cache_path, 'r', encoding='utf-8') as f:
                    cache = json.load(f)
                logger.info(f"Loaded index cache with {len(cache.get('skills', {}))} skills")
                return cache
            except Exception as e:
                logger.error(f"Error loading index cache: {e}")

        return {"skills": {}, "last_updated": None}

    def _save_index_cache(self, index: Dict[str, Any]):
        """ä¿å­˜ç´¢å¼•ç¼“å­˜"""
        try:
            cache_dir = os.path.dirname(self.index_cache_path)
            if cache_dir and not os.path.exists(cache_dir):
                os.makedirs(cache_dir, exist_ok=True)

            with open(self.index_cache_path, 'w', encoding='utf-8') as f:
                json.dump(index, f, ensure_ascii=False, indent=2)
            logger.info(f"Saved index cache to {self.index_cache_path}")
        except Exception as e:
            logger.error(f"Error saving index cache: {e}")

    def _compute_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶å†…å®¹çš„å“ˆå¸Œå€?""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            logger.error(f"Error computing hash for {file_path}: {e}")
            return ""

    def _parse_odin_json(self, json_data: dict) -> Dict[str, Any]:
        """
        è§£æOdinåºåˆ—åŒ–çš„JSONæ•°æ®

        Args:
            json_data: åŸå§‹JSONæ•°æ®

        Returns:
            è§£æåçš„æŠ€èƒ½æ•°æ?
        """
        skill_data = {}

        # æå–åŸºæœ¬å­—æ®µ
        skill_data['skillName'] = json_data.get('skillName', '')
        skill_data['skillDescription'] = json_data.get('skillDescription', '')
        skill_data['skillId'] = json_data.get('skillId', '')
        skill_data['totalDuration'] = json_data.get('totalDuration', 0)
        skill_data['frameRate'] = json_data.get('frameRate', 30)

        # è§£ætrackså’Œactions
        skill_data['tracks'] = []
        tracks_data = json_data.get('tracks', {})

        if isinstance(tracks_data, dict) and '$rcontent' in tracks_data:
            # Odinåºåˆ—åŒ–æ ¼å¼?
            tracks_content = tracks_data.get('$rcontent', [])

            for track in tracks_content:
                if isinstance(track, dict):
                    track_info = {
                        'trackName': track.get('trackName', ''),
                        'enabled': track.get('enabled', True),
                        'actions': []
                    }

                    # è§£æactions
                    actions_data = track.get('actions', {})
                    if isinstance(actions_data, dict) and '$rcontent' in actions_data:
                        actions_content = actions_data.get('$rcontent', [])

                        for action in actions_content:
                            if isinstance(action, dict):
                                action_info = self._parse_action(action)
                                track_info['actions'].append(action_info)

                    skill_data['tracks'].append(track_info)

        return skill_data

    def _parse_action(self, action_data: dict) -> Dict[str, Any]:
        """
        è§£æå•ä¸ªActionæ•°æ®

        Args:
            action_data: Actionçš„JSONæ•°æ®

        Returns:
            è§£æåçš„Actionä¿¡æ¯
        """
        action_info = {
            'type': self._extract_action_type(action_data.get('$type', '')),
            'frame': action_data.get('frame', 0),
            'duration': action_data.get('duration', 0),
            'enabled': action_data.get('enabled', True)
        }

        # å¦‚æœéœ€è¦ç´¢å¼•è¯¦ç»†å‚æ•?
        if self.index_action_details:
            # æå–å…³é”®å‚æ•°ï¼ˆæ’é™¤å†…éƒ¨å­—æ®µï¼‰
            params = {}
            for key, value in action_data.items():
                if not key.startswith('$') and key not in ['frame', 'duration', 'enabled']:
                    # ç®€åŒ–å¤æ‚å¯¹è±?
                    if isinstance(value, (str, int, float, bool)):
                        params[key] = value
                    elif isinstance(value, dict):
                        # æå–ç±»å‹ä¿¡æ¯
                        if '$type' in value:
                            params[key] = self._extract_type_name(value['$type'])
                        else:
                            params[key] = str(value)
                    elif isinstance(value, list):
                        params[key] = f"List[{len(value)}]"

            action_info['parameters'] = params

        return action_info

    def _extract_action_type(self, type_string: str) -> str:
        """ä»Odinç±»å‹å­—ç¬¦ä¸²ä¸­æå–Actionç±»å‹å?""
        # æ ¼å¼: "2|SkillSystem.Actions.DamageAction, Assembly-CSharp"
        if '|' in type_string:
            type_string = type_string.split('|')[1]
        if ',' in type_string:
            type_string = type_string.split(',')[0]
        if '.' in type_string:
            type_string = type_string.split('.')[-1]
        return type_string

    def _extract_type_name(self, type_string: str) -> str:
        """æå–ç±»å‹åç§°"""
        return self._extract_action_type(type_string)

    def scan_skills(self) -> List[str]:
        """
        æ‰«ææŠ€èƒ½ç›®å½•ï¼Œè¿”å›æ‰€æœ‰æŠ€èƒ½JSONæ–‡ä»¶è·¯å¾„

        Returns:
            æŠ€èƒ½æ–‡ä»¶è·¯å¾„åˆ—è¡?
        """
        skill_files = []

        if not os.path.exists(self.skills_directory):
            logger.warning(f"Skills directory not found: {self.skills_directory}")
            return skill_files

        try:
            for file_name in os.listdir(self.skills_directory):
                if file_name.endswith('.json'):
                    file_path = os.path.join(self.skills_directory, file_name)
                    skill_files.append(file_path)

            logger.info(f"Found {len(skill_files)} skill files")
        except Exception as e:
            logger.error(f"Error scanning skills directory: {e}")

        return skill_files

    def _fix_unity_json(self, json_str: str) -> str:
        """
        ä¿®å¤Unityç”Ÿæˆçš„éæ ‡å‡†JSONæ ¼å¼
        ä¸»è¦å¤„ç†Vector3ã€Colorç­‰ç±»å‹çš„ç®€å†™æ ¼å¼?
        """
        import re

        # å¤„ç† Color (4ä¸ªå€? r, g, b, a)
        pattern_color = r'("\$type":\s*"[^"]*UnityEngine\.Color([^"]*)")\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)'

        def replace_color(match):
            type_str = match.group(1)
            r = match.group(3)
            g = match.group(4)
            b = match.group(5)
            a = match.group(6)
            return f'{type_str}, "r": {r}, "g": {g}, "b": {b}, "a": {a}'

        json_str = re.sub(pattern_color, replace_color, json_str)

        # å¤„ç† Vector3 (3ä¸ªå€? x, y, z)
        pattern_vector3 = r'("\$type":\s*"[^"]*UnityEngine\.Vector3([^"]*)")\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)'

        def replace_vector3(match):
            type_str = match.group(1)
            x = match.group(3)
            y = match.group(4)
            z = match.group(5)
            return f'{type_str}, "x": {x}, "y": {y}, "z": {z}'

        json_str = re.sub(pattern_vector3, replace_vector3, json_str)

        # å¤„ç† Vector2 (2ä¸ªå€? x, y)
        pattern_vector2 = r'("\$type":\s*"[^"]*UnityEngine\.Vector2([^"]*)")\s*,\s*(-?\d+(?:\.\d+)?)\s*,\s*(-?\d+(?:\.\d+)?)'

        def replace_vector2(match):
            type_str = match.group(1)
            x = match.group(3)
            y = match.group(4)
            return f'{type_str}, "x": {x}, "y": {y}'

        json_str = re.sub(pattern_vector2, replace_vector2, json_str)

        return json_str

    def parse_skill_file(self, file_path: str) -> Optional[Dict[str, Any]]:
        """
        è§£æå•ä¸ªæŠ€èƒ½æ–‡ä»?

        Args:
            file_path: æŠ€èƒ½æ–‡ä»¶è·¯å¾?

        Returns:
            è§£æåçš„æŠ€èƒ½æ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                json_str = f.read()

            # ä¿®å¤Unityçš„éæ ‡å‡†JSONæ ¼å¼
            json_str = self._fix_unity_json(json_str)

            # è§£æJSON
            json_data = json.loads(json_str)

            skill_data = self._parse_odin_json(json_data)

            # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
            skill_data['file_path'] = file_path
            skill_data['file_name'] = os.path.basename(file_path)
            skill_data['file_hash'] = self._compute_file_hash(file_path)
            skill_data['last_modified'] = datetime.fromtimestamp(
                os.path.getmtime(file_path)
            ).isoformat()

            return skill_data

        except Exception as e:
            logger.error(f"Error parsing skill file {file_path}: {e}")
            return None

    def build_search_text(self, skill_data: Dict[str, Any]) -> str:
        """
        æ„å»ºç”¨äºå‘é‡æ£€ç´¢çš„æœç´¢æ–‡æœ¬

        Args:
            skill_data: æŠ€èƒ½æ•°æ?

        Returns:
            æœç´¢æ–‡æœ¬
        """
        text_parts = []

        # æŠ€èƒ½åç§?
        if skill_data.get('skillName'):
            text_parts.append(f"æŠ€èƒ½åç§°ï¼š{skill_data['skillName']}")

        # æŠ€èƒ½æè¿?
        if skill_data.get('skillDescription'):
            text_parts.append(f"æŠ€èƒ½æè¿°ï¼š{skill_data['skillDescription']}")

        # æŠ€èƒ½ID
        if skill_data.get('skillId'):
            text_parts.append(f"æŠ€èƒ½IDï¼š{skill_data['skillId']}")

        # Actionä¿¡æ¯
        if skill_data.get('tracks'):
            action_types = []
            action_summaries = []

            for track in skill_data['tracks']:
                if not track.get('enabled', True):
                    continue

                for action in track.get('actions', []):
                    action_type = action.get('type', '')
                    if action_type:
                        action_types.append(action_type)

                        # æ·»åŠ å…³é”®å‚æ•°ä¿¡æ¯
                        if self.index_action_details and 'parameters' in action:
                            params = action['parameters']
                            # æ„å»ºç®€çŸ­æè¿?
                            param_strs = [f"{k}={v}" for k, v in list(params.items())[:3]]
                            action_summaries.append(f"{action_type}({', '.join(param_strs)})")

            if action_types:
                text_parts.append(f"åŒ…å«åŠ¨ä½œï¼š{', '.join(set(action_types))}")

            if action_summaries:
                text_parts.append(f"åŠ¨ä½œè¯¦æƒ…ï¼š{'; '.join(action_summaries[:5])}")

        return "\n".join(text_parts)

    def index_all_skills(self, force_rebuild: bool = False) -> List[Dict[str, Any]]:
        """
        ç´¢å¼•æ‰€æœ‰æŠ€èƒ?

        Args:
            force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»ºç´¢å¼•ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰

        Returns:
            æŠ€èƒ½æ•°æ®åˆ—è¡?
        """
        skill_files = self.scan_skills()
        indexed_skills = []

        for file_path in skill_files:
            # æ£€æŸ¥ç¼“å­?
            file_hash = self._compute_file_hash(file_path)
            cached_skill = self.cached_index.get('skills', {}).get(file_path)

            if not force_rebuild and cached_skill:
                if cached_skill.get('file_hash') == file_hash:
                    logger.debug(f"Using cached data for {file_path}")
                    indexed_skills.append(cached_skill)
                    continue

            # è§£ææŠ€èƒ½æ–‡ä»?
            skill_data = self.parse_skill_file(file_path)
            if skill_data:
                # æ„å»ºæœç´¢æ–‡æœ¬
                skill_data['search_text'] = self.build_search_text(skill_data)
                indexed_skills.append(skill_data)

        # æ›´æ–°ç¼“å­˜
        new_cache = {
            'skills': {skill['file_path']: skill for skill in indexed_skills},
            'last_updated': datetime.now().isoformat()
        }
        self._save_index_cache(new_cache)
        self.cached_index = new_cache

        logger.info(f"Indexed {len(indexed_skills)} skills")
        return indexed_skills

    def check_for_changes(self) -> List[str]:
        """
        æ£€æŸ¥æŠ€èƒ½æ–‡ä»¶æ˜¯å¦æœ‰å˜åŒ–

        Returns:
            å˜åŒ–çš„æ–‡ä»¶è·¯å¾„åˆ—è¡?
        """
        changed_files = []
        skill_files = self.scan_skills()

        for file_path in skill_files:
            current_hash = self._compute_file_hash(file_path)
            cached_skill = self.cached_index.get('skills', {}).get(file_path)

            if not cached_skill or cached_skill.get('file_hash') != current_hash:
                changed_files.append(file_path)

        return changed_files


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)

    config = {
        "skills_directory": "../../ai_agent_for_skill/Assets/Skills",
        "index_cache": "../Data/skill_index.json",
        "index_fields": ["skillName", "skillDescription", "skillId", "actions"],
        "index_action_details": True
    }

    indexer = SkillIndexer(config)

    # ç´¢å¼•æ‰€æœ‰æŠ€èƒ?
    skills = indexer.index_all_skills(force_rebuild=True)

    # æ‰“å°ç»“æœ
    for skill in skills[:2]:  # åªæ‰“å°å‰2ä¸?
        print(f"\n{'='*60}")
        print(f"Skill: {skill.get('skillName', 'N/A')}")
        print(f"ID: {skill.get('skillId', 'N/A')}")
        print(f"Description: {skill.get('skillDescription', 'N/A')}")
        print(f"Tracks: {len(skill.get('tracks', []))}")
        print(f"Search Text:\n{skill.get('search_text', 'N/A')[:200]}...")
