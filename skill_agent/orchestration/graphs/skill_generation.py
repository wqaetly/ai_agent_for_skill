"""
æŠ€èƒ½ç”Ÿæˆå›¾ï¼ˆå¾ªç¯ä¼˜åŒ–é“¾ï¼‰
å®ç°ï¼šæ£€ç´¢ â†’ ç”Ÿæˆ â†’ éªŒè¯ â†’ ä¿®å¤ â†’ é‡è¯• çš„å®Œæ•´å¾ªç¯
"""

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver
import os
import logging
from ..nodes.skill_nodes import (
    SkillGenerationState,
    retriever_node,
    generator_node,
    validator_node,
    fixer_node,
    finalize_node,
    should_continue,
)

logger = logging.getLogger(__name__)


def build_skill_generation_graph():
    """
    æ„å»ºæŠ€èƒ½ç”Ÿæˆ LangGraph

    æµç¨‹ï¼š
    1. retrieve: æ£€ç´¢ç›¸ä¼¼æŠ€èƒ½
    2. generate: ç”Ÿæˆ JSON
    3. validate: éªŒè¯ JSON
    4. åˆ¤æ–­ï¼š
       - å¦‚æœé€šè¿‡ â†’ finalizeï¼ˆç»“æŸï¼‰
       - å¦‚æœå¤±è´¥ä¸”æœªè¾¾é‡è¯•ä¸Šé™ â†’ fixï¼ˆä¿®å¤ï¼‰â†’ generateï¼ˆé‡æ–°ç”Ÿæˆï¼‰
       - å¦‚æœå¤±è´¥ä¸”è¾¾åˆ°ä¸Šé™ â†’ finalizeï¼ˆå¼ºåˆ¶ç»“æŸï¼‰

    Returns:
        ç¼–è¯‘åçš„ LangGraph
    """
    # åˆ›å»º StateGraph
    workflow = StateGraph(SkillGenerationState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("retrieve", retriever_node)
    workflow.add_node("generate", generator_node)
    workflow.add_node("validate", validator_node)
    workflow.add_node("fix", fixer_node)
    workflow.add_node("finalize", finalize_node)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("retrieve")

    # æ·»åŠ è¾¹
    workflow.add_edge("retrieve", "generate")  # æ£€ç´¢ â†’ ç”Ÿæˆ
    workflow.add_edge("generate", "validate")  # ç”Ÿæˆ â†’ éªŒè¯

    # æ¡ä»¶åˆ†æ”¯ï¼šéªŒè¯åçš„è·¯ç”±
    workflow.add_conditional_edges(
        "validate",
        should_continue,
        {
            "fix": "fix",          # éªŒè¯å¤±è´¥ â†’ ä¿®å¤
            "finalize": "finalize" # éªŒè¯é€šè¿‡ â†’ ç»“æŸ
        }
    )

    # ä¿®å¤åé‡æ–°ç”Ÿæˆ
    workflow.add_edge("fix", "generate")

    # æœ€ç»ˆåŒ–åç»“æŸ
    workflow.add_edge("finalize", END)

    # ğŸ”¥ P0æ”¹è¿›ï¼šæ·»åŠ æŒä¹…åŒ–æ”¯æŒ
    # åˆ›å»ºcheckpointsç›®å½•
    checkpoint_dir = os.path.join(os.path.dirname(__file__), "..", "..", "Data", "checkpoints")
    os.makedirs(checkpoint_dir, exist_ok=True)

    checkpoint_db = os.path.join(checkpoint_dir, "skill_generation.db")
    logger.info(f"ğŸ’¾ ä½¿ç”¨checkpointæ•°æ®åº“: {checkpoint_db}")

    # åˆå§‹åŒ–SqliteSaver
    checkpointer = SqliteSaver.from_conn_string(checkpoint_db)

    # ğŸ”¥ ç¼–è¯‘å›¾ï¼ˆæ·»åŠ checkpointerå’Œrecursion_limitï¼‰
    return workflow.compile(
        checkpointer=checkpointer,
        interrupt_before=[],  # å¯ä»¥åœ¨ç‰¹å®šèŠ‚ç‚¹å‰æš‚åœï¼Œæ”¯æŒhuman-in-the-loop
        interrupt_after=[],   # å¯ä»¥åœ¨ç‰¹å®šèŠ‚ç‚¹åæš‚åœ
        debug=False           # ç”Ÿäº§ç¯å¢ƒè®¾ä¸ºFalse
    )


# å…¨å±€å›¾å®ä¾‹ï¼ˆå•ä¾‹ï¼‰
_skill_generation_graph = None


def get_skill_generation_graph():
    """è·å–æŠ€èƒ½ç”Ÿæˆå›¾çš„å•ä¾‹å®ä¾‹"""
    global _skill_generation_graph

    if _skill_generation_graph is None:
        _skill_generation_graph = build_skill_generation_graph()

    return _skill_generation_graph


# ==================== ä¾¿æ·è°ƒç”¨æ¥å£ ====================

async def generate_skill(requirement: str, max_retries: int = 3) -> dict:
    """
    ç”ŸæˆæŠ€èƒ½é…ç½®ï¼ˆå¼‚æ­¥ï¼‰

    Args:
        requirement: éœ€æ±‚æè¿°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

    Returns:
        åŒ…å« final_resultã€messagesã€retry_count çš„å­—å…¸
    """
    graph = get_skill_generation_graph()

    initial_state = {
        "requirement": requirement,
        "similar_skills": [],
        "generated_json": "",
        "validation_errors": [],
        "retry_count": 0,
        "max_retries": max_retries,
        "final_result": {},
        "messages": [],
    }

    # ğŸ”¥ P0æ”¹è¿›ï¼šæ·»åŠ thread_idå’Œrecursion_limité…ç½®
    config = {
        "configurable": {"thread_id": f"skill_gen_{hash(requirement) % 10000}"},
        "recursion_limit": 50  # é˜²æ­¢æ— é™å¾ªç¯
    }

    result = await graph.ainvoke(initial_state, config)
    return result


def generate_skill_sync(requirement: str, max_retries: int = 3) -> dict:
    """
    ç”ŸæˆæŠ€èƒ½é…ç½®ï¼ˆåŒæ­¥ï¼‰

    Args:
        requirement: éœ€æ±‚æè¿°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

    Returns:
        åŒ…å« final_resultã€messagesã€retry_count çš„å­—å…¸
    """
    graph = get_skill_generation_graph()

    initial_state = {
        "requirement": requirement,
        "similar_skills": [],
        "generated_json": "",
        "validation_errors": [],
        "retry_count": 0,
        "max_retries": max_retries,
        "final_result": {},
        "messages": [],
    }

    # ğŸ”¥ P0æ”¹è¿›ï¼šæ·»åŠ thread_idå’Œrecursion_limité…ç½®
    config = {
        "configurable": {"thread_id": f"skill_gen_{hash(requirement) % 10000}"},
        "recursion_limit": 50  # é˜²æ­¢æ— é™å¾ªç¯
    }

    result = graph.invoke(initial_state, config)
    return result


# ==================== å¯è§†åŒ– ====================

def visualize_graph():
    """
    ç”Ÿæˆ Mermaid å›¾è¡¨ï¼ˆç”¨äºæ–‡æ¡£ï¼‰

    Returns:
        Mermaid æ ¼å¼çš„å›¾è¡¨å­—ç¬¦ä¸²
    """
    graph = get_skill_generation_graph()
    return graph.get_graph().draw_mermaid()
