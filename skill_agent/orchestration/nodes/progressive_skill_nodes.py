"""
æ¸è¿›å¼æŠ€èƒ½ç”ŸæˆèŠ‚ç‚¹å®ç°
å®ç°ä¸‰é˜¶æ®µç”Ÿæˆï¼šéª¨æ¶ç”Ÿæˆ â†’ é€Trackç”Ÿæˆ â†’ æŠ€èƒ½ç»„è£…
"""

import json
import logging
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, TypedDict, Annotated, Optional, Literal, Tuple
from langchain_core.messages import AIMessage, AnyMessage
from langgraph.graph.message import add_messages
from langgraph.types import StreamWriter
from langgraph.config import get_stream_writer
from pydantic import ValidationError

from .skill_nodes import get_llm, get_openai_client, _prepare_payload_text
from ..schemas import SkillSkeletonSchema, TrackPlanItem, SkillTrack, OdinSkillSchema
from ..streaming import (
    ProgressEventType,
    emit_progress,
)
from core.odin_json_parser import serialize_to_odin

logger = logging.getLogger(__name__)


# ==================== æµå¼ LLM è°ƒç”¨è¾…åŠ©å‡½æ•° ====================

# ğŸ”¥ æ³¨æ„ï¼šåŸ stream_llm_with_reasoning å‡½æ•°å·²åºŸå¼ƒ
# LangGraph Studio é€šè¿‡ stream_mode="messages" è‡ªåŠ¨æ•è· LangChain LLM çš„æµå¼ token
# ä¸å†éœ€è¦æ‰‹åŠ¨å¤„ç†æµå¼è¾“å‡ºï¼ŒLangGraph ä¼šè‡ªåŠ¨è¿½è¸ªæ‰€æœ‰ LLM.invoke() è°ƒç”¨

# ==================== JSON è¾“å‡ºé…ç½® ====================

# è¾“å‡ºç›®å½•ï¼ˆç›¸å¯¹äº skill_agent ç›®å½•ï¼‰
_OUTPUT_DIR = Path(__file__).parent.parent.parent / "Data" / "generated_skills"


def _save_generated_json(
    data: Dict[str, Any], 
    stage: str, 
    skill_name: str = "unknown",
    require_odin_format: bool = True
) -> Tuple[Optional[Path], bool]:
    """
    ä¿å­˜ç”Ÿæˆçš„ JSON æ•°æ®åˆ°æ–‡ä»¶

    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        stage: ç”Ÿæˆé˜¶æ®µ (skeleton/track/final)
        skill_name: æŠ€èƒ½åç§°
        require_odin_format: final é˜¶æ®µæ˜¯å¦å¼ºåˆ¶è¦æ±‚ Odin æ ¼å¼

    Returns:
        (ä¿å­˜çš„æ–‡ä»¶è·¯å¾„, æ˜¯å¦ä¸ºOdinæ ¼å¼) å…ƒç»„ï¼Œè·¯å¾„ä¸ºNoneè¡¨ç¤ºå¤±è´¥
    """
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        _OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶åï¼š{skill_name}_{stage}_{timestamp}.json
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_name = "".join(c if c.isalnum() or c in "-_" else "_" for c in skill_name)
        filename = f"{safe_name}_{stage}_{timestamp}.json"
        filepath = _OUTPUT_DIR / filename
        
        is_odin_format = False

        # å¦‚æœæ˜¯ final é˜¶æ®µï¼Œè½¬æ¢ä¸º Odin åºåˆ—åŒ–æ ¼å¼
        if stage == "final" and "tracks" in data:
            try:
                data_to_save = serialize_to_odin(data)
                is_odin_format = True
                logger.info("âœ… å·²å°†æŠ€èƒ½æ•°æ®è½¬æ¢ä¸º Odin åºåˆ—åŒ–æ ¼å¼")
            except Exception as e:
                if require_odin_format:
                    # å¼ºåˆ¶è¦æ±‚æ—¶è®°å½•é”™è¯¯ä½†ä»ä¿å­˜åŸå§‹æ ¼å¼ï¼ˆåŒæ—¶ä¿å­˜ä¸¤ä¸ªæ–‡ä»¶ï¼‰
                    logger.error(f"âŒ Odin åºåˆ—åŒ–å¤±è´¥: {e}")
                    # ä¿å­˜åŸå§‹æ ¼å¼ä½œä¸ºå¤‡ä»½
                    backup_filename = f"{safe_name}_{stage}_raw_{timestamp}.json"
                    backup_filepath = _OUTPUT_DIR / backup_filename
                    with open(backup_filepath, "w", encoding="utf-8") as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                    logger.warning(f"âš ï¸ å·²ä¿å­˜åŸå§‹æ ¼å¼å¤‡ä»½: {backup_filepath}")
                    
                    # å°è¯•ç®€åŒ–åºåˆ—åŒ–ï¼ˆåªå¤„ç† _odin_typeï¼‰
                    data_to_save = _simple_odin_serialize(data)
                    logger.info("âœ… ä½¿ç”¨ç®€åŒ– Odin åºåˆ—åŒ–")
                else:
                    logger.warning(f"âš ï¸ Odin åºåˆ—åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ ¼å¼: {e}")
                    data_to_save = data
        else:
            data_to_save = data

        # ä¿å­˜ JSONï¼ˆæ ¼å¼åŒ–è¾“å‡ºï¼Œæ”¯æŒä¸­æ–‡ï¼‰
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data_to_save, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ“ å·²ä¿å­˜ {stage} JSON: {filepath}")
        return filepath, is_odin_format

    except Exception as e:
        logger.warning(f"âš ï¸ ä¿å­˜ JSON å¤±è´¥: {e}")
        return None, False


def _simple_odin_serialize(data: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç®€åŒ–çš„ Odin åºåˆ—åŒ–ï¼ˆå½“å®Œæ•´åºåˆ—åŒ–å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
    
    åªç¡®ä¿ _odin_type æ ¼å¼æ­£ç¡®ï¼Œä¸åšå…¶ä»–å¤æ‚è½¬æ¢
    """
    import copy
    result = copy.deepcopy(data)
    
    # éå†æ‰€æœ‰ tracks å’Œ actions
    for track in result.get("tracks", []):
        for action in track.get("actions", []):
            params = action.get("parameters", {})
            odin_type = params.get("_odin_type", "")
            
            # ç¡®ä¿ _odin_type æœ‰ç´¢å¼•å‰ç¼€
            if odin_type and "|" not in odin_type:
                # æ·»åŠ é»˜è®¤ç´¢å¼• 0
                params["_odin_type"] = f"0|{odin_type}"
    
    return result


# ==================== æµå¼è¾“å‡ºè¾…åŠ©å‡½æ•° ====================

def _get_writer_safe() -> Optional[Any]:
    """
    å®‰å…¨è·å–StreamWriter

    åœ¨éæµå¼æ‰§è¡Œç¯å¢ƒä¸­ä¸ä¼šæŠ¥é”™
    """
    try:
        writer = get_stream_writer()
        logger.info(f"âœ… æˆåŠŸè·å– StreamWriter: {type(writer)}")
        return writer
    except Exception as e:
        logger.warning(f"âš ï¸ æ— æ³•è·å– StreamWriter: {e}")
        return None


def _emit_skeleton_progress(
    event_type: ProgressEventType,
    message: str,
    **kwargs
):
    """
    å‘é€éª¨æ¶ç”Ÿæˆè¿›åº¦äº‹ä»¶çš„ä¾¿æ·å‡½æ•°
    """
    writer = _get_writer_safe()
    if writer is None:
        logger.debug(f"[{event_type.value}] {message}")
        return

    # éª¨æ¶é˜¶æ®µè¿›åº¦å›ºå®šä¸º10%ä»¥å†…
    progress = kwargs.pop("progress", 0.05)

    emit_progress(
        writer,
        event_type,
        message,
        progress=progress,
        phase="skeleton",
        **kwargs
    )


def _emit_finalize_progress(
    event_type: ProgressEventType,
    message: str,
    is_valid: bool = True,
    **kwargs
):
    """
    å‘é€æœ€ç»ˆåŒ–è¿›åº¦äº‹ä»¶çš„ä¾¿æ·å‡½æ•°
    """
    writer = _get_writer_safe()
    if writer is None:
        logger.debug(f"[{event_type.value}] {message}")
        return

    # æœ€ç»ˆåŒ–é˜¶æ®µè¿›åº¦ä¸º100%
    progress = 1.0 if is_valid else 0.95

    emit_progress(
        writer,
        event_type,
        message,
        progress=progress,
        phase="finalize",
        **kwargs
    )


def _emit_track_progress(
    event_type: ProgressEventType,
    message: str,
    track_index: int,
    total_tracks: int,
    track_name: str = "",
    **kwargs
):
    """
    å‘é€Trackç”Ÿæˆè¿›åº¦äº‹ä»¶çš„ä¾¿æ·å‡½æ•°
    
    Args:
        event_type: äº‹ä»¶ç±»å‹
        message: æ¶ˆæ¯å†…å®¹
        track_index: å½“å‰Trackç´¢å¼•ï¼ˆ0-basedï¼‰
        total_tracks: Trackæ€»æ•°
        track_name: Trackåç§°
        **kwargs: å…¶ä»–å‚æ•°
    """
    writer = _get_writer_safe()
    if writer is None:
        logger.debug(f"[{event_type.value}] {message}")
        return

    # è®¡ç®—è¿›åº¦ï¼šéª¨æ¶10% + trackså 80%ï¼ˆæŒ‰æ¯”ä¾‹åˆ†é…ï¼‰
    base_progress = 0.1  # éª¨æ¶å·²å®Œæˆ
    track_weight = 0.8 / max(1, total_tracks)
    
    if event_type == ProgressEventType.TRACK_STARTED:
        progress = base_progress + track_index * track_weight
    elif event_type == ProgressEventType.TRACK_COMPLETED:
        progress = base_progress + (track_index + 1) * track_weight
    else:
        progress = base_progress + (track_index + 0.5) * track_weight

    emit_progress(
        writer,
        event_type,
        message,
        progress=progress,
        phase="track",
        track_index=track_index,
        track_name=track_name,
        total_tracks=total_tracks,
        **kwargs
    )


# ==================== State å®šä¹‰ ====================

class ProgressiveSkillGenerationState(TypedDict):
    """
    æ¸è¿›å¼æŠ€èƒ½ç”ŸæˆçŠ¶æ€

    æ”¯æŒä¸‰é˜¶æ®µç”Ÿæˆï¼š
    1. éª¨æ¶ç”Ÿæˆï¼šç”ŸæˆæŠ€èƒ½å…ƒä¿¡æ¯å’Œ track è®¡åˆ’
    2. é€ Track ç”Ÿæˆï¼šä¸ºæ¯ä¸ª track ç”Ÿæˆå…·ä½“ actions
    3. æŠ€èƒ½ç»„è£…ï¼šç»„è£…å®Œæ•´æŠ€èƒ½å¹¶è¿›è¡Œæ•´ä½“éªŒè¯
    """

    # === è¾“å…¥ ===
    requirement: str  # ç”¨æˆ·éœ€æ±‚æè¿°
    similar_skills: List[Dict[str, Any]]  # RAG æ£€ç´¢çš„ç›¸ä¼¼æŠ€èƒ½

    # === é˜¶æ®µ1è¾“å‡º ===
    skill_skeleton: Dict[str, Any]  # éª¨æ¶æ•°æ®ï¼ˆSkillSkeletonSchemaï¼‰
    skeleton_validation_errors: List[str]  # éª¨æ¶éªŒè¯é”™è¯¯
    skeleton_retry_count: int  # éª¨æ¶é‡è¯•æ¬¡æ•°
    max_skeleton_retries: int  # éª¨æ¶æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 2ï¼‰

    # === é˜¶æ®µ2çŠ¶æ€ ===
    track_plan: List[Dict[str, Any]]  # Track è®¡åˆ’åˆ—è¡¨
    current_track_index: int  # å½“å‰æ­£åœ¨ç”Ÿæˆçš„ track ç´¢å¼•
    current_track_data: Dict[str, Any]  # å½“å‰ç”Ÿæˆçš„ track æ•°æ®
    generated_tracks: List[Dict[str, Any]]  # å·²ç”Ÿæˆå¹¶éªŒè¯é€šè¿‡çš„ tracks
    current_track_errors: List[str]  # å½“å‰ track çš„éªŒè¯é”™è¯¯
    track_retry_count: int  # å½“å‰ track é‡è¯•æ¬¡æ•°
    max_track_retries: int  # å•ä¸ª track æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 3ï¼‰
    used_action_types: List[str]  # å·²ä½¿ç”¨çš„ Action ç±»å‹ï¼ˆè·¨ Track ä¼ é€’ï¼‰

    # === é˜¶æ®µ3è¾“å‡º ===
    assembled_skill: Dict[str, Any]  # ç»„è£…åçš„å®Œæ•´æŠ€èƒ½ï¼ˆOdinSkillSchemaï¼‰
    final_validation_errors: List[str]  # æœ€ç»ˆéªŒè¯é”™è¯¯

    # === å…¼å®¹æ—§ç‰ˆ State çš„å­—æ®µ ===
    final_result: Dict[str, Any]  # æœ€ç»ˆç»“æœï¼ˆç­‰åŒäº assembled_skillï¼Œç”¨äºå…¼å®¹æ—§ç‰ˆAPIï¼‰
    is_valid: bool  # æŠ€èƒ½æ˜¯å¦é€šè¿‡éªŒè¯

    # === é€šç”¨ ===
    # ä½¿ç”¨add_messages reducerç¡®ä¿æ¶ˆæ¯æ­£ç¡®ç´¯ç§¯
    messages: Annotated[List[AnyMessage], add_messages]
    thread_id: str  # çº¿ç¨‹IDï¼ˆç”¨äºè¿½è¸ªä¼šè¯ï¼‰


# ==================== é»˜è®¤ Action æ¨¡æ¿ ====================

DEFAULT_ACTIONS_BY_TRACK_TYPE: Dict[str, List[Dict[str, Any]]] = {
    "animation": [
        {
            "action_name": "AnimationAction",
            "action_type": "SkillSystem.Actions.AnimationAction, Assembly-CSharp",
            "description": "æ’­æ”¾è§’è‰²åŠ¨ç”»",
            "parameters": [
                {"name": "animationClipName", "type": "string", "defaultValue": "Attack01"},
                {"name": "normalizedTime", "type": "float", "defaultValue": "0"},
                {"name": "crossFadeDuration", "type": "float", "defaultValue": "0.2"},
                {"name": "animationLayer", "type": "int", "defaultValue": "0"}
            ]
        }
    ],
    "effect": [
        {
            "action_name": "SpawnEffectAction",
            "action_type": "SkillSystem.Actions.SpawnEffectAction, Assembly-CSharp",
            "description": "ç”Ÿæˆç‰¹æ•ˆ",
            "parameters": [
                {"name": "effectPrefab", "type": "string", "defaultValue": "DefaultEffect"},
                {"name": "position", "type": "Vector3", "defaultValue": "(0,0,0)"},
                {"name": "duration", "type": "float", "defaultValue": "1.0"}
            ]
        },
        {
            "action_name": "DamageAction",
            "action_type": "SkillSystem.Actions.DamageAction, Assembly-CSharp",
            "description": "é€ æˆä¼¤å®³",
            "parameters": [
                {"name": "damageAmount", "type": "float", "defaultValue": "10"},
                {"name": "damageType", "type": "DamageType", "defaultValue": "Physical"},
                {"name": "radius", "type": "float", "defaultValue": "1.0"}
            ]
        }
    ],
    "audio": [
        {
            "action_name": "PlaySoundAction",
            "action_type": "SkillSystem.Actions.PlaySoundAction, Assembly-CSharp",
            "description": "æ’­æ”¾éŸ³æ•ˆ",
            "parameters": [
                {"name": "soundClip", "type": "string", "defaultValue": "DefaultSound"},
                {"name": "volume", "type": "float", "defaultValue": "1.0"},
                {"name": "pitch", "type": "float", "defaultValue": "1.0"}
            ]
        }
    ],
    "movement": [
        {
            "action_name": "MoveAction",
            "action_type": "SkillSystem.Actions.MoveAction, Assembly-CSharp",
            "description": "è§’è‰²ä½ç§»",
            "parameters": [
                {"name": "direction", "type": "Vector3", "defaultValue": "(0,0,1)"},
                {"name": "distance", "type": "float", "defaultValue": "2.0"},
                {"name": "speed", "type": "float", "defaultValue": "5.0"}
            ]
        }
    ],
    "camera": [
        {
            "action_name": "CameraShakeAction",
            "action_type": "SkillSystem.Actions.CameraShakeAction, Assembly-CSharp",
            "description": "é•œå¤´éœ‡åŠ¨",
            "parameters": [
                {"name": "intensity", "type": "float", "defaultValue": "0.5"},
                {"name": "duration", "type": "float", "defaultValue": "0.3"}
            ]
        }
    ],
    "other": [
        {
            "action_name": "GenericAction",
            "action_type": "SkillSystem.Actions.GenericAction, Assembly-CSharp",
            "description": "é€šç”¨Action",
            "parameters": []
        }
    ]
}


def get_default_actions_for_track_type(track_type: str) -> List[Dict[str, Any]]:
    """
    è·å–æŒ‡å®šTrackç±»å‹çš„é»˜è®¤Actionæ¨¡æ¿
    
    å½“RAGæ£€ç´¢å¤±è´¥æ—¶ä½¿ç”¨ï¼Œç¡®ä¿LLMæœ‰å‚è€ƒæ ¼å¼
    """
    return DEFAULT_ACTIONS_BY_TRACK_TYPE.get(track_type, DEFAULT_ACTIONS_BY_TRACK_TYPE["other"])


# ==================== éª¨æ¶éªŒè¯å‡½æ•° ====================

def validate_skeleton(skeleton: Dict[str, Any]) -> List[str]:
    """
    éªŒè¯æŠ€èƒ½éª¨æ¶çš„åˆæ³•æ€§

    éªŒè¯è§„åˆ™ï¼š
    1. skillNameã€skillId éç©º
    2. totalDuration >= 30ï¼ˆè‡³å°‘1ç§’@30fpsï¼‰
    3. trackPlan éç©ºæ•°ç»„
    4. æ¯ä¸ª trackPlan é¡¹åŒ…å« trackName å’Œ purpose

    Args:
        skeleton: éª¨æ¶æ•°æ®ï¼ˆdict æ ¼å¼ï¼‰

    Returns:
        é”™è¯¯åˆ—è¡¨ï¼Œç©ºè¡¨ç¤ºéªŒè¯é€šè¿‡
    """
    errors = []

    # éªŒè¯1ï¼šåŸºæœ¬å­—æ®µéç©º
    if not skeleton.get("skillName"):
        errors.append("skillName ä¸èƒ½ä¸ºç©º")

    if not skeleton.get("skillId"):
        errors.append("skillId ä¸èƒ½ä¸ºç©º")

    # éªŒè¯2ï¼štotalDuration è‡³å°‘ 30 å¸§
    total_duration = skeleton.get("totalDuration", 0)
    if not isinstance(total_duration, int) or total_duration < 30:
        errors.append(f"totalDuration ({total_duration}) å¿…é¡»æ˜¯ >= 30 çš„æ•´æ•°")

    # éªŒè¯3ï¼štrackPlan éç©º
    track_plan = skeleton.get("trackPlan", [])
    if not track_plan or not isinstance(track_plan, list):
        errors.append("trackPlan ä¸èƒ½ä¸ºç©ºï¼Œå¿…é¡»æ˜¯æ•°ç»„")
        return errors  # æå‰è¿”å›ï¼Œåç»­éªŒè¯ä¾èµ– trackPlan

    # éªŒè¯4ï¼šæ¯ä¸ª trackPlan é¡¹çš„å¿…å¡«å­—æ®µ
    track_names_seen = set()
    for idx, track_item in enumerate(track_plan):
        if not isinstance(track_item, dict):
            errors.append(f"trackPlan[{idx}] å¿…é¡»æ˜¯å¯¹è±¡")
            continue

        track_name = track_item.get("trackName")
        purpose = track_item.get("purpose")

        if not track_name:
            errors.append(f"trackPlan[{idx}].trackName ä¸èƒ½ä¸ºç©º")
        else:
            # æ£€æŸ¥ trackName å”¯ä¸€æ€§
            if track_name in track_names_seen:
                errors.append(f"trackPlan[{idx}].trackName '{track_name}' é‡å¤")
            track_names_seen.add(track_name)

        if not purpose:
            errors.append(f"trackPlan[{idx}].purpose ä¸èƒ½ä¸ºç©º")

        # éªŒè¯ estimatedActions åˆç†æ€§
        estimated_actions = track_item.get("estimatedActions", 1)
        if not isinstance(estimated_actions, int) or estimated_actions < 1 or estimated_actions > 20:
            errors.append(f"trackPlan[{idx}].estimatedActions ({estimated_actions}) å¿…é¡»åœ¨ 1-20 ä¹‹é—´")

    return errors


# ==================== é˜¶æ®µ1ï¼šéª¨æ¶ç”ŸæˆèŠ‚ç‚¹ ====================

def skeleton_generator_node(state: ProgressiveSkillGenerationState, writer: StreamWriter) -> Dict[str, Any]:
    """
    éª¨æ¶ç”ŸæˆèŠ‚ç‚¹ï¼ˆé˜¶æ®µ1ï¼‰- ä½¿ç”¨ LangChain LLM å®ç°æµå¼è¾“å‡º

    èŒè´£ï¼š
    1. æ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œç›¸ä¼¼æŠ€èƒ½ï¼Œç”ŸæˆæŠ€èƒ½éª¨æ¶å’Œ track è®¡åˆ’
    2. ğŸ”¥ ä½¿ç”¨ OpenAI SDK ç›´æ¥è°ƒç”¨ DeepSeek APIï¼Œæ”¯æŒ reasoning_content æµå¼è¾“å‡º
    3. é€šè¿‡ writer å‘é€ thinking_chunk/content_chunk è‡ªå®šä¹‰äº‹ä»¶
    4. éªŒè¯éª¨æ¶æ•°æ®
    5. å‘é€è¿›åº¦äº‹ä»¶

    Args:
        state: æ¸è¿›å¼æŠ€èƒ½ç”ŸæˆçŠ¶æ€
        writer: LangGraph æ³¨å…¥çš„ StreamWriterï¼Œç”¨äºæµå¼è¾“å‡ºè‡ªå®šä¹‰äº‹ä»¶

    è¾“å‡ºï¼š
    - skill_skeleton: éª¨æ¶æ•°æ®
    - track_plan: Track è®¡åˆ’åˆ—è¡¨
    - skeleton_validation_errors: éªŒè¯é”™è¯¯
    - current_track_index: åˆå§‹åŒ–ä¸º 0
    - generated_tracks: åˆå§‹åŒ–ä¸ºç©ºæ•°ç»„
    """
    from ..prompts.prompt_manager import get_prompt_manager
    from .json_utils import extract_json_from_markdown

    requirement = state["requirement"]
    similar_skills = state.get("similar_skills", [])

    logger.info(f"ğŸ¦´ å¼€å§‹ç”ŸæˆæŠ€èƒ½éª¨æ¶: {requirement[:50]}...")

    # å‘é€éª¨æ¶ç”Ÿæˆå¼€å§‹äº‹ä»¶
    _emit_skeleton_progress(
        ProgressEventType.SKELETON_STARTED,
        f"å¼€å§‹ç”ŸæˆæŠ€èƒ½éª¨æ¶...",
        progress=0.02,
        data={"requirement": requirement[:50]}
    )

    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
    messages = []
    messages.append(AIMessage(content=f"ğŸ¦´ **é˜¶æ®µ1/3**: æ­£åœ¨ç”ŸæˆæŠ€èƒ½éª¨æ¶å’Œ Track è®¡åˆ’..."))

    # æ ¼å¼åŒ–ç›¸ä¼¼æŠ€èƒ½ï¼ˆç®€åŒ–ç‰ˆï¼Œåªç”¨äºå‚è€ƒç»“æ„ï¼‰
    similar_skills_text = format_similar_skills(similar_skills)

    # è·å– Prompt
    prompt_mgr = get_prompt_manager()
    prompt = prompt_mgr.get_prompt("skeleton_generation")

    # å‘é€LLMè°ƒç”¨äº‹ä»¶
    _emit_skeleton_progress(
        ProgressEventType.LLM_CALLING,
        "è°ƒç”¨LLMç”ŸæˆæŠ€èƒ½éª¨æ¶...",
        progress=0.03
    )

    api_start_time = time.time()
    first_chunk_time = None
    logger.info("â³ æ­£åœ¨è°ƒç”¨ DeepSeek API ç”Ÿæˆéª¨æ¶ï¼ˆOpenAI SDK æµå¼ï¼‰...")

    # ğŸ”¥ ç”Ÿæˆå”¯ä¸€çš„ message_id ç”¨äºè·Ÿè¸ªæµå¼æ¶ˆæ¯
    thinking_message_id = f"skeleton_thinking_{api_start_time}"
    content_message_id = f"skeleton_content_{api_start_time}"

    # æ”¶é›†æµå¼è¾“å‡º
    full_reasoning = ""
    full_content = ""

    try:
        # ğŸ”¥ ä½¿ç”¨ OpenAI SDK ç›´æ¥è°ƒç”¨ DeepSeek API
        # LangChain çš„ ChatOpenAI ä¸èƒ½æ­£ç¡®å¤„ç† DeepSeek Reasoner çš„ reasoning_content
        client = get_openai_client()

        # æ¸²æŸ“ prompt æ¨¡æ¿
        prompt_inputs = {
            "requirement": requirement,
            "similar_skills": similar_skills_text or "æ— å‚è€ƒæŠ€èƒ½"
        }
        prompt_value = prompt.invoke(prompt_inputs)

        # è½¬æ¢ä¸º OpenAI æ ¼å¼çš„ messages
        openai_messages = []
        for msg in prompt_value.to_messages():
            msg_type = msg.__class__.__name__.lower()
            if "system" in msg_type:
                openai_messages.append({"role": "system", "content": msg.content})
            elif "human" in msg_type:
                openai_messages.append({"role": "user", "content": msg.content})
            elif "ai" in msg_type:
                openai_messages.append({"role": "assistant", "content": msg.content})
            else:
                openai_messages.append({"role": "user", "content": msg.content})

        logger.info(f"ğŸ“¤ å‘é€è¯·æ±‚åˆ° DeepSeek APIï¼Œæ¶ˆæ¯æ•°: {len(openai_messages)}")

        # ğŸ”¥ å‘é€åˆå§‹æ€è€ƒæç¤º
        if writer:
            try:
                writer({
                    "type": "thinking_chunk",
                    "message_id": thinking_message_id,
                    "chunk": "ğŸ¤” DeepSeek Reasoner æ­£åœ¨åˆ†ææŠ€èƒ½éœ€æ±‚...\n"
                })
            except Exception as e:
                logger.warning(f"âš ï¸ å‘é€åˆå§‹ thinking chunk å¤±è´¥: {e}")

        # ğŸ”¥ ä½¿ç”¨ OpenAI SDK è¿›è¡Œæµå¼è°ƒç”¨
        response = client.chat.completions.create(
            model="deepseek-reasoner",
            messages=openai_messages,
            stream=True
        )

        # æµå¼å¤„ç†å“åº”
        for chunk in response:
            # è®°å½•é¦–å­—èŠ‚æ—¶é—´ï¼ˆTTFBï¼‰
            if first_chunk_time is None:
                first_chunk_time = time.time()
                ttfb = first_chunk_time - api_start_time
                logger.info(f"âš¡ é¦–å­—èŠ‚å»¶è¿Ÿ (TTFB): {ttfb:.2f}s")

            delta = chunk.choices[0].delta if chunk.choices else None
            if delta is None:
                continue

            # æå– reasoning_contentï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰
            reasoning_chunk = getattr(delta, 'reasoning_content', None)
            if reasoning_chunk:
                full_reasoning += reasoning_chunk
                # é™ä½æ—¥å¿—é¢‘ç‡
                if len(full_reasoning) % 500 < len(reasoning_chunk):
                    logger.debug(f"ğŸ“ Reasoning progress: {len(full_reasoning)} chars")

                # ğŸ”¥ ä½¿ç”¨ writer å®æ—¶æ¨é€ thinking chunk
                if writer:
                    try:
                        writer({
                            "type": "thinking_chunk",
                            "message_id": thinking_message_id,
                            "chunk": reasoning_chunk
                        })
                    except Exception as e:
                        logger.debug(f"å‘é€ thinking chunk å¤±è´¥: {e}")

            # æå– contentï¼ˆæœ€ç»ˆè¾“å‡ºï¼‰
            content_chunk = getattr(delta, 'content', None)
            if content_chunk:
                full_content += content_chunk
                # é™ä½æ—¥å¿—é¢‘ç‡
                if len(full_content) % 200 < len(content_chunk):
                    logger.debug(f"ğŸ“ Content progress: {len(full_content)} chars")

                # ğŸ”¥ ä½¿ç”¨ writer å®æ—¶æ¨é€ content chunk
                if writer:
                    try:
                        writer({
                            "type": "content_chunk",
                            "message_id": content_message_id,
                            "chunk": content_chunk
                        })
                    except Exception as e:
                        logger.debug(f"å‘é€ content chunk å¤±è´¥: {e}")

        api_elapsed = time.time() - api_start_time
        logger.info(f"â±ï¸ éª¨æ¶ç”Ÿæˆè€—æ—¶: {api_elapsed:.2f}s")
        logger.info(f"ğŸ§  æ€è€ƒå†…å®¹é•¿åº¦: {len(full_reasoning)} å­—ç¬¦")
        logger.info(f"ğŸ“ è¾“å‡ºå†…å®¹é•¿åº¦: {len(full_content)} å­—ç¬¦")

        # è§£æ JSON å“åº”
        json_content = extract_json_from_markdown(full_content)
        skeleton_dict = json.loads(json_content)

        # ä½¿ç”¨ Pydantic éªŒè¯
        validated = SkillSkeletonSchema.model_validate(skeleton_dict)
        skeleton_dict = validated.model_dump()
        logger.info(f"âœ… éª¨æ¶ç”ŸæˆæˆåŠŸ: {skeleton_dict.get('skillName')}")

        # ä¿å­˜éª¨æ¶ JSON åˆ°æ–‡ä»¶ï¼ˆskeleton é˜¶æ®µä¸æ¶‰åŠ Odin åºåˆ—åŒ–ï¼‰
        _save_generated_json(
            skeleton_dict,
            stage="skeleton",
            skill_name=skeleton_dict.get("skillName", "unknown"),
            require_odin_format=False
        )

        # éªŒè¯éª¨æ¶
        validation_errors = validate_skeleton(skeleton_dict)

        if validation_errors:
            logger.warning(f"âš ï¸ éª¨æ¶éªŒè¯å‘ç° {len(validation_errors)} ä¸ªé”™è¯¯")
            messages.append(AIMessage(
                content=f"âš ï¸ éª¨æ¶éªŒè¯å‘ç° {len(validation_errors)} ä¸ªé—®é¢˜:\n" +
                        "\n".join([f"â€¢ {e}" for e in validation_errors])
            ))
        else:
            logger.info("âœ… éª¨æ¶éªŒè¯é€šè¿‡")
            # æ„å»ºæˆåŠŸæ¶ˆæ¯
            track_plan = skeleton_dict.get("trackPlan", [])
            track_summary = "\n".join([
                f"  {i+1}. **{t['trackName']}** - {t['purpose'][:30]}... (é¢„ä¼° {t['estimatedActions']} actions)"
                for i, t in enumerate(track_plan)
            ])
            messages.append(AIMessage(
                content=f"âœ… **éª¨æ¶ç”Ÿæˆå®Œæˆ**\n\n" +
                        f"**æŠ€èƒ½åç§°**: {skeleton_dict['skillName']}\n" +
                        f"**æŠ€èƒ½ID**: {skeleton_dict['skillId']}\n" +
                        f"**æ€»æ—¶é•¿**: {skeleton_dict['totalDuration']} å¸§\n\n" +
                        f"**Track è®¡åˆ’** ({len(track_plan)} ä¸ªè½¨é“):\n{track_summary}"
            ))

        # ğŸ”¥ æ·»åŠ æ€è€ƒè¿‡ç¨‹æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if full_reasoning:
            messages.append(AIMessage(
                content=full_reasoning,
                additional_kwargs={"thinking": True},
                id=thinking_message_id
            ))

        # å‘é€éª¨æ¶ç”Ÿæˆå®Œæˆäº‹ä»¶
        _emit_skeleton_progress(
            ProgressEventType.SKELETON_COMPLETED,
            f"éª¨æ¶ç”Ÿæˆå®Œæˆ: {skeleton_dict.get('skillName', 'Unknown')}",
            progress=0.1,
            data={
                "skill_name": skeleton_dict.get("skillName"),
                "total_duration": skeleton_dict.get("totalDuration"),
                "track_count": len(skeleton_dict.get("trackPlan", []))
            }
        )

        return {
            "skill_skeleton": skeleton_dict,
            "track_plan": skeleton_dict.get("trackPlan", []),
            "skeleton_validation_errors": validation_errors,
            "current_track_index": 0,
            "generated_tracks": [],
            "track_retry_count": 0,
            "messages": messages
        }

    except ValidationError as e:
        # Pydantic éªŒè¯å¤±è´¥
        logger.error(f"âŒ éª¨æ¶ Schema éªŒè¯å¤±è´¥: {e}")
        error_details = "\n".join([f"â€¢ {err['loc']}: {err['msg']}" for err in e.errors()])
        messages.append(AIMessage(content=f"âŒ éª¨æ¶ç”Ÿæˆå¤±è´¥ï¼ˆSchema éªŒè¯é”™è¯¯ï¼‰:\n{error_details}"))

        # å‘é€éª¨æ¶ç”Ÿæˆå¤±è´¥äº‹ä»¶
        _emit_skeleton_progress(
            ProgressEventType.SKELETON_FAILED,
            f"éª¨æ¶SchemaéªŒè¯å¤±è´¥",
            progress=0.1,
            data={"error": str(e)[:100]}
        )

        return {
            "skill_skeleton": {},
            "track_plan": [],
            "skeleton_validation_errors": [f"Schema éªŒè¯å¤±è´¥: {str(e)}"],
            "current_track_index": 0,
            "generated_tracks": [],
            "track_retry_count": 0,
            "messages": messages
        }

    except Exception as e:
        # å…¶ä»–é”™è¯¯
        logger.error(f"âŒ éª¨æ¶ç”Ÿæˆå¼‚å¸¸: {e}", exc_info=True)
        messages.append(AIMessage(content=f"âŒ éª¨æ¶ç”Ÿæˆå¤±è´¥: {str(e)}"))

        # å‘é€éª¨æ¶ç”Ÿæˆå¤±è´¥äº‹ä»¶
        _emit_skeleton_progress(
            ProgressEventType.SKELETON_FAILED,
            f"éª¨æ¶ç”Ÿæˆå¼‚å¸¸: {str(e)[:50]}",
            progress=0.1,
            data={"error": str(e)[:100]}
        )

        return {
            "skill_skeleton": {},
            "track_plan": [],
            "skeleton_validation_errors": [f"ç”Ÿæˆå¼‚å¸¸: {str(e)}"],
            "current_track_index": 0,
            "generated_tracks": [],
            "track_retry_count": 0,
            "messages": messages
        }


# ==================== è¾…åŠ©å‡½æ•° ====================

def format_similar_skills(skills: List[Dict[str, Any]]) -> str:
    """æ ¼å¼åŒ–ç›¸ä¼¼æŠ€èƒ½ç”¨äº prompt"""
    if not skills:
        return "æ— å‚è€ƒæŠ€èƒ½"

    formatted = []
    for i, skill in enumerate(skills[:3]):
        skill_name = skill.get("skill_name", "Unknown")
        skill_data = skill.get("skill_data", {})

        # æå– track ç»“æ„
        tracks = skill_data.get("tracks", [])
        track_info = []
        for track in tracks[:5]:
            track_name = track.get("trackName", "?")
            actions_count = len(track.get("actions", []))
            track_info.append(f"{track_name} ({actions_count} actions)")

        formatted.append(
            f"å‚è€ƒæŠ€èƒ½ {i+1}: {skill_name}\n"
            f"  - Tracks: {', '.join(track_info) if track_info else 'æ— '}\n"
            f"  - æ€»æ—¶é•¿: {skill_data.get('totalDuration', '?')} å¸§"
        )

    return "\n\n".join(formatted)


# ==================== éª¨æ¶ä¿®å¤èŠ‚ç‚¹ ====================

def skeleton_fixer_node(state: ProgressiveSkillGenerationState) -> Dict[str, Any]:
    """
    éª¨æ¶ä¿®å¤èŠ‚ç‚¹
    
    èŒè´£ï¼šæ ¹æ®éªŒè¯é”™è¯¯ä¿®å¤éª¨æ¶æ•°æ®
    
    è¾“å‡ºï¼š
    - skill_skeleton: ä¿®å¤åçš„éª¨æ¶æ•°æ®
    - skeleton_validation_errors: æ¸…ç©ºï¼ˆç”±éªŒè¯èŠ‚ç‚¹é‡æ–°å¡«å……ï¼‰
    - skeleton_retry_count: é€’å¢é‡è¯•è®¡æ•°
    """
    from ..prompts.prompt_manager import get_prompt_manager
    from .json_utils import extract_json_from_markdown
    
    skeleton = state.get("skill_skeleton", {})
    errors = state.get("skeleton_validation_errors", [])
    requirement = state.get("requirement", "")
    
    logger.info(f"ğŸ”§ ä¿®å¤éª¨æ¶ï¼Œé”™è¯¯æ•°: {len(errors)}")
    
    # æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯
    errors_text = "\n".join([f"{i+1}. {err}" for i, err in enumerate(errors)])
    
    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
    messages = []
    messages.append(AIMessage(
        content=f"ğŸ”§ éª¨æ¶éªŒè¯å‘ç° {len(errors)} ä¸ªé”™è¯¯ï¼Œæ­£åœ¨ä¿®å¤...\n{errors_text}"
    ))
    
    # è·å– Promptï¼ˆå¤ç”¨ä¿®å¤é€»è¾‘ï¼‰
    prompt_mgr = get_prompt_manager()
    prompt = prompt_mgr.get_prompt("skeleton_validation_fix")
    
    # è°ƒç”¨ LLM
    llm = get_llm(temperature=0.3)  # ä¿®å¤æ—¶ä½¿ç”¨æ›´ä½æ¸©åº¦
    
    try:
        fixer_llm = llm.with_structured_output(
            SkillSkeletonSchema,
            method="json_mode",
            include_raw=False
        )
        logger.info("âœ… Skeleton fixer ä½¿ç”¨ structured output æ¨¡å¼")
    except Exception as e:
        logger.warning(f"âš ï¸ Fixer structured output ä¸å¯ç”¨: {e}")
        fixer_llm = llm
    
    chain = prompt | fixer_llm
    
    try:
        response = chain.invoke({
            "errors": errors_text,
            "skeleton_json": json.dumps(skeleton, ensure_ascii=False, indent=2),
            "requirement": requirement
        })
        
        # å¤„ç†å“åº”
        if isinstance(response, SkillSkeletonSchema):
            fixed_skeleton_dict = response.model_dump()
            logger.info("âœ… éª¨æ¶ä¿®å¤æˆåŠŸ (structured output)")
        else:
            payload_text = _prepare_payload_text(response)
            json_content = extract_json_from_markdown(payload_text)
            fixed_skeleton_dict = json.loads(json_content)
            validated = SkillSkeletonSchema.model_validate(fixed_skeleton_dict)
            fixed_skeleton_dict = validated.model_dump()
            logger.info("âœ… éª¨æ¶ä¿®å¤æˆåŠŸï¼ˆæ‰‹åŠ¨è§£æï¼‰")
        
        # é‡æ–°éªŒè¯
        new_errors = validate_skeleton(fixed_skeleton_dict)
        
        messages.append(AIMessage(content="âœ… éª¨æ¶å·²ä¿®å¤ï¼Œé‡æ–°éªŒè¯ä¸­..."))
        
        return {
            "skill_skeleton": fixed_skeleton_dict,
            "track_plan": fixed_skeleton_dict.get("trackPlan", []),
            "skeleton_validation_errors": new_errors,
            "skeleton_retry_count": state.get("skeleton_retry_count", 0) + 1,
            "messages": messages
        }
        
    except Exception as e:
        logger.error(f"âŒ éª¨æ¶ä¿®å¤å¤±è´¥: {e}", exc_info=True)
        messages.append(AIMessage(content=f"âŒ éª¨æ¶ä¿®å¤å¤±è´¥: {str(e)}"))
        
        # ä¿®å¤å¤±è´¥æ—¶ï¼Œä¿ç•™åŸæœ‰é”™è¯¯å¹¶æ·»åŠ ä¿®å¤å¤±è´¥ä¿¡æ¯
        original_errors = state.get("skeleton_validation_errors", [])
        updated_errors = original_errors + [f"ä¿®å¤å¤±è´¥: {str(e)}"]
        
        return {
            "skeleton_validation_errors": updated_errors,
            "skeleton_retry_count": state.get("skeleton_retry_count", 0) + 1,
            "messages": messages
        }


# ==================== æ¡ä»¶åˆ¤æ–­å‡½æ•° ====================

def should_continue_to_track_generation(state: ProgressiveSkillGenerationState) -> Literal["generate_tracks", "fix_skeleton", "skeleton_failed"]:
    """
    åˆ¤æ–­æ˜¯å¦ç»§ç»­è¿›å…¥ Track ç”Ÿæˆé˜¶æ®µ

    æ¡ä»¶ï¼š
    - éª¨æ¶éªŒè¯æ— é”™è¯¯ â†’ "generate_tracks"
    - éª¨æ¶éªŒè¯æœ‰é”™è¯¯ä¸”æœªè¾¾é‡è¯•ä¸Šé™ â†’ "fix_skeleton"
    - éª¨æ¶éªŒè¯æœ‰é”™è¯¯ä¸”è¾¾åˆ°ä¸Šé™ â†’ "skeleton_failed"
    """
    errors = state.get("skeleton_validation_errors", [])
    retry_count = state.get("skeleton_retry_count", 0)
    max_retries = state.get("max_skeleton_retries", 2)

    if not errors:
        return "generate_tracks"
    
    if retry_count < max_retries:
        logger.info(f"éª¨æ¶éœ€è¦ä¿®å¤ (é‡è¯• {retry_count + 1}/{max_retries})")
        return "fix_skeleton"
    else:
        logger.warning(f"éª¨æ¶è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œç”Ÿæˆå¤±è´¥")
        return "skeleton_failed"


# ==================== Track ç±»å‹è¯†åˆ« ====================

# Trackç±»å‹å…³é”®è¯æ˜ å°„ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼Œå¢å¼ºç‰ˆï¼‰
TRACK_TYPE_KEYWORDS = {
    "animation": [
        "animation", "anim", "animator", 
        "åŠ¨ç”»", "å‹•ç•«", "åŠ¨ä½œ", "å‹•ä½œ"
    ],
    "effect": [
        "effect", "fx", "vfx", "visual", "particle",
        "ç‰¹æ•ˆ", "æ•ˆæœ", "ä¼¤å®³", "å‚·å®³", "damage", "buff", "debuff",
        "æŠ€èƒ½æ•ˆæœ", "æ”»å‡»æ•ˆæœ", "æ”»æ“Šæ•ˆæœ"
    ],
    "audio": [
        "audio", "sound", "sfx", "music",
        "éŸ³æ•ˆ", "éŸ³é¢‘", "éŸ³é »", "å£°éŸ³", "è²éŸ³", "éŸ³ä¹", "éŸ³æ¨‚"
    ],
    "movement": [
        "movement", "move", "position", "translate", "dash", "teleport",
        "ç§»åŠ¨", "ç§»å‹•", "ä½ç§»", "å†²åˆº", "è¡åˆº", "ä¼ é€", "å‚³é€", "ä½ç½®"
    ],
    "camera": [
        "camera", "cam", "shake", "zoom", "focus",
        "é•œå¤´", "é¡é ­", "ç›¸æœº", "ç›¸æ©Ÿ", "éœ‡åŠ¨", "éœ‡å‹•", "éœ‡å±"
    ],
}


def infer_track_type(track_name: str) -> str:
    """
    æ ¹æ® track åç§°æ¨æ–­ç±»å‹ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰

    Args:
        track_name: Track åç§°ï¼ˆå¦‚ "Animation Track", "åŠ¨ç”»è½¨é“"ï¼‰

    Returns:
        Track ç±»å‹ï¼šanimation | effect | audio | movement | camera | other
    """
    track_name_lower = track_name.lower()

    for track_type, keywords in TRACK_TYPE_KEYWORDS.items():
        for keyword in keywords:
            if keyword in track_name_lower:
                return track_type

    return "other"


def search_actions_by_track_type(
    track_type: str,
    purpose: str,
    top_k: int = 5,
    suggested_types: Optional[List[str]] = None,
    used_types: Optional[List[str]] = None,
    batch_context: Optional[str] = None
) -> List[Dict[str, Any]]:
    """
    æ ¹æ® track ç±»å‹å’Œç”¨é€”æ£€ç´¢ç›¸å…³ Actionsï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒè¯­ä¹‰ä¸Šä¸‹æ–‡ï¼‰

    ç­–ç•¥ï¼š
    1. åŸºäº track_type è¿‡æ»¤ Action ç±»åˆ«
    2. ä¼˜å…ˆæ£€ç´¢ suggested_types æŒ‡å®šçš„Actionç±»å‹
    3. ç»“åˆ purpose å’Œ batch_context è¿›è¡Œè¯­ä¹‰æ£€ç´¢
    4. é™æƒå·²ä½¿ç”¨çš„ used_typesï¼ˆé¿å…é‡å¤æ¨èåŒç±»å‹ï¼‰
    5. è¿”å›æœ€ç›¸å…³çš„ top_k ä¸ª

    Args:
        track_type: Track ç±»å‹ï¼ˆanimation/effect/audio/movement/camera/otherï¼‰
        purpose: Track ç”¨é€”æè¿°
        top_k: è¿”å›çš„æœ€å¤§ Action æ•°é‡
        suggested_types: å»ºè®®ä½¿ç”¨çš„Actionç±»å‹åˆ—è¡¨ï¼ˆæ¥è‡ªè¯­ä¹‰ä¸Šä¸‹æ–‡ï¼‰
        used_types: å·²ä½¿ç”¨çš„Actionç±»å‹åˆ—è¡¨ï¼ˆé¿å…é‡å¤ï¼‰
        batch_context: æ‰¹æ¬¡ä¸Šä¸‹æ–‡æè¿°

    Returns:
        Action å®šä¹‰åˆ—è¡¨ï¼ˆæŒ‰ç›¸å…³æ€§æ’åºï¼‰
    """
    from ..tools.rag_tools import search_actions

    # Track ç±»å‹ â†’ Action ç±»åˆ«æ˜ å°„
    type_to_category_map = {
        "animation": ["Animation"],
        "effect": ["Effect", "Damage", "Buff", "Debuff", "Spawn", "Heal", "Shield"],
        "audio": ["Audio", "Sound"],
        "movement": ["Movement", "Dash", "Teleport"],
        "camera": ["Camera"],
        "other": []  # ä¸è¿‡æ»¤
    }

    categories = type_to_category_map.get(track_type, [])
    all_results = []

    # ç­–ç•¥1ï¼šä¼˜å…ˆæ£€ç´¢å»ºè®®çš„Actionç±»å‹
    if suggested_types:
        for suggested_type in suggested_types[:3]:  # æœ€å¤šæ£€ç´¢3ç§å»ºè®®ç±»å‹
            try:
                query = f"{suggested_type} {purpose[:30]}"
                results = search_actions.invoke({"query": query, "top_k": 3})
                if isinstance(results, list):
                    for r in results:
                        r["_relevance_boost"] = 2.0  # å»ºè®®ç±»å‹åŠ æƒ
                        if r not in all_results:
                            all_results.append(r)
            except Exception as e:
                logger.warning(f"âš ï¸ æ£€ç´¢å»ºè®®ç±»å‹ {suggested_type} å¤±è´¥: {e}")

    # ç­–ç•¥2ï¼šç»“åˆpurposeå’Œbatch_contextæ„å»ºæŸ¥è¯¢
    if batch_context:
        combined_query = f"{track_type} {batch_context} {purpose[:50]}"
    else:
        combined_query = f"{track_type} {purpose}"

    logger.info(f"ğŸ” æ£€ç´¢ {track_type} track: query=\"{combined_query[:60]}...\"")

    try:
        # ä¸»æŸ¥è¯¢
        results = search_actions.invoke({"query": combined_query, "top_k": top_k * 2})

        if isinstance(results, list):
            for r in results:
                if r not in all_results:
                    r["_relevance_boost"] = 1.0
                    all_results.append(r)

    except Exception as e:
        logger.error(f"âŒ ä¸»æŸ¥è¯¢å¤±è´¥: {e}")

    # ç±»åˆ«è¿‡æ»¤
    if categories:
        filtered_results = []
        for action in all_results:
            action_category = action.get("category", "")
            if any(cat.lower() in action_category.lower() for cat in categories):
                filtered_results.append(action)

        # å¦‚æœè¿‡æ»¤åç»“æœå¤ªå°‘ï¼Œä¿ç•™éƒ¨åˆ†åŸå§‹ç»“æœ
        if len(filtered_results) < top_k // 2 and all_results:
            logger.warning(f"âš ï¸ ç±»åˆ«è¿‡æ»¤ååªå‰© {len(filtered_results)} ä¸ªï¼Œè¡¥å……åŸå§‹ç»“æœ")
            for r in all_results:
                if r not in filtered_results and len(filtered_results) < top_k:
                    filtered_results.append(r)
        all_results = filtered_results

    # é™æƒå·²ä½¿ç”¨çš„ç±»å‹
    if used_types:
        for action in all_results:
            action_type = action.get("typeName", "")
            if action_type in used_types:
                action["_relevance_boost"] = action.get("_relevance_boost", 1.0) * 0.5

    # æŒ‰åŠ æƒç›¸å…³æ€§æ’åº
    all_results.sort(key=lambda x: x.get("_relevance_boost", 1.0), reverse=True)

    # æ¸…ç†ä¸´æ—¶å­—æ®µ
    for action in all_results:
        action.pop("_relevance_boost", None)

    final_results = all_results[:top_k]
    logger.info(f"âœ… æ£€ç´¢åˆ° {len(final_results)} ä¸ª {track_type} ç›¸å…³ Actions")

    return final_results


def validate_track(track_data: Dict[str, Any], total_duration: int) -> List[str]:
    """
    éªŒè¯å•ä¸ª Track çš„åˆæ³•æ€§

    éªŒè¯è§„åˆ™ï¼š
    1. trackName éç©º
    2. actions æ•°ç»„éç©º
    3. æ¯ä¸ª action çš„ frame/duration åˆæ³•
    4. æ¯ä¸ª action çš„ parameters åŒ…å« _odin_type
    5. _odin_type æ ¼å¼æ­£ç¡®ï¼ˆTypeName, Assembly-CSharpï¼‰
    6. æ‰€æœ‰ action çš„ç»“æŸå¸§ <= totalDuration

    Args:
        track_data: Track æ•°æ®ï¼ˆdict æ ¼å¼ï¼‰
        total_duration: æŠ€èƒ½æ€»æ—¶é•¿ï¼ˆå¸§æ•°ï¼‰

    Returns:
        é”™è¯¯åˆ—è¡¨ï¼Œç©ºè¡¨ç¤ºéªŒè¯é€šè¿‡
    """
    from core.odin_json_parser import validate_odin_type
    
    errors = []

    # éªŒè¯1ï¼štrackName éç©º
    track_name = track_data.get("trackName")
    if not track_name:
        errors.append("trackName ä¸èƒ½ä¸ºç©º")
        track_name = "Unknown Track"  # ç”¨äºåç»­é”™è¯¯ä¿¡æ¯

    # éªŒè¯2ï¼šactions æ•°ç»„éç©º
    actions = track_data.get("actions", [])
    if not actions or not isinstance(actions, list):
        errors.append(f"Track '{track_name}' çš„ actions æ•°ç»„ä¸ºç©º")
        return errors  # æå‰è¿”å›ï¼Œåç»­éªŒè¯ä¾èµ– actions

    # éªŒè¯3ï¼šæ¯ä¸ª action çš„åˆæ³•æ€§
    for idx, action in enumerate(actions):
        if not isinstance(action, dict):
            errors.append(f"Track '{track_name}' çš„ action[{idx}] å¿…é¡»æ˜¯å¯¹è±¡")
            continue

        # æ£€æŸ¥ frame
        frame = action.get("frame")
        if not isinstance(frame, int) or frame < 0:
            errors.append(f"Track '{track_name}' action[{idx}].frame å¿…é¡»æ˜¯éè´Ÿæ•´æ•°ï¼ˆå½“å‰: {frame}ï¼‰")

        # æ£€æŸ¥ duration
        duration = action.get("duration")
        if not isinstance(duration, int) or duration < 1:
            errors.append(f"Track '{track_name}' action[{idx}].duration å¿…é¡»æ˜¯æ­£æ•´æ•°ï¼ˆå½“å‰: {duration}ï¼‰")

        # æ£€æŸ¥æ—¶é—´èŒƒå›´
        if isinstance(frame, int) and isinstance(duration, int):
            end_frame = frame + duration
            if end_frame > total_duration:
                errors.append(
                    f"Track '{track_name}' action[{idx}] ç»“æŸå¸§ ({end_frame}) "
                    f"è¶…å‡ºæŠ€èƒ½æ€»æ—¶é•¿ ({total_duration})"
                )

        # æ£€æŸ¥ parameters å’Œ _odin_type
        parameters = action.get("parameters")
        if not parameters or not isinstance(parameters, dict):
            errors.append(f"Track '{track_name}' action[{idx}].parameters ç¼ºå¤±æˆ–æ ¼å¼é”™è¯¯")
        elif "_odin_type" not in parameters:
            errors.append(f"Track '{track_name}' action[{idx}].parameters ç¼ºå°‘ _odin_type")
        else:
            # éªŒè¯ _odin_type æ ¼å¼
            odin_type = parameters.get("_odin_type", "")
            is_valid, _, error_msg = validate_odin_type(odin_type)
            if not is_valid:
                errors.append(f"Track '{track_name}' action[{idx}]: {error_msg}")

    return errors


# ==================== é˜¶æ®µ2ï¼šTrack ç”ŸæˆèŠ‚ç‚¹ ====================

def track_action_generator_node(state: ProgressiveSkillGenerationState, writer: StreamWriter) -> Dict[str, Any]:
    """
    Track Action ç”ŸæˆèŠ‚ç‚¹ï¼ˆé˜¶æ®µ2ï¼‰

    èŒè´£ï¼š
    1. ä¸ºå½“å‰ track ç”Ÿæˆå…·ä½“çš„ actions
    2. æ ¹æ® track ç±»å‹æ£€ç´¢ç›¸å…³ Action å®šä¹‰
    3. ğŸ”¥ ä½¿ç”¨ OpenAI SDK ç›´æ¥è°ƒç”¨ DeepSeek APIï¼Œæ”¯æŒ reasoning_content æµå¼è¾“å‡º
    4. é€šè¿‡ writer å‘é€ thinking_chunk/content_chunk è‡ªå®šä¹‰äº‹ä»¶

    è¾“å‡ºï¼š
    - current_track_data: å½“å‰ç”Ÿæˆçš„ track æ•°æ®
    - current_track_errors: åˆå§‹ä¸ºç©ºï¼ˆç”± validator å¡«å……ï¼‰
    """
    from ..prompts.prompt_manager import get_prompt_manager
    from .json_utils import extract_json_from_markdown

    skeleton = state["skill_skeleton"]
    track_plan = state["track_plan"]
    current_index = state["current_track_index"]

    if current_index >= len(track_plan):
        logger.error(f"âŒ current_track_index ({current_index}) è¶…å‡º track_plan é•¿åº¦ ({len(track_plan)})")
        return {
            "current_track_data": {},
            "current_track_errors": ["ç´¢å¼•è¶Šç•Œ"],
            "messages": [AIMessage(content="âŒ Track ç´¢å¼•é”™è¯¯")]
        }

    current_track_plan = track_plan[current_index]
    track_name = current_track_plan.get("trackName", "Unknown Track")
    purpose = current_track_plan.get("purpose", "")
    estimated_actions = current_track_plan.get("estimatedActions", 1)

    logger.info(
        f"ğŸ¯ å¼€å§‹ç”Ÿæˆ Track [{current_index + 1}/{len(track_plan)}]: "
        f"{track_name} (é¢„ä¼° {estimated_actions} actions)"
    )

    # å‘é€Trackç”Ÿæˆå¼€å§‹äº‹ä»¶
    _emit_track_progress(
        ProgressEventType.TRACK_STARTED,
        f"å¼€å§‹ç”Ÿæˆ Track: {track_name}",
        track_index=current_index,
        total_tracks=len(track_plan),
        track_name=track_name,
        data={"purpose": purpose[:50], "estimated_actions": estimated_actions}
    )

    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
    messages = []
    messages.append(AIMessage(
        content=f"ğŸ¯ **é˜¶æ®µ2/3**: æ­£åœ¨ç”Ÿæˆ Track [{current_index + 1}/{len(track_plan)}] - **{track_name}**\n"
                f"ç”¨é€”: {purpose}"
    ))

    # RAG æ£€ç´¢ï¼šæ ¹æ® trackName å’Œ purpose æ£€ç´¢ç›¸å…³ Actions
    track_type = infer_track_type(track_name)
    used_action_types = state.get("used_action_types", [])
    
    relevant_actions = search_actions_by_track_type(
        track_type=track_type,
        purpose=purpose,
        top_k=5,
        used_types=used_action_types
    )

    # RAG æ£€ç´¢å®¹é”™ï¼šæ— ç»“æœæ—¶ä½¿ç”¨é»˜è®¤æ¨¡æ¿
    if not relevant_actions:
        logger.warning(f"âš ï¸ RAG æ£€ç´¢æ— ç»“æœï¼Œä½¿ç”¨ {track_type} ç±»å‹é»˜è®¤æ¨¡æ¿")
        relevant_actions = get_default_actions_for_track_type(track_type)
        messages.append(AIMessage(
            content=f"âš ï¸ æœªæ£€ç´¢åˆ°ç›¸å…³ Actionï¼Œä½¿ç”¨ {track_type} ç±»å‹é»˜è®¤æ¨¡æ¿ç”Ÿæˆ"
        ))
    else:
        messages.append(AIMessage(
            content=f"ğŸ“‹ æ£€ç´¢åˆ° {len(relevant_actions)} ä¸ªç›¸å…³ Action å®šä¹‰ç”¨äºç”Ÿæˆ"
        ))

    # æ ¼å¼åŒ– Action Schema
    action_schemas_text = format_action_schemas_for_prompt(relevant_actions)

    # è·å– Prompt
    prompt_mgr = get_prompt_manager()
    prompt = prompt_mgr.get_prompt("track_action_generation")

    # ğŸ”¥ ä½¿ç”¨ OpenAI SDK è¿›è¡Œæµå¼è°ƒç”¨
    api_start_time = time.time()
    first_chunk_time = None
    logger.info(f"â³ æ­£åœ¨ä¸º '{track_name}' ç”Ÿæˆ actionsï¼ˆOpenAI SDK æµå¼ï¼‰...")

    # ğŸ”¥ ç”Ÿæˆå”¯ä¸€çš„ message_id ç”¨äºè·Ÿè¸ªæµå¼æ¶ˆæ¯
    thinking_message_id = f"track_{current_index}_thinking_{api_start_time}"
    content_message_id = f"track_{current_index}_content_{api_start_time}"

    # æ”¶é›†æµå¼è¾“å‡º
    full_reasoning = ""
    full_content = ""

    try:
        # ğŸ”¥ ä½¿ç”¨ OpenAI SDK ç›´æ¥è°ƒç”¨ DeepSeek API
        client = get_openai_client()

        # æ¸²æŸ“ prompt æ¨¡æ¿
        prompt_inputs = {
            "skillName": skeleton.get("skillName", "Unknown"),
            "totalDuration": skeleton.get("totalDuration", 150),
            "trackName": track_name,
            "purpose": purpose,
            "estimatedActions": estimated_actions,
            "relevant_actions": action_schemas_text or "æ— ç‰¹å®š Action å‚è€ƒ"
        }
        prompt_value = prompt.invoke(prompt_inputs)

        # è½¬æ¢ä¸º OpenAI æ ¼å¼çš„ messages
        openai_messages = []
        for msg in prompt_value.to_messages():
            msg_type = msg.__class__.__name__.lower()
            if "system" in msg_type:
                openai_messages.append({"role": "system", "content": msg.content})
            elif "human" in msg_type:
                openai_messages.append({"role": "user", "content": msg.content})
            elif "ai" in msg_type:
                openai_messages.append({"role": "assistant", "content": msg.content})
            else:
                openai_messages.append({"role": "user", "content": msg.content})

        logger.info(f"ğŸ“¤ å‘é€è¯·æ±‚åˆ° DeepSeek APIï¼Œæ¶ˆæ¯æ•°: {len(openai_messages)}")

        # ğŸ”¥ å‘é€åˆå§‹æ€è€ƒæç¤º
        if writer:
            try:
                writer({
                    "type": "thinking_chunk",
                    "message_id": thinking_message_id,
                    "chunk": f"ğŸ¤” æ­£åœ¨æ€è€ƒ Track '{track_name}' çš„ actions ç»“æ„...\n"
                })
            except Exception as e:
                logger.warning(f"âš ï¸ å‘é€åˆå§‹ thinking chunk å¤±è´¥: {e}")

        # ğŸ”¥ ä½¿ç”¨ OpenAI SDK è¿›è¡Œæµå¼è°ƒç”¨
        response = client.chat.completions.create(
            model="deepseek-reasoner",
            messages=openai_messages,
            stream=True
        )

        # æµå¼å¤„ç†å“åº”
        for chunk in response:
            # è®°å½•é¦–å­—èŠ‚æ—¶é—´ï¼ˆTTFBï¼‰
            if first_chunk_time is None:
                first_chunk_time = time.time()
                ttfb = first_chunk_time - api_start_time
                logger.info(f"âš¡ Track '{track_name}' é¦–å­—èŠ‚å»¶è¿Ÿ (TTFB): {ttfb:.2f}s")

            delta = chunk.choices[0].delta if chunk.choices else None
            if delta is None:
                continue

            # æå– reasoning_contentï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰
            reasoning_chunk = getattr(delta, 'reasoning_content', None)
            if reasoning_chunk:
                full_reasoning += reasoning_chunk
                # é™ä½æ—¥å¿—é¢‘ç‡
                if len(full_reasoning) % 500 < len(reasoning_chunk):
                    logger.debug(f"ğŸ“ Track reasoning progress: {len(full_reasoning)} chars")

                # ğŸ”¥ ä½¿ç”¨ writer å®æ—¶æ¨é€ thinking chunk
                if writer:
                    try:
                        writer({
                            "type": "thinking_chunk",
                            "message_id": thinking_message_id,
                            "chunk": reasoning_chunk
                        })
                    except Exception as e:
                        logger.debug(f"å‘é€ thinking chunk å¤±è´¥: {e}")

            # æå– contentï¼ˆæœ€ç»ˆè¾“å‡ºï¼‰
            content_chunk = getattr(delta, 'content', None)
            if content_chunk:
                full_content += content_chunk
                # é™ä½æ—¥å¿—é¢‘ç‡
                if len(full_content) % 200 < len(content_chunk):
                    logger.debug(f"ğŸ“ Track content progress: {len(full_content)} chars")

                # ğŸ”¥ ä½¿ç”¨ writer å®æ—¶æ¨é€ content chunk
                if writer:
                    try:
                        writer({
                            "type": "content_chunk",
                            "message_id": content_message_id,
                            "chunk": content_chunk
                        })
                    except Exception as e:
                        logger.debug(f"å‘é€ content chunk å¤±è´¥: {e}")

        api_elapsed = time.time() - api_start_time
        logger.info(f"â±ï¸ Track '{track_name}' ç”Ÿæˆè€—æ—¶: {api_elapsed:.2f}s")
        logger.info(f"ğŸ§  æ€è€ƒå†…å®¹é•¿åº¦: {len(full_reasoning)} å­—ç¬¦")
        logger.info(f"ğŸ“ è¾“å‡ºå†…å®¹é•¿åº¦: {len(full_content)} å­—ç¬¦")

        # è§£æ JSON å“åº”
        json_content = extract_json_from_markdown(full_content)
        track_dict = json.loads(json_content)

        # ä½¿ç”¨ Pydantic éªŒè¯
        validated = SkillTrack.model_validate(track_dict)
        track_dict = validated.model_dump()
        logger.info(f"âœ… Track ç”ŸæˆæˆåŠŸ: {len(track_dict.get('actions', []))} actions")

        # ç¡®ä¿ trackName æ­£ç¡®
        if track_dict.get("trackName") != track_name:
            logger.warning(f"âš ï¸ LLM è¿”å›çš„ trackName ä¸ä¸€è‡´ï¼Œå¼ºåˆ¶ä¿®æ­£ä¸º '{track_name}'")
            track_dict["trackName"] = track_name

        messages.append(AIMessage(
            content=f"âœ… Track ç”Ÿæˆå®Œæˆï¼š{len(track_dict.get('actions', []))} ä¸ª actions"
        ))

        # ğŸ”¥ æ·»åŠ æ€è€ƒè¿‡ç¨‹æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if full_reasoning:
            messages.append(AIMessage(
                content=full_reasoning,
                additional_kwargs={"thinking": True},
                id=thinking_message_id
            ))

        # å‘é€Trackç”Ÿæˆå®Œæˆäº‹ä»¶ï¼ˆæ³¨æ„ï¼šè¿™é‡Œåªæ˜¯LLMç”Ÿæˆå®Œæˆï¼Œè¿˜éœ€è¦éªŒè¯ï¼‰
        _emit_track_progress(
            ProgressEventType.LLM_COMPLETED,
            f"Track {track_name} LLMç”Ÿæˆå®Œæˆï¼Œå¾…éªŒè¯",
            track_index=current_index,
            total_tracks=len(track_plan),
            track_name=track_name,
            data={"actions_count": len(track_dict.get('actions', []))}
        )

        return {
            "current_track_data": track_dict,
            "current_track_errors": [],  # åˆå§‹ä¸ºç©ºï¼Œç”± validator å¡«å……
            "messages": messages
        }

    except ValidationError as e:
        # Pydantic éªŒè¯å¤±è´¥
        logger.error(f"âŒ Track Schema éªŒè¯å¤±è´¥: {e}")
        error_details = "\n".join([f"â€¢ {err['loc']}: {err['msg']}" for err in e.errors()])
        messages.append(AIMessage(content=f"âŒ Track ç”Ÿæˆå¤±è´¥ï¼ˆSchema éªŒè¯é”™è¯¯ï¼‰:\n{error_details}"))

        # å‘é€Trackç”Ÿæˆå¤±è´¥äº‹ä»¶
        _emit_track_progress(
            ProgressEventType.TRACK_FAILED,
            f"Track {track_name} SchemaéªŒè¯å¤±è´¥",
            track_index=current_index,
            total_tracks=len(track_plan),
            track_name=track_name,
            data={"error": str(e)[:100]}
        )

        return {
            "current_track_data": {},
            "current_track_errors": [f"Schema éªŒè¯å¤±è´¥: {str(e)}"],
            "messages": messages
        }

    except Exception as e:
        # å…¶ä»–é”™è¯¯
        logger.error(f"âŒ Track ç”Ÿæˆå¼‚å¸¸: {e}", exc_info=True)
        messages.append(AIMessage(content=f"âŒ Track ç”Ÿæˆå¤±è´¥: {str(e)}"))

        # å‘é€Trackç”Ÿæˆå¤±è´¥äº‹ä»¶
        _emit_track_progress(
            ProgressEventType.TRACK_FAILED,
            f"Track {track_name} ç”Ÿæˆå¼‚å¸¸",
            track_index=current_index,
            total_tracks=len(track_plan),
            track_name=track_name,
            data={"error": str(e)[:100]}
        )

        return {
            "current_track_data": {},
            "current_track_errors": [f"ç”Ÿæˆå¼‚å¸¸: {str(e)}"],
            "messages": messages
        }


def track_validator_node(state: ProgressiveSkillGenerationState) -> Dict[str, Any]:
    """
    Track éªŒè¯èŠ‚ç‚¹

    èŒè´£ï¼šéªŒè¯å½“å‰ç”Ÿæˆçš„ track æ˜¯å¦ç¬¦åˆè§„èŒƒ

    è¾“å‡ºï¼š
    - current_track_errors: æ›´æ–°éªŒè¯é”™è¯¯åˆ—è¡¨
    """
    track_data = state.get("current_track_data", {})
    total_duration = state["skill_skeleton"].get("totalDuration", 150)

    logger.info("ğŸ” éªŒè¯å½“å‰ Track...")

    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
    messages = []

    # éªŒè¯
    errors = validate_track(track_data, total_duration)

    if errors:
        logger.warning(f"âš ï¸ Track éªŒè¯å‘ç° {len(errors)} ä¸ªé”™è¯¯")
        errors_list = "\n".join([f"â€¢ {err}" for err in errors])
        messages.append(AIMessage(
            content=f"âš ï¸ Track éªŒè¯å¤±è´¥ï¼Œå‘ç° {len(errors)} ä¸ªé—®é¢˜:\n{errors_list}"
        ))
    else:
        track_name = track_data.get("trackName", "Unknown")
        actions_count = len(track_data.get("actions", []))
        logger.info(f"âœ… Track '{track_name}' éªŒè¯é€šè¿‡")
        messages.append(AIMessage(
            content=f"âœ… Track éªŒè¯é€šè¿‡ï¼ï¼ˆ{actions_count} actionsï¼‰"
        ))

    return {
        "current_track_errors": errors,
        "messages": messages
    }


def track_fixer_node(state: ProgressiveSkillGenerationState) -> Dict[str, Any]:
    """
    Track ä¿®å¤èŠ‚ç‚¹

    èŒè´£ï¼šæ ¹æ®éªŒè¯é”™è¯¯ä¿®å¤å½“å‰ track

    è¾“å‡ºï¼š
    - current_track_data: ä¿®å¤åçš„ track æ•°æ®
    - track_retry_count: é€’å¢é‡è¯•è®¡æ•°
    """
    from ..prompts.prompt_manager import get_prompt_manager
    from .json_utils import extract_json_from_markdown

    track_data = state.get("current_track_data", {})
    errors = state.get("current_track_errors", [])
    skeleton = state["skill_skeleton"]

    logger.info(f"ğŸ”§ ä¿®å¤ Trackï¼Œé”™è¯¯æ•°: {len(errors)}")

    # æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯
    errors_text = "\n".join([f"{i+1}. {err}" for i, err in enumerate(errors)])

    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
    messages = []
    messages.append(AIMessage(
        content=f"ğŸ”§ å‘ç° {len(errors)} ä¸ªé”™è¯¯ï¼Œæ­£åœ¨ä¿®å¤...\n{errors_text}"
    ))

    # è·å– Promptï¼ˆå¤ç”¨ validation_fixï¼Œé’ˆå¯¹å•ä¸ª trackï¼‰
    prompt_mgr = get_prompt_manager()
    prompt = prompt_mgr.get_prompt("track_validation_fix")

    # è°ƒç”¨ LLM
    llm = get_llm(temperature=0.3)  # ä¿®å¤æ—¶ä½¿ç”¨æ›´ä½æ¸©åº¦

    try:
        fixer_llm = llm.with_structured_output(
            SkillTrack,
            method="json_mode",
            include_raw=False
        )
        logger.info("âœ… Track fixer ä½¿ç”¨ structured output æ¨¡å¼")
    except Exception as e:
        logger.warning(f"âš ï¸ Fixer structured output ä¸å¯ç”¨: {e}")
        fixer_llm = llm

    chain = prompt | fixer_llm

    try:
        response = chain.invoke({
            "errors": errors_text,
            "track_json": json.dumps(track_data, ensure_ascii=False, indent=2),
            "total_duration": skeleton.get("totalDuration", 150)
        })

        # å¤„ç†å“åº”
        if isinstance(response, SkillTrack):
            fixed_track_dict = response.model_dump()
            logger.info("âœ… Track ä¿®å¤æˆåŠŸ (structured output)")
        else:
            payload_text = _prepare_payload_text(response)
            json_content = extract_json_from_markdown(payload_text)
            fixed_track_dict = json.loads(json_content)
            validated = SkillTrack.model_validate(fixed_track_dict)
            fixed_track_dict = validated.model_dump()
            logger.info("âœ… Track ä¿®å¤æˆåŠŸï¼ˆæ‰‹åŠ¨è§£æï¼‰")

        messages.append(AIMessage(content="âœ… Track å·²ä¿®å¤ï¼Œé‡æ–°éªŒè¯ä¸­..."))

        return {
            "current_track_data": fixed_track_dict,
            "track_retry_count": state.get("track_retry_count", 0) + 1,
            "messages": messages
        }

    except Exception as e:
        logger.error(f"âŒ Track ä¿®å¤å¤±è´¥: {e}", exc_info=True)
        messages.append(AIMessage(content=f"âŒ Track ä¿®å¤å¤±è´¥: {str(e)}"))

        return {
            "track_retry_count": state.get("track_retry_count", 0) + 1,
            "messages": messages
        }


def track_saver_node(state: ProgressiveSkillGenerationState) -> Dict[str, Any]:
    """
    Track ä¿å­˜èŠ‚ç‚¹

    èŒè´£ï¼šä¿å­˜éªŒè¯é€šè¿‡çš„ trackï¼Œå¹¶ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ª track

    è¾“å‡ºï¼š
    - generated_tracks: è¿½åŠ å½“å‰ trackï¼ˆè·³è¿‡ç©º trackï¼‰
    - current_track_index: é€’å¢ç´¢å¼•
    - track_retry_count: é‡ç½®ä¸º 0
    - used_action_types: æ›´æ–°å·²ä½¿ç”¨çš„ Action ç±»å‹
    """
    from core.odin_json_parser import extract_type_name_from_odin_type
    
    track_data = state.get("current_track_data", {})
    generated_tracks = list(state.get("generated_tracks", []))  # åˆ›å»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸåˆ—è¡¨
    current_index = state.get("current_track_index", 0)
    track_plan = state.get("track_plan", [])
    used_action_types = list(state.get("used_action_types", []))

    track_name = track_data.get("trackName", "Unknown")
    actions = track_data.get("actions", [])
    actions_count = len(actions)

    # å‡†å¤‡æ¶ˆæ¯
    messages = []
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºç©º Trackï¼ˆè·³è¿‡ä¿å­˜ï¼‰
    if not track_data or not actions:
        logger.warning(f"âš ï¸ è·³è¿‡ç©º Track '{track_name}'ï¼ˆæ— æœ‰æ•ˆ actionsï¼‰")
        messages.append(AIMessage(
            content=f"âš ï¸ Track '{track_name}' ä¸ºç©ºæˆ–æ— æ•ˆï¼Œå·²è·³è¿‡"
        ))
        return {
            "generated_tracks": generated_tracks,  # ä¸è¿½åŠ 
            "current_track_index": current_index + 1,
            "track_retry_count": 0,
            "used_action_types": used_action_types,
            "messages": messages
        }

    logger.info(f"ğŸ’¾ ä¿å­˜ Track '{track_name}' ({actions_count} actions)")

    # ä¿å­˜æœ‰æ•ˆ Track
    generated_tracks.append(track_data)
    
    # æ”¶é›†å·²ä½¿ç”¨çš„ Action ç±»å‹ï¼ˆç”¨äºåç»­ Track é¿å…é‡å¤ï¼‰
    # ä½¿ç”¨ set æé«˜æŸ¥æ‰¾æ•ˆç‡
    used_types_set = set(used_action_types)
    for action in actions:
        params = action.get("parameters", {})
        odin_type = params.get("_odin_type", "")
        if odin_type:
            type_name = extract_type_name_from_odin_type(odin_type)
            if type_name:
                used_types_set.add(type_name)
    used_action_types = list(used_types_set)

    progress = f"[{len(generated_tracks)}/{len(track_plan)}]"
    messages.append(AIMessage(
        content=f"ğŸ’¾ Track '{track_name}' å·²ä¿å­˜ {progress}"
    ))

    # å‘é€Trackå®Œæˆäº‹ä»¶
    _emit_track_progress(
        ProgressEventType.TRACK_COMPLETED,
        f"Track {track_name} å·²ä¿å­˜ {progress}",
        track_index=current_index,
        total_tracks=len(track_plan),
        track_name=track_name,
        data={"actions_count": actions_count, "saved_tracks": len(generated_tracks)}
    )

    return {
        "generated_tracks": generated_tracks,
        "current_track_index": current_index + 1,
        "track_retry_count": 0,  # é‡ç½®é‡è¯•è®¡æ•°
        "used_action_types": used_action_types,
        "messages": messages
    }


# ==================== è¾…åŠ©å‡½æ•° ====================

def format_action_schemas_for_prompt(actions: List[Dict[str, Any]]) -> str:
    """æ ¼å¼åŒ– Action Schema ç”¨äº prompt"""
    if not actions:
        return "æ— ç‰¹å®š Action å‚è€ƒ"

    formatted = []
    for action in actions[:5]:  # æœ€å¤š5ä¸ª
        action_name = action.get("action_name", "Unknown")
        action_type = action.get("action_type", "N/A")
        description = action.get("description", "")[:150]  # é™åˆ¶é•¿åº¦
        parameters = action.get("parameters", [])

        # æ ¼å¼åŒ–å‚æ•°
        params_info = []
        for param in parameters[:8]:  # æœ€å¤šæ˜¾ç¤º8ä¸ªå‚æ•°
            param_name = param.get("name", "unknown")
            param_type = param.get("type", "unknown")
            default_val = param.get("defaultValue", "")

            param_info = f"  - {param_name}: {param_type}"
            if default_val:
                param_info += f" = {default_val}"
            params_info.append(param_info)

        params_text = "\n".join(params_info) if params_info else "  æ— å‚æ•°"

        formatted.append(
            f"**{action_name}** ({action_type})\n"
            f"æè¿°: {description}\n"
            f"å‚æ•°:\n{params_text}"
        )

    return "\n\n".join(formatted)


# ==================== æ¡ä»¶åˆ¤æ–­å‡½æ•° ====================

def should_fix_track(state: ProgressiveSkillGenerationState) -> str:
    """
    åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®å¤ track

    æ¡ä»¶ï¼š
    - æ— é”™è¯¯ â†’ "save"
    - æœ‰é”™è¯¯ä¸”æœªè¾¾é‡è¯•ä¸Šé™ â†’ "fix"
    - æœ‰é”™è¯¯ä¸”è¾¾åˆ°ä¸Šé™ â†’ "skip"
    """
    errors = state.get("current_track_errors", [])
    retry_count = state.get("track_retry_count", 0)
    max_retries = state.get("max_track_retries", 3)

    if not errors:
        return "save"

    if retry_count < max_retries:
        logger.info(f"Track éœ€è¦ä¿®å¤ (é‡è¯• {retry_count + 1}/{max_retries})")
        return "fix"
    else:
        logger.warning(f"Track è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œè·³è¿‡")
        return "skip"


def should_continue_tracks(state: ProgressiveSkillGenerationState) -> str:
    """
    åˆ¤æ–­æ˜¯å¦ç»§ç»­ç”Ÿæˆä¸‹ä¸€ä¸ª track

    æ¡ä»¶ï¼š
    - è¿˜æœ‰æœªç”Ÿæˆçš„ track â†’ "continue"
    - æ‰€æœ‰ track å·²ç”Ÿæˆ â†’ "assemble"
    """
    current_index = state.get("current_track_index", 0)
    track_plan = state.get("track_plan", [])

    if current_index < len(track_plan):
        logger.info(f"ç»§ç»­ç”Ÿæˆä¸‹ä¸€ä¸ª Track ({current_index + 1}/{len(track_plan)})")
        return "continue"
    else:
        logger.info(f"æ‰€æœ‰ {len(track_plan)} ä¸ª Tracks å·²ç”Ÿæˆï¼Œè¿›å…¥ç»„è£…é˜¶æ®µ")
        return "assemble"


# ==================== é˜¶æ®µ3ï¼šæŠ€èƒ½ç»„è£…èŠ‚ç‚¹ ====================

# æ—¶é—´çº¿éªŒè¯é…ç½®å¸¸é‡
TIMELINE_VALIDATION_CONFIG = {
    "audio_sync_tolerance": 15,      # åŠ¨ç”»å’ŒéŸ³æ•ˆåŒæ­¥å®¹å·®ï¼ˆå¸§ï¼‰
    "max_timeline_gap": 60,          # æ—¶é—´è½´æœ€å¤§ç©ºç™½è­¦å‘Šé˜ˆå€¼ï¼ˆå¸§ï¼‰
    "damage_after_visual_delay": 5,  # ä¼¤å®³åœ¨è§†è§‰æ•ˆæœåçš„å»¶è¿Ÿï¼ˆå¸§ï¼‰
    "effect_after_anim_delay": 3,    # ç‰¹æ•ˆåœ¨åŠ¨ç”»åçš„å»¶è¿Ÿï¼ˆå¸§ï¼‰
}


def validate_cross_track_timeline(
    tracks: List[Dict[str, Any]], 
    config: Optional[Dict[str, int]] = None
) -> Tuple[List[str], List[str]]:
    """
    éªŒè¯è·¨Trackæ—¶é—´åŒæ­¥

    æ£€æŸ¥ä¸åŒTracké—´çš„æ—¶é—´åè°ƒæ€§ï¼Œç¡®ä¿ï¼š
    1. åŠ¨ç”»å’ŒéŸ³æ•ˆåœ¨ç›¸è¿‘å¸§è§¦å‘
    2. ä¼¤å®³Actionåœ¨åŠ¨ç”»/ç‰¹æ•ˆä¹‹å
    3. æ•ˆæœTrackä¸æ—©äºåŠ¨ç”»Trackå¼€å§‹

    Args:
        tracks: å·²ç”Ÿæˆçš„Trackåˆ—è¡¨
        config: å¯é€‰çš„éªŒè¯é…ç½®ï¼Œè¦†ç›–é»˜è®¤å€¼

    Returns:
        (errors, warnings) å…ƒç»„
    """
    # åˆå¹¶é…ç½®
    cfg = {**TIMELINE_VALIDATION_CONFIG, **(config or {})}
    audio_sync_tolerance = cfg["audio_sync_tolerance"]
    max_timeline_gap = cfg["max_timeline_gap"]
    
    errors = []
    warnings = []

    # æ”¶é›†å„ç±»å‹Trackçš„å¸§ä¿¡æ¯
    animation_frames: List[int] = []  # åŠ¨ç”»å¼€å§‹å¸§
    audio_frames: List[int] = []       # éŸ³æ•ˆå¼€å§‹å¸§
    damage_frames: List[int] = []      # ä¼¤å®³å¼€å§‹å¸§
    effect_frames: List[int] = []      # ç‰¹æ•ˆå¼€å§‹å¸§

    track_start_frames: Dict[str, int] = {}  # Trackç±»å‹ -> æœ€æ—©å¼€å§‹å¸§

    for track in tracks:
        track_name = track.get("trackName", "")
        actions = track.get("actions", [])

        if not actions:
            continue

        # ä½¿ç”¨å¢å¼ºçš„Trackç±»å‹è¯†åˆ«ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
        track_type = infer_track_type(track_name)

        # è®°å½•Trackæœ€æ—©å¼€å§‹å¸§
        min_frame = min(a.get("frame", 999) for a in actions)

        if track_type == "animation":
            track_start_frames["animation"] = min(
                track_start_frames.get("animation", 999), min_frame
            )
            for action in actions:
                animation_frames.append(action.get("frame", 0))

        elif track_type == "audio":
            track_start_frames["audio"] = min(
                track_start_frames.get("audio", 999), min_frame
            )
            for action in actions:
                audio_frames.append(action.get("frame", 0))

        elif track_type == "effect":
            track_start_frames["effect"] = min(
                track_start_frames.get("effect", 999), min_frame
            )
            for action in actions:
                params = action.get("parameters", {})
                odin_type = params.get("_odin_type", "")

                if "Damage" in odin_type:
                    damage_frames.append(action.get("frame", 0))
                elif "Effect" in odin_type or "Spawn" in odin_type:
                    effect_frames.append(action.get("frame", 0))

    # === éªŒè¯1ï¼šåŠ¨ç”»å’ŒéŸ³æ•ˆæ—¶é—´åŒæ­¥ ===
    if animation_frames and audio_frames:
        for anim_frame in animation_frames[:3]:  # æ£€æŸ¥å‰3ä¸ªåŠ¨ç”»å¸§
            has_nearby_audio = any(
                abs(anim_frame - audio_frame) <= audio_sync_tolerance
                for audio_frame in audio_frames
            )
            if not has_nearby_audio:
                warnings.append(
                    f"åŠ¨ç”»å¸§{anim_frame}é™„è¿‘ç¼ºå°‘é…å¥—éŸ³æ•ˆï¼ˆÂ±{audio_sync_tolerance}å¸§å†…ï¼‰"
                )

    # === éªŒè¯2ï¼šä¼¤å®³åº”åœ¨åŠ¨ç”»/ç‰¹æ•ˆä¹‹å ===
    if damage_frames and (animation_frames or effect_frames):
        earliest_visual = min(
            animation_frames + effect_frames if animation_frames or effect_frames else [0]
        )
        for damage_frame in damage_frames:
            if damage_frame < earliest_visual:
                warnings.append(
                    f"ä¼¤å®³(å¸§{damage_frame})å‡ºç°åœ¨åŠ¨ç”»/ç‰¹æ•ˆ(å¸§{earliest_visual})ä¹‹å‰"
                )

    # === éªŒè¯3ï¼šæ•ˆæœTrackä¸åº”æ—©äºåŠ¨ç”»Track ===
    anim_start = track_start_frames.get("animation", 0)
    effect_start = track_start_frames.get("effect", 999)

    if effect_start < anim_start and anim_start != 999:
        warnings.append(
            f"æ•ˆæœTrack(å¸§{effect_start})æ—©äºåŠ¨ç”»Track(å¸§{anim_start})å¼€å§‹"
        )

    # === éªŒè¯4ï¼šæ£€æŸ¥æ—¶é—´è½´ç©ºç™½ï¼ˆå¯é€‰ï¼Œä»…è­¦å‘Šï¼‰ ===
    all_frames = animation_frames + audio_frames + damage_frames + effect_frames
    if all_frames:
        all_frames.sort()
        max_gap = 0
        for i in range(1, len(all_frames)):
            gap = all_frames[i] - all_frames[i-1]
            if gap > max_gap:
                max_gap = gap

        if max_gap > max_timeline_gap:
            warnings.append(
                f"æ—¶é—´è½´å­˜åœ¨è¾ƒå¤§ç©ºç™½ï¼ˆæœ€å¤§é—´éš”{max_gap}å¸§ï¼‰ï¼Œå¯èƒ½å½±å“æŠ€èƒ½è¿è´¯æ€§"
            )

    return errors, warnings


def auto_fix_timeline_issues(
    tracks: List[Dict[str, Any]], 
    config: Optional[Dict[str, int]] = None
) -> Tuple[List[Dict[str, Any]], List[str]]:
    """
    è‡ªåŠ¨ä¿®å¤è·¨Trackæ—¶é—´çº¿é—®é¢˜
    
    ä¿®å¤ç­–ç•¥ï¼š
    1. ä¼¤å®³Actionæ—©äºåŠ¨ç”» â†’ å°†ä¼¤å®³å¸§åç§»è‡³åŠ¨ç”»å¸§+å»¶è¿Ÿ
    2. æ•ˆæœTrackæ—©äºåŠ¨ç”»Track â†’ å°†æ•ˆæœTrackçš„èµ·å§‹å¸§åç§»
    
    Args:
        tracks: å·²ç”Ÿæˆçš„Trackåˆ—è¡¨
        config: å¯é€‰çš„ä¿®å¤é…ç½®ï¼Œè¦†ç›–é»˜è®¤å€¼
        
    Returns:
        (ä¿®å¤åçš„tracks, ä¿®å¤æ—¥å¿—åˆ—è¡¨)
    """
    import copy
    
    # åˆå¹¶é…ç½®
    cfg = {**TIMELINE_VALIDATION_CONFIG, **(config or {})}
    damage_delay = cfg["damage_after_visual_delay"]
    effect_delay = cfg["effect_after_anim_delay"]
    
    fixed_tracks = copy.deepcopy(tracks)
    fix_logs = []
    
    # æ”¶é›†åŠ¨ç”»å¸§ä¿¡æ¯
    animation_min_frame = 999
    for track in fixed_tracks:
        track_type = infer_track_type(track.get("trackName", ""))
        if track_type == "animation":
            for action in track.get("actions", []):
                frame = action.get("frame", 999)
                if frame < animation_min_frame:
                    animation_min_frame = frame
    
    if animation_min_frame == 999:
        animation_min_frame = 0  # æ²¡æœ‰åŠ¨ç”»Trackæ—¶ä½¿ç”¨0
    
    # éå†ä¿®å¤
    for track in fixed_tracks:
        track_name = track.get("trackName", "")
        track_type = infer_track_type(track_name)
        actions = track.get("actions", [])
        
        for action in actions:
            frame = action.get("frame", 0)
            params = action.get("parameters", {})
            odin_type = params.get("_odin_type", "")
            
            # ä¿®å¤1ï¼šä¼¤å®³Actionæ—©äºåŠ¨ç”»
            if "Damage" in odin_type and frame < animation_min_frame:
                new_frame = animation_min_frame + damage_delay
                fix_logs.append(
                    f"ä¿®å¤: {track_name} ä¼¤å®³å¸§ {frame} â†’ {new_frame}ï¼ˆåŠ¨ç”»åè§¦å‘ï¼‰"
                )
                action["frame"] = new_frame
            
            # ä¿®å¤2ï¼šæ•ˆæœTrackæ—©äºåŠ¨ç”»Track
            elif track_type == "effect" and frame < animation_min_frame:
                # åªä¿®å¤ç‰¹æ•ˆç”Ÿæˆç±»ï¼ˆä¸ä¿®å¤ä¼¤å®³ï¼Œä¸Šé¢å·²å¤„ç†ï¼‰
                if "Effect" in odin_type or "Spawn" in odin_type:
                    new_frame = animation_min_frame + effect_delay
                    fix_logs.append(
                        f"ä¿®å¤: {track_name} ç‰¹æ•ˆå¸§ {frame} â†’ {new_frame}ï¼ˆä¸åŠ¨ç”»åŒæ­¥ï¼‰"
                    )
                    action["frame"] = new_frame
    
    return fixed_tracks, fix_logs


def validate_complete_skill(skill_data: Dict[str, Any]) -> List[str]:
    """
    éªŒè¯å®Œæ•´æŠ€èƒ½çš„åˆæ³•æ€§

    éªŒè¯è§„åˆ™ï¼š
    1. åŸºæœ¬å­—æ®µéç©ºï¼ˆskillName, skillId, totalDurationï¼‰
    2. è‡³å°‘æœ‰ä¸€ä¸ª track
    3. æ‰€æœ‰ track çš„æœ€å¤§ç»“æŸå¸§ <= totalDuration
    4. å¿…é¡»æœ‰ Animation Trackï¼ˆå¯é…ç½®ä¸ºå¯é€‰ï¼‰
    5. å„ track çš„æ—¶é—´è½´é€»è¾‘åˆç†

    Args:
        skill_data: å®Œæ•´æŠ€èƒ½æ•°æ®ï¼ˆdict æ ¼å¼ï¼‰

    Returns:
        é”™è¯¯åˆ—è¡¨ï¼Œç©ºè¡¨ç¤ºéªŒè¯é€šè¿‡
    """
    errors = []

    # éªŒè¯1ï¼šåŸºæœ¬å­—æ®µ
    if not skill_data.get("skillName"):
        errors.append("skillName ä¸èƒ½ä¸ºç©º")

    if not skill_data.get("skillId"):
        errors.append("skillId ä¸èƒ½ä¸ºç©º")

    total_duration = skill_data.get("totalDuration", 0)
    if not isinstance(total_duration, int) or total_duration < 30:
        errors.append(f"totalDuration ({total_duration}) å¿…é¡»æ˜¯ >= 30 çš„æ•´æ•°")

    # éªŒè¯2ï¼šè‡³å°‘æœ‰ä¸€ä¸ª track
    tracks = skill_data.get("tracks", [])
    if not tracks:
        errors.append("tracks ä¸èƒ½ä¸ºç©ºï¼Œè‡³å°‘éœ€è¦ä¸€ä¸ªè½¨é“")
        return errors  # æå‰è¿”å›

    # éªŒè¯3ï¼šæ£€æŸ¥æ‰€æœ‰ action çš„æ—¶é—´èŒƒå›´
    max_end_frame = 0
    for track in tracks:
        track_name = track.get("trackName", "Unknown")
        actions = track.get("actions", [])

        for idx, action in enumerate(actions):
            frame = action.get("frame", 0)
            duration = action.get("duration", 0)
            end_frame = frame + duration

            if end_frame > max_end_frame:
                max_end_frame = end_frame

            if end_frame > total_duration:
                errors.append(
                    f"Track '{track_name}' action[{idx}] ç»“æŸå¸§ ({end_frame}) "
                    f"è¶…å‡ºæŠ€èƒ½æ€»æ—¶é•¿ ({total_duration})"
                )

    # éªŒè¯4ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ Animation Trackï¼ˆå¯é€‰éªŒè¯ï¼‰
    has_animation_track = any(
        "animation" in track.get("trackName", "").lower()
        for track in tracks
    )
    if not has_animation_track:
        # è¿™åªæ˜¯è­¦å‘Šï¼Œä¸ä½œä¸ºé”™è¯¯
        logger.warning("âš ï¸ æŠ€èƒ½æ²¡æœ‰ Animation Trackï¼Œå¯èƒ½ç¼ºå°‘åŠ¨ç”»è¡¨ç°")

    return errors


def skill_assembler_node(state: ProgressiveSkillGenerationState) -> Dict[str, Any]:
    """
    æŠ€èƒ½ç»„è£…èŠ‚ç‚¹ï¼ˆé˜¶æ®µ3ï¼‰

    èŒè´£ï¼š
    1. å°†éª¨æ¶å’Œæ‰€æœ‰ç”Ÿæˆçš„ tracks ç»„è£…æˆå®Œæ•´æŠ€èƒ½
    2. è‡ªåŠ¨ä¿®å¤è·¨Trackæ—¶é—´çº¿é—®é¢˜
    3. è¿›è¡Œæ•´ä½“éªŒè¯
    4. è¾“å‡ºç¬¦åˆ OdinSkillSchema æ ¼å¼çš„æŠ€èƒ½æ•°æ®

    è¾“å‡ºï¼š
    - assembled_skill: ç»„è£…åçš„å®Œæ•´æŠ€èƒ½
    - final_validation_errors: æœ€ç»ˆéªŒè¯é”™è¯¯
    """
    skeleton = state.get("skill_skeleton", {})
    tracks = state.get("generated_tracks", [])

    logger.info(f"ğŸ”§ å¼€å§‹ç»„è£…æŠ€èƒ½: {skeleton.get('skillName', 'Unknown')}")
    logger.info(f"   - éª¨æ¶ä¿¡æ¯: totalDuration={skeleton.get('totalDuration')}, frameRate={skeleton.get('frameRate')}")
    logger.info(f"   - å·²ç”Ÿæˆ {len(tracks)} ä¸ª Tracks")

    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
    messages = []
    messages.append(AIMessage(
        content=f"ğŸ”§ **é˜¶æ®µ3/3**: æ­£åœ¨ç»„è£…å®Œæ•´æŠ€èƒ½...\n"
                f"å…± {len(tracks)} ä¸ªè½¨é“å¾…ç»„è£…"
    ))

    # è·¨Trackæ—¶é—´çº¿è‡ªåŠ¨ä¿®å¤
    fixed_tracks, fix_logs = auto_fix_timeline_issues(tracks)
    if fix_logs:
        logger.info(f"ğŸ”§ è‡ªåŠ¨ä¿®å¤äº† {len(fix_logs)} ä¸ªæ—¶é—´çº¿é—®é¢˜")
        for log in fix_logs:
            logger.info(f"   - {log}")
        messages.append(AIMessage(
            content=f"ğŸ”§ è‡ªåŠ¨ä¿®å¤äº† {len(fix_logs)} ä¸ªæ—¶é—´çº¿é—®é¢˜:\n" +
                    "\n".join([f"â€¢ {log}" for log in fix_logs])
        ))
    
    # ä½¿ç”¨ä¿®å¤åçš„ tracks
    tracks = fixed_tracks

    # ç»„è£…å®Œæ•´æŠ€èƒ½
    assembled_skill = {
        "skillName": skeleton.get("skillName", "Unnamed Skill"),
        "skillId": skeleton.get("skillId", "unknown-skill-001"),
        "skillDescription": skeleton.get("skillDescription", ""),
        "totalDuration": skeleton.get("totalDuration", 150),
        "frameRate": skeleton.get("frameRate", 30),
        "tracks": tracks
    }

    # æ•´ä½“éªŒè¯
    errors = validate_complete_skill(assembled_skill)

    # è·¨Trackæ—¶é—´åŒæ­¥éªŒè¯ï¼ˆä¿®å¤åå†éªŒè¯ï¼‰
    timeline_errors, timeline_warnings = validate_cross_track_timeline(tracks)
    errors.extend(timeline_errors)

    if errors:
        logger.warning(f"âš ï¸ æŠ€èƒ½ç»„è£…åéªŒè¯å‘ç° {len(errors)} ä¸ªé—®é¢˜")
        errors_list = "\n".join([f"â€¢ {err}" for err in errors])
        messages.append(AIMessage(
            content=f"âš ï¸ æŠ€èƒ½éªŒè¯å‘ç° {len(errors)} ä¸ªé—®é¢˜:\n{errors_list}"
        ))
    else:
        logger.info("âœ… æŠ€èƒ½ç»„è£…éªŒè¯é€šè¿‡")

        # ç»Ÿè®¡ä¿¡æ¯
        total_actions = sum(len(track.get("actions", [])) for track in tracks)
        track_summary = ", ".join([
            f"{track.get('trackName', '?')}({len(track.get('actions', []))})"
            for track in tracks
        ])

        result_msg = (
            f"âœ… **æŠ€èƒ½ç»„è£…å®Œæˆ**\n\n"
            f"**æŠ€èƒ½åç§°**: {assembled_skill['skillName']}\n"
            f"**æŠ€èƒ½ID**: {assembled_skill['skillId']}\n"
            f"**æ€»æ—¶é•¿**: {assembled_skill['totalDuration']} å¸§\n"
            f"**è½¨é“æ•°**: {len(tracks)}\n"
            f"**æ€»Actions**: {total_actions}\n\n"
            f"**è½¨é“è¯¦æƒ…**: {track_summary}"
        )

        # æ·»åŠ è·¨Trackæ—¶é—´åŒæ­¥è­¦å‘Š
        if timeline_warnings:
            warnings_text = "\n".join([f"  â€¢ {w}" for w in timeline_warnings[:5]])
            result_msg += f"\n\nâš ï¸ **æ—¶é—´åŒæ­¥å»ºè®®**:\n{warnings_text}"
            logger.warning(f"âš ï¸ è·¨Trackæ—¶é—´åŒæ­¥æœ‰ {len(timeline_warnings)} ä¸ªå»ºè®®")

        messages.append(AIMessage(content=result_msg))

    return {
        "assembled_skill": assembled_skill,
        "final_validation_errors": errors,
        "messages": messages
    }


def finalize_progressive_node(state: ProgressiveSkillGenerationState) -> Dict[str, Any]:
    """
    æ¸è¿›å¼ç”Ÿæˆæœ€ç»ˆåŒ–èŠ‚ç‚¹ - å¢å¼ºç‰ˆï¼šæ”¯æŒæµå¼è¾“å‡º

    èŒè´£ï¼š
    1. è¾“å‡ºæœ€ç»ˆç»“æœ
    2. ç”Ÿæˆæ‘˜è¦æ¶ˆæ¯
    3. å‘é€ç”Ÿæˆå®Œæˆ/å¤±è´¥äº‹ä»¶

    è¾“å‡ºï¼š
    - final_result: æœ€ç»ˆæŠ€èƒ½é…ç½®ï¼ˆä¸æ—§ç‰ˆ SkillGenerationState å…¼å®¹ï¼‰
    """
    assembled_skill = state.get("assembled_skill", {})
    final_errors = state.get("final_validation_errors", [])
    tracks = assembled_skill.get("tracks", [])

    logger.info(f"ğŸ æ¸è¿›å¼æŠ€èƒ½ç”Ÿæˆå®Œæˆ: {assembled_skill.get('skillName', 'Unknown')}")

    # å‡†å¤‡æ¶ˆæ¯
    messages = []

    if final_errors:
        # æœ‰é”™è¯¯ä½†ä»è¾“å‡ºç»“æœï¼ˆæ ‡è®°ä¸ºä¸å®Œæ•´ï¼‰
        messages.append(AIMessage(
            content=f"[WARN] æŠ€èƒ½ç”Ÿæˆå®Œæˆï¼Œä½†å­˜åœ¨ {len(final_errors)} ä¸ªéªŒè¯é—®é¢˜\n"
                    f"å»ºè®®æ‰‹åŠ¨æ£€æŸ¥åä½¿ç”¨"
        ))
        is_valid = False

        # å‘é€ç”Ÿæˆå®Œæˆäº‹ä»¶ï¼ˆå¸¦è­¦å‘Šï¼‰
        _emit_finalize_progress(
            ProgressEventType.GENERATION_COMPLETED,
            f"æŠ€èƒ½ç”Ÿæˆå®Œæˆï¼ˆæœ‰ {len(final_errors)} ä¸ªè­¦å‘Šï¼‰",
            is_valid=False,
            data={
                "skill_name": assembled_skill.get("skillName"),
                "track_count": len(tracks),
                "error_count": len(final_errors)
            }
        )
    else:
        messages.append(AIMessage(
            content="[SUCCESS] **æŠ€èƒ½ç”ŸæˆæˆåŠŸï¼**\n\n"
                    f"æŠ€èƒ½ `{assembled_skill.get('skillName')}` å·²å°±ç»ªï¼Œå¯ç›´æ¥å¯¼å…¥ Unity ä½¿ç”¨"
        ))
        is_valid = True

        # å‘é€ç”Ÿæˆå®Œæˆäº‹ä»¶ï¼ˆæˆåŠŸï¼‰
        total_actions = sum(len(t.get("actions", [])) for t in tracks)
        _emit_finalize_progress(
            ProgressEventType.GENERATION_COMPLETED,
            f"æŠ€èƒ½ {assembled_skill.get('skillName')} ç”ŸæˆæˆåŠŸï¼",
            is_valid=True,
            data={
                "skill_name": assembled_skill.get("skillName"),
                "track_count": len(tracks),
                "total_actions": total_actions,
                "total_duration": assembled_skill.get("totalDuration")
            }
        )

    # ä¿å­˜æœ€ç»ˆæŠ€èƒ½ JSON åˆ°æ–‡ä»¶
    if assembled_skill:
        filepath, is_odin_format = _save_generated_json(
            assembled_skill,
            stage="final",
            skill_name=assembled_skill.get("skillName", "unknown")
        )
        if filepath and not is_odin_format:
            messages.append(AIMessage(
                content="âš ï¸ æ³¨æ„ï¼šOdin åºåˆ—åŒ–å¤±è´¥ï¼Œå·²ä¿å­˜åŸå§‹æ ¼å¼ã€‚å¯èƒ½éœ€è¦æ‰‹åŠ¨è½¬æ¢åå¯¼å…¥ Unityã€‚"
            ))

    # å…¼å®¹æ—§ç‰ˆ State çš„ final_result å­—æ®µ
    return {
        "final_result": assembled_skill,
        "is_valid": is_valid,
        "messages": messages
    }


def should_finalize_or_fail(state: ProgressiveSkillGenerationState) -> Literal["finalize", "failed"]:
    """
    åˆ¤æ–­æ˜¯å¦è¿›å…¥æœ€ç»ˆåŒ–æˆ–å¤±è´¥çŠ¶æ€

    æ¡ä»¶ï¼š
    - æ— æœ€ç»ˆéªŒè¯é”™è¯¯ â†’ "finalize"
    - æœ‰é”™è¯¯ä½†æœ‰ç»„è£…ç»“æœ â†’ "finalize"ï¼ˆå¸¦è­¦å‘Šï¼‰
    - æ— ç»„è£…ç»“æœ â†’ "failed"
    """
    assembled_skill = state.get("assembled_skill", {})
    final_errors = state.get("final_validation_errors", [])

    if not assembled_skill or not assembled_skill.get("tracks"):
        logger.error("âŒ æŠ€èƒ½ç»„è£…å¤±è´¥ï¼Œæ— æœ‰æ•ˆç»“æœ")
        return "failed"

    if final_errors:
        logger.warning(f"âš ï¸ æŠ€èƒ½æœ‰ {len(final_errors)} ä¸ªéªŒè¯é—®é¢˜ï¼Œä½†ä»è¾“å‡ºç»“æœ")

    return "finalize"
