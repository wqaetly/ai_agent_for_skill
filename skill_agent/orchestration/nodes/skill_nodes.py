"""
LangGraph èŠ‚ç‚¹å®ç°
å®šä¹‰ Graph ä¸­çš„å„ä¸ªèŠ‚ç‚¹ï¼ˆgeneratorã€validatorã€fixer ç­‰ï¼‰
"""

import json
import logging
import time
from typing import Any, Dict, List, TypedDict, Annotated
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

from .json_utils import extract_json_from_markdown
from ..config import get_skill_gen_config

logger = logging.getLogger(__name__)

# ==================== é»˜è®¤ç±»å‹é…ç½® ====================
# å½“ LLM ç”Ÿæˆçš„ Action ç¼ºå°‘ _odin_type æ—¶ä½¿ç”¨çš„é»˜è®¤ç±»å‹
# æ³¨æ„ï¼šä¸å†ç¡¬ç¼–ç ç´¢å¼•ï¼Œåºåˆ—åŒ–å™¨ä¼šè‡ªåŠ¨åˆ†é…ç´¢å¼•
DEFAULT_ACTION_TYPE = "SkillSystem.Actions.BaseAction, Assembly-CSharp"


# ==================== State å®šä¹‰ ====================

class SkillGenerationState(TypedDict):
    """æŠ€èƒ½ç”Ÿæˆæµç¨‹çš„çŠ¶æ€"""
    requirement: str  # ç”¨æˆ·éœ€æ±‚æè¿°
    similar_skills: List[Dict[str, Any]]  # æ£€ç´¢åˆ°çš„ç›¸ä¼¼æŠ€èƒ½
    action_schemas: List[Dict[str, Any]]  # ğŸ”¥ æ£€ç´¢åˆ°çš„Actionå®šä¹‰schema
    generated_json: str  # ç”Ÿæˆçš„ JSON
    validation_errors: List[str]  # éªŒè¯é”™è¯¯åˆ—è¡¨
    retry_count: int  # é‡è¯•æ¬¡æ•°
    max_retries: int  # æœ€å¤§é‡è¯•æ¬¡æ•°
    final_result: Dict[str, Any]  # æœ€ç»ˆç»“æœ
    messages: Annotated[List, "append"]  # å¯¹è¯å†å²
    thread_id: str  # ğŸ”¥ çº¿ç¨‹ID (ç”¨äºæµå¼è¾“å‡º)


# ==================== LLM åˆå§‹åŒ– ====================

def get_llm(model: str = None, temperature: float = None, streaming: bool = None):
    """
    è·å– LLM å®ä¾‹ï¼ˆä½¿ç”¨ LangChain ChatOpenAI å…¼å®¹ DeepSeekï¼‰

    Args:
        model: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        temperature: æ¸©åº¦å‚æ•°ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        streaming: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡ºï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰

    Returns:
        ChatOpenAI å®ä¾‹
    """
    config = get_skill_gen_config().llm
    
    # ä½¿ç”¨ä¼ å…¥å‚æ•°æˆ–é…ç½®é»˜è®¤å€¼
    model = model or config.model
    temperature = temperature if temperature is not None else config.temperature
    streaming = streaming if streaming is not None else config.streaming
    
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        raise ValueError("ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY æœªè®¾ç½®")

    logger.info(f"åˆå§‹åŒ– LLM: model={model}, timeout={config.timeout}s, max_retries={config.max_retries}, streaming={streaming}")

    return ChatOpenAI(
        model=model,
        temperature=temperature,
        api_key=api_key,
        base_url="https://api.deepseek.com/v1",
        timeout=config.timeout,
        max_retries=config.max_retries,
        streaming=streaming,
        http_client=None,
    )


def get_openai_client():
    """
    è·å– OpenAI SDK å®¢æˆ·ç«¯ï¼ˆç”¨äºç›´æ¥è°ƒç”¨ DeepSeek API ä»¥æ”¯æŒ reasoning_content æµå¼è¾“å‡ºï¼‰

    Returns:
        OpenAI å®¢æˆ·ç«¯å®ä¾‹ï¼ˆå·²é…ç½®è¶…æ—¶å’Œé‡è¯•ï¼‰
    """
    from openai import OpenAI
    import httpx

    config = get_skill_gen_config().llm
    
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        raise ValueError("ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY æœªè®¾ç½®")

    logger.info(f"åˆå§‹åŒ– OpenAI SDK: timeout={config.timeout}s, max_retries={config.max_retries}")

    return OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com",
        timeout=httpx.Timeout(config.timeout, connect=30.0),
        max_retries=config.max_retries
    )


# ==================== Schema è½¬æ¢è¾…åŠ©å‡½æ•° ====================

def _prepare_payload_text(payload: Any) -> str:
    """
    å°†å¼‚æ„çš„ payloadï¼ˆAIMessage/BaseModel/str/dictï¼‰è§„èŒƒåŒ–ä¸ºåŸå§‹æ–‡æœ¬

    æ”¯æŒå¤šç§è¾“å…¥ç±»å‹ï¼š
    - str: ç›´æ¥è¿”å›
    - AIMessage/æœ‰ content å±æ€§çš„å¯¹è±¡: è¿”å› content
    - Pydantic Model: è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
    - dict/list: åºåˆ—åŒ–ä¸º JSON

    Args:
        payload: ä»»æ„ç±»å‹çš„è¾“å…¥

    Returns:
        è§„èŒƒåŒ–åçš„æ–‡æœ¬å­—ç¬¦ä¸²
    """
    if payload is None:
        return ""

    # å­—ç¬¦ä¸²ç›´æ¥è¿”å›
    if isinstance(payload, str):
        return payload

    # AIMessage æˆ–å…¶ä»–æœ‰ content å±æ€§çš„å¯¹è±¡
    if hasattr(payload, "content"):
        content = payload.content
        # ğŸ”¥ LangChain å¯èƒ½å­˜å‚¨ç»“æ„åŒ–å“åº”ä¸º List[dict]ï¼Œéœ€è¦æå–æ–‡æœ¬éƒ¨åˆ†
        if isinstance(content, list):
            # å°è¯•æå–æ–‡æœ¬å†…å®¹
            text_parts = []
            for item in content:
                if isinstance(item, dict):
                    # å¸¸è§æ ¼å¼ï¼š{'type': 'output_text', 'text': '...'}
                    text_parts.append(item.get('text', ''))
                elif isinstance(item, str):
                    text_parts.append(item)
            if text_parts:
                return ''.join(text_parts)
        elif isinstance(content, dict):
            # dict æ ¼å¼ï¼šå°è¯•æå–æ–‡æœ¬å­—æ®µ
            return content.get('text', content.get('content', json.dumps(content, ensure_ascii=False)))
        # å…¶ä»–æƒ…å†µï¼šè½¬å­—ç¬¦ä¸²
        return str(content)

    # Pydantic V2 Model
    if hasattr(payload, "model_dump_json"):
        try:
            return payload.model_dump_json()
        except Exception:
            pass

    # Pydantic V1 Model æˆ–å…¶ä»–æœ‰ model_dump çš„å¯¹è±¡
    if hasattr(payload, "model_dump"):
        try:
            return json.dumps(payload.model_dump(), ensure_ascii=False)
        except Exception:
            pass

    # dict æˆ– list
    if isinstance(payload, (dict, list)):
        return json.dumps(payload, ensure_ascii=False)

    # å…¶ä»–ç±»å‹ï¼šå¼ºåˆ¶è½¬å­—ç¬¦ä¸²
    return str(payload)


def _safe_int(value: Any, default: int = 0, min_value: int = 0) -> int:
    """
    å®‰å…¨åœ°å°†å€¼è½¬æ¢ä¸ºæ•´æ•°

    æ”¯æŒï¼šstr, int, float, Decimal ç­‰ç±»å‹
    å®¹é”™ï¼šæ— æ•ˆå€¼è¿”å› defaultï¼Œè´Ÿæ•°é’³åˆ¶åˆ° min_value

    Args:
        value: å¾…è½¬æ¢çš„å€¼
        default: è½¬æ¢å¤±è´¥æ—¶çš„é»˜è®¤å€¼
        min_value: æœ€å°å€¼ï¼ˆç”¨äºé’³åˆ¶è´Ÿæ•°ï¼‰

    Returns:
        æ•´æ•°å€¼
    """
    if value is None:
        return default

    try:
        # å°è¯•ç›´æ¥è½¬ int
        result = int(value)
    except (ValueError, TypeError):
        try:
            # å°è¯•å…ˆè½¬ float å†è½¬ intï¼ˆå¤„ç† "12.5" è¿™ç§æƒ…å†µï¼‰
            result = int(float(value))
        except (ValueError, TypeError):
            # å®Œå…¨æ— æ³•è½¬æ¢ï¼Œä½¿ç”¨é»˜è®¤å€¼
            logger.debug(f"æ— æ³•å°† {value} (type={type(value)}) è½¬æ¢ä¸º intï¼Œä½¿ç”¨é»˜è®¤å€¼ {default}")
            return default

    # é’³åˆ¶åˆ°æœ€å°å€¼
    return max(result, min_value)


def _normalize_existing_tracks(payload_dict: Dict[str, Any], source: str):
    """
    è§„èŒƒåŒ–å·²æœ‰ tracks ç»“æ„çš„ payload

    å¤„ç†åœºæ™¯ï¼šDeepSeek å·²ç»ç”Ÿæˆäº† tracksï¼Œä½†å¯èƒ½å­˜åœ¨ï¼š
    - æŸäº› action ç¼ºå°‘ _odin_type
    - totalDuration è®¡ç®—é”™è¯¯
    - frame/duration ä¸ºå­—ç¬¦ä¸²æˆ–æµ®ç‚¹æ•°

    Args:
        payload_dict: å·²è§£æçš„ dictï¼ŒåŒ…å« tracks å­—æ®µ
        source: æ¥æºæè¿°

    Returns:
        éªŒè¯é€šè¿‡çš„ OdinSkillSchema å®ä¾‹
    """
    from pydantic import ValidationError
    from ..schemas import OdinSkillSchema

    # è§„èŒƒåŒ– tracks
    max_end_frame = 0
    normalized_tracks = []

    for track_dict in payload_dict.get("tracks", []):
        track_name = track_dict.get("trackName") or track_dict.get("track_name") or "Unknown Track"
        enabled = bool(track_dict.get("enabled", True))
        actions = track_dict.get("actions", [])

        normalized_actions = []
        for action in actions:
            # ğŸ”¥ ä½¿ç”¨ _safe_int å®¹é”™è½¬æ¢
            frame = _safe_int(action.get("frame"), default=0, min_value=0)
            duration = _safe_int(action.get("duration"), default=1, min_value=1)
            action_enabled = bool(action.get("enabled", True))
            parameters = action.get("parameters") or {}

            # ğŸ”¥ ç¡®ä¿ _odin_type å­˜åœ¨
            if "_odin_type" not in parameters:
                fallback_type = (
                    parameters.get("odinType") or
                    action.get("_odin_type") or
                    action.get("odinType") or
                    DEFAULT_ACTION_TYPE
                )
                parameters = {**parameters, "_odin_type": fallback_type}
                logger.debug(f"ä¸º track[{track_name}].action (frame={frame}) è¡¥å…… _odin_type")

            normalized_actions.append({
                "frame": frame,
                "duration": duration,
                "enabled": action_enabled,
                "parameters": parameters
            })

            # æ›´æ–°æœ€å¤§ç»“æŸå¸§
            max_end_frame = max(max_end_frame, frame + duration)

        normalized_tracks.append({
            "trackName": track_name,
            "enabled": enabled,
            "actions": normalized_actions
        })

    # æ„å»ºè§„èŒƒåŒ–çš„ dict
    normalized_dict = {
        "skillName": payload_dict.get("skillName") or "Unnamed Skill",
        "skillId": payload_dict.get("skillId") or "unnamed-skill-001",
        "skillDescription": payload_dict.get("skillDescription") or "",
        "totalDuration": max(
            _safe_int(payload_dict.get("totalDuration"), default=0, min_value=1),
            max_end_frame or 1
        ),
        "frameRate": _safe_int(payload_dict.get("frameRate"), default=30, min_value=1),
        "tracks": normalized_tracks
    }

    # æœ€ç»ˆéªŒè¯
    try:
        final_skill = OdinSkillSchema.model_validate(normalized_dict)
        logger.info(
            f"âœ… {source} tracks ç»“æ„è§„èŒƒåŒ–æˆåŠŸ "
            f"({len(normalized_tracks)} tracks, "
            f"{sum(len(t['actions']) for t in normalized_tracks)} actions)"
        )
        return final_skill
    except ValidationError as e:
        logger.error(f"âŒ è§„èŒƒåŒ–åçš„ tracks ä»ç„¶æ— æ³•éªŒè¯: {e}")
        raise ValueError(f"{source} tracks è§„èŒƒåŒ–å¤±è´¥") from e


def _enforce_odin_structure(payload: Any, source: str):
    """
    å¼ºåˆ¶å°†ä»»æ„æ ¼å¼çš„ payload è½¬æ¢ä¸ºç¬¦åˆ OdinSkillSchema çš„ç»“æ„

    è¿™ä¸ªå‡½æ•°å®ç°äº†ç¡®å®šæ€§è½¬æ¢å±‚ï¼Œç¡®ä¿å³ä½¿ DeepSeek ç”Ÿæˆäº†ä¸è§„èŒƒçš„æ ¼å¼
    ï¼ˆå¦‚æ‰å¹³çš„ actions æ•°ç»„ï¼‰ï¼Œä¹Ÿèƒ½è‡ªåŠ¨è½¬æ¢ä¸ºæ­£ç¡®çš„ tracks åµŒå¥—ç»“æ„ã€‚

    è½¬æ¢ç­–ç•¥ï¼š
    1. é¦–å…ˆå°è¯•ç›´æ¥éªŒè¯ä¸º OdinSkillSchema
    2. å¦‚æœå¤±è´¥ï¼Œå°è¯•è§£æä¸º SimplifiedSkillSchemaï¼ˆæ‰å¹³ç»“æ„ï¼‰
    3. å°†æ‰å¹³ç»“æ„è½¬æ¢ä¸ºåµŒå¥—çš„ tracks ç»“æ„
    4. è¡¥å……ç¼ºå¤±çš„å¿…å¡«å­—æ®µï¼ˆå¦‚ _odin_typeï¼‰
    5. é‡æ–°è®¡ç®— totalDuration

    Args:
        payload: å¯ä»¥æ˜¯ AIMessageã€å­—ç¬¦ä¸²ã€dict ç­‰
        source: payload æ¥æºæè¿°ï¼ˆç”¨äºæ—¥å¿—ï¼‰

    Returns:
        éªŒè¯é€šè¿‡çš„ OdinSkillSchema å®ä¾‹

    Raises:
        ValueError: å¦‚æœ payload æ— æ³•è½¬æ¢ä¸ºæœ‰æ•ˆçš„ OdinSkillSchema
    """
    from pydantic import ValidationError
    from ..schemas import OdinSkillSchema, SimplifiedSkillSchema

    # å¦‚æœå·²ç»æ˜¯ OdinSkillSchemaï¼Œç›´æ¥è¿”å›
    if isinstance(payload, OdinSkillSchema):
        logger.info(f"{source} payload å·²ç»æ˜¯ OdinSkillSchemaï¼Œç›´æ¥ä½¿ç”¨")
        return payload

    # æ­¥éª¤1ï¼šè§„èŒƒåŒ–ä¸ºæ–‡æœ¬
    payload_text = _prepare_payload_text(payload)
    if not payload_text:
        raise ValueError(f"{source} payload ä¸ºç©ºï¼Œæ— æ³•è½¬æ¢")

    # æ­¥éª¤2ï¼šæå– JSONï¼ˆå¤„ç† Markdown ä»£ç å—ï¼‰
    json_blob = extract_json_from_markdown(payload_text)

    # æ­¥éª¤3ï¼šå°è¯•ç›´æ¥éªŒè¯ä¸º OdinSkillSchema
    try:
        validated_skill = OdinSkillSchema.model_validate_json(json_blob)
        logger.info(f"âœ… {source} payload ç›´æ¥éªŒè¯ä¸º OdinSkillSchema æˆåŠŸ")
        return validated_skill
    except ValidationError as schema_error:
        logger.debug(
            f"âš ï¸ {source} payload æ— æ³•ç›´æ¥éªŒè¯ä¸º OdinSkillSchemaï¼Œå°è¯•è§„èŒƒåŒ–è½¬æ¢",
            exc_info=True
        )

    # æ­¥éª¤4ï¼šè§£æä¸º dictï¼Œå‡†å¤‡è½¬æ¢
    try:
        payload_dict = json.loads(json_blob)
    except json.JSONDecodeError as decode_err:
        raise ValueError(f"{source} payload ä¸æ˜¯æœ‰æ•ˆçš„ JSON") from decode_err

    # æ­¥éª¤5ï¼šæ£€æŸ¥æ ¼å¼ç±»å‹
    has_tracks = "tracks" in payload_dict and isinstance(payload_dict["tracks"], list)
    has_actions = "actions" in payload_dict and isinstance(payload_dict["actions"], list)

    if not has_tracks and not has_actions:
        # æ—¢ä¸æ˜¯ OdinSkillSchema ä¹Ÿä¸æ˜¯ SimplifiedSkillSchemaï¼Œæ— æ³•è½¬æ¢
        raise ValueError(
            f"{source} payload æ—¢æ²¡æœ‰ tracks å­—æ®µä¹Ÿæ²¡æœ‰ actions å­—æ®µï¼Œæ— æ³•è¯†åˆ«æ ¼å¼"
        )

    # ğŸ”¥ åˆ†æ”¯å¤„ç†ï¼štracks å·²å­˜åœ¨ï¼ˆä½†å¯èƒ½æœ‰å­—æ®µç¼ºå¤±ï¼‰vs æ‰å¹³ actions
    if has_tracks:
        logger.info(f"ğŸ”„ æ£€æµ‹åˆ° tracks åµŒå¥—ç»“æ„ï¼Œè¿›è¡Œè§„èŒƒåŒ–ä¿®å¤...")
        return _normalize_existing_tracks(payload_dict, source)

    # å¦åˆ™å¤„ç†æ‰å¹³ actions æ ¼å¼
    logger.info(f"ğŸ”„ æ£€æµ‹åˆ°æ‰å¹³ actions ç»“æ„ï¼Œè½¬æ¢ä¸º tracks åµŒå¥—ç»“æ„...")

    # æ­¥éª¤6ï¼šéªŒè¯ä¸º SimplifiedSkillSchema
    try:
        simplified = SimplifiedSkillSchema.model_validate(payload_dict)
    except ValidationError as e:
        raise ValueError(f"{source} payload ä¹Ÿæ— æ³•éªŒè¯ä¸º SimplifiedSkillSchema") from e

    logger.info(f"ğŸ”„ æ£€æµ‹åˆ°æ‰å¹³ actions ç»“æ„ï¼Œå¼€å§‹è½¬æ¢ä¸º tracks åµŒå¥—ç»“æ„...")

    # æ­¥éª¤7ï¼šæŒ‰ trackName åˆ†ç»„ actions
    grouped_actions: Dict[str, List[Dict[str, Any]]] = {}
    for action in simplified.actions:
        # è·å– trackNameï¼ˆæ”¯æŒå¤šç§å­—æ®µåï¼‰
        track_name = (
            action.get("trackName") or
            action.get("track_name") or
            "Animation Track"  # é»˜è®¤è½¨é“
        )
        grouped_actions.setdefault(track_name, []).append(action)

    # æ­¥éª¤8ï¼šå¦‚æœæ²¡æœ‰ä»»ä½• actionsï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤ action
    if not grouped_actions:
        logger.warning(f"{source} æ²¡æœ‰ä»»ä½• actionsï¼Œåˆ›å»ºé»˜è®¤ action")
        grouped_actions["Animation Track"] = [{
            "frame": 0,
            "duration": 1,
            "enabled": True,
            "parameters": {
                "_odin_type": DEFAULT_ACTION_TYPE
            }
        }]

    # æ­¥éª¤9ï¼šæ„å»º tracks æ•°ç»„å¹¶è§„èŒƒåŒ– actions
    tracks: List[Dict[str, Any]] = []
    max_end_frame = 0

    for track_name, actions in grouped_actions.items():
        odin_actions = []

        for action in actions:
            # ğŸ”¥ æå–å¹¶è§„èŒƒåŒ–å­—æ®µï¼ˆä½¿ç”¨ _safe_int å®¹é”™è½¬æ¢ï¼‰
            frame = _safe_int(action.get("frame"), default=0, min_value=0)
            duration = _safe_int(action.get("duration"), default=1, min_value=1)
            enabled = bool(action.get("enabled", True))
            parameters = action.get("parameters") or {}

            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿ _odin_type å­˜åœ¨
            if "_odin_type" not in parameters:
                # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–
                fallback_type = (
                    parameters.get("odinType") or
                    action.get("_odin_type") or
                    action.get("odinType") or
                    DEFAULT_ACTION_TYPE
                )
                parameters = {**parameters, "_odin_type": fallback_type}
                logger.debug(f"ä¸º action (frame={frame}) è¡¥å…… _odin_type: {fallback_type}")

            odin_actions.append({
                "frame": frame,
                "duration": duration,
                "enabled": enabled,
                "parameters": parameters
            })

            # æ›´æ–°æœ€å¤§ç»“æŸå¸§
            max_end_frame = max(max_end_frame, frame + duration)

        # æ·»åŠ åˆ° tracks
        tracks.append({
            "trackName": track_name,
            "enabled": True,
            "actions": odin_actions
        })

    # æ­¥éª¤10ï¼šæ„å»ºè§„èŒƒåŒ–çš„ dict
    normalized_dict = {
        "skillName": simplified.skillName,
        "skillId": simplified.skillId,
        "skillDescription": (
            simplified.skillDescription or
            payload_dict.get("skillDescription") or
            ""
        ),
        "totalDuration": max(
            _safe_int(payload_dict.get("totalDuration"), default=0, min_value=1),
            max_end_frame or 1
        ),
        "frameRate": _safe_int(payload_dict.get("frameRate"), default=30, min_value=1),
        "tracks": tracks
    }

    # æ­¥éª¤11ï¼šæœ€ç»ˆéªŒè¯
    try:
        final_skill = OdinSkillSchema.model_validate(normalized_dict)
        logger.info(
            f"âœ… {source} payload æˆåŠŸè½¬æ¢ä¸º OdinSkillSchema "
            f"({len(tracks)} tracks, {sum(len(t['actions']) for t in tracks)} actions)"
        )
        return final_skill
    except ValidationError as e:
        logger.error(f"âŒ è§„èŒƒåŒ–åçš„ dict ä»ç„¶æ— æ³•éªŒè¯ä¸º OdinSkillSchema: {e}")
        raise ValueError(f"{source} è§„èŒƒåŒ–å¤±è´¥") from e


# ==================== èŠ‚ç‚¹å‡½æ•° ====================

def retriever_node(state: SkillGenerationState) -> Dict[str, Any]:
    """
    æ£€ç´¢ç›¸ä¼¼æŠ€èƒ½èŠ‚ç‚¹

    æ ¹æ®éœ€æ±‚æè¿°ï¼Œä» RAG Core æ£€ç´¢ç›¸ä¼¼æŠ€èƒ½å’Œç›¸å…³ Action å®šä¹‰ä½œä¸ºå‚è€ƒã€‚
    """
    from ..tools.rag_tools import search_skills_semantic, search_actions

    requirement = state["requirement"]
    logger.info(f"æ£€ç´¢ç›¸ä¼¼æŠ€èƒ½: {requirement}")

    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
    messages = []

    # æ·»åŠ å¼€å§‹æ£€ç´¢çš„æ¶ˆæ¯
    messages.append(AIMessage(content=f"ğŸ” æ­£åœ¨ä»æŠ€èƒ½åº“ä¸­æ£€ç´¢ä¸ã€Œ{requirement}ã€ç›¸å…³çš„æŠ€èƒ½å’ŒActionå®šä¹‰..."))

    # ğŸ”¥ P0æ”¹è¿›ï¼šæ·»åŠ é”™è¯¯è¾¹ç•Œ
    try:
        # è°ƒç”¨ RAG å·¥å…·æ£€ç´¢æŠ€èƒ½ï¼ˆæ·»åŠ æ€§èƒ½æ—¥å¿—ï¼‰
        # top_k=2 ä¼˜åŒ–ï¼šå‡å°‘æ£€ç´¢æ•°é‡ä»¥æå‡é€Ÿåº¦ï¼Œ2ä¸ªé«˜è´¨é‡å‚è€ƒå·²è¶³å¤Ÿ
        start_time = time.time()
        results = search_skills_semantic.invoke({"query": requirement, "top_k": 2})
        rag_elapsed = time.time() - start_time
        logger.info(f"â±ï¸ RAG æŠ€èƒ½æ£€ç´¢è€—æ—¶: {rag_elapsed:.2f}s")

        # ğŸ”¥ æ–°å¢ï¼šæ£€ç´¢ç›¸å…³çš„ Action å®šä¹‰
        action_start = time.time()
        action_results = search_actions.invoke({"query": requirement, "top_k": 5})
        action_elapsed = time.time() - action_start
        logger.info(f"â±ï¸ RAG Actionæ£€ç´¢è€—æ—¶: {action_elapsed:.2f}s")
        logger.info(f"ğŸ“‹ æ£€ç´¢åˆ° {len(action_results) if isinstance(action_results, list) else 0} ä¸ªç›¸å…³Action")
        
        # P2-4: è®°å½• RAG æ£€ç´¢æ€§èƒ½æŒ‡æ ‡
        try:
            from ..metrics import record_rag_search
            record_rag_search(rag_elapsed, "skill")
            record_rag_search(action_elapsed, "action")
        except ImportError:
            pass  # æŒ‡æ ‡æ¨¡å—å¯é€‰
    except Exception as e:
        # RAGæ£€ç´¢å¤±è´¥æ—¶è¿”å›ç©ºç»“æœï¼Œå…è®¸ç»§ç»­æ‰§è¡Œ
        logger.error(f"âŒ RAGæ£€ç´¢å¤±è´¥: {e}", exc_info=True)
        results = []
        action_results = []
        messages.append(AIMessage(content=f"âš ï¸ æ£€ç´¢å¤±è´¥ï¼Œå°†ç›´æ¥åŸºäºéœ€æ±‚ç”Ÿæˆ"))

    # æ„å»ºè¯¦ç»†çš„æ£€ç´¢ç»“æœæ¶ˆæ¯
    if results:
        skills_summary = "\n".join([
            f"â€¢ **{skill.get('skill_name', 'Unknown')}** (ç›¸ä¼¼åº¦: {skill.get('similarity', 0):.2%})"
            for skill in results[:3]
        ])
        message = f"ğŸ“š **æ£€ç´¢åˆ° {len(results)} ä¸ªç›¸ä¼¼æŠ€èƒ½ï¼š**\n\n{skills_summary}\n\nè¿™äº›æŠ€èƒ½å°†ä½œä¸ºç”Ÿæˆå‚è€ƒã€‚"
    else:
        message = "âš ï¸ æœªæ£€ç´¢åˆ°ç›¸ä¼¼æŠ€èƒ½ï¼Œå°†åŸºäºéœ€æ±‚ç›´æ¥ç”Ÿæˆã€‚"

    # æ·»åŠ Actionæ£€ç´¢ç»“æœä¿¡æ¯
    if isinstance(action_results, list) and action_results:
        action_summary = "\n".join([
            f"â€¢ **{action.get('action_name', 'Unknown')}** ({action.get('category', 'N/A')})"
            for action in action_results[:3]
        ])
        message += f"\n\nğŸ¯ **æ£€ç´¢åˆ° {len(action_results)} ä¸ªç›¸å…³Actionï¼š**\n\n{action_summary}"

    messages.append(AIMessage(content=message))

    # P0-3: RAG æ£€ç´¢ç»“æœä¸ºç©ºæ—¶çš„è­¦å‘Šå’Œé™çº§ç­–ç•¥
    has_skills = bool(results)
    has_actions = isinstance(action_results, list) and bool(action_results)

    if not has_skills and not has_actions:
        # å®Œå…¨æ²¡æœ‰å‚è€ƒèµ„æ–™ï¼Œæ·»åŠ å¼ºè­¦å‘Š
        logger.warning(f"âš ï¸ RAG æ£€ç´¢æ— ç»“æœï¼ŒæŠ€èƒ½ç”Ÿæˆè´¨é‡å¯èƒ½è¾ƒä½: {requirement}")
        messages.append(AIMessage(
            content="âš ï¸ **è­¦å‘Šï¼šæœªæ£€ç´¢åˆ°ä»»ä½•å‚è€ƒèµ„æ–™**\n\n"
                    "æŠ€èƒ½åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼æŠ€èƒ½æˆ–ç›¸å…³Actionå®šä¹‰ã€‚\n"
                    "ç”Ÿæˆç»“æœå°†å®Œå…¨åŸºäºéœ€æ±‚æè¿°ï¼Œè´¨é‡å¯èƒ½ä¸ç¨³å®šã€‚\n"
                    "å»ºè®®ï¼šæ£€æŸ¥éœ€æ±‚æè¿°æ˜¯å¦æ¸…æ™°ï¼Œæˆ–å…ˆæ·»åŠ ç›¸å…³æŠ€èƒ½åˆ°çŸ¥è¯†åº“ã€‚"
        ))
    elif not has_skills:
        # æ²¡æœ‰ç›¸ä¼¼æŠ€èƒ½ï¼Œä½†æœ‰Actionå®šä¹‰
        logger.info(f"â„¹ï¸ æœªæ£€ç´¢åˆ°ç›¸ä¼¼æŠ€èƒ½ï¼Œå°†ä»…åŸºäºActionå®šä¹‰ç”Ÿæˆ")
        messages.append(AIMessage(
            content="â„¹ï¸ æœªæ£€ç´¢åˆ°ç›¸ä¼¼æŠ€èƒ½ï¼Œå°†åŸºäºActionå®šä¹‰å’Œéœ€æ±‚æè¿°ç”Ÿæˆã€‚"
        ))
    elif not has_actions:
        # æœ‰ç›¸ä¼¼æŠ€èƒ½ï¼Œä½†æ²¡æœ‰Actionå®šä¹‰
        logger.info(f"â„¹ï¸ æœªæ£€ç´¢åˆ°Actionå®šä¹‰ï¼Œå°†ä»…åŸºäºç›¸ä¼¼æŠ€èƒ½ç”Ÿæˆ")
        messages.append(AIMessage(
            content="â„¹ï¸ æœªæ£€ç´¢åˆ°ç›¸å…³Actionå®šä¹‰ï¼Œå°†åŸºäºç›¸ä¼¼æŠ€èƒ½å‚è€ƒç”Ÿæˆã€‚"
        ))

    return {
        "similar_skills": results,
        "action_schemas": action_results if isinstance(action_results, list) else [],
        "messages": messages
    }


def generator_node(state: SkillGenerationState, writer: Any = None) -> Dict[str, Any]:
    """
    ç”ŸæˆæŠ€èƒ½ JSON èŠ‚ç‚¹

    æ ¹æ®éœ€æ±‚å’Œå‚è€ƒæŠ€èƒ½ï¼Œä½¿ç”¨ LLM ç”ŸæˆæŠ€èƒ½é…ç½® JSONã€‚
    ğŸ”¥ ä½¿ç”¨ structured output ç¡®ä¿ç¬¦åˆ Odin æ ¼å¼

    Args:
        state: æŠ€èƒ½ç”ŸæˆçŠ¶æ€
        writer: StreamWriter å®ä¾‹ï¼ˆç”± LangGraph æ³¨å…¥ï¼Œç”¨äºæµå¼è¾“å‡ºè‡ªå®šä¹‰äº‹ä»¶ï¼‰
    """
    from ..prompts.prompt_manager import get_prompt_manager
    from langgraph.config import get_stream_writer
    from ..schemas import OdinSkillSchema  # ğŸ”¥ å¯¼å…¥ Schema

    requirement = state["requirement"]
    similar_skills = state.get("similar_skills", [])
    action_schemas = state.get("action_schemas", [])  # ğŸ”¥ æ–°å¢ï¼šè·å–action schemas

    # ğŸ”¥ ä½¿ç”¨ LangGraph æ ‡å‡†çš„ stream_writer æœºåˆ¶
    # ä¼˜å…ˆä½¿ç”¨å‚æ•°ä¼ å…¥çš„ writerï¼Œå…¶æ¬¡å°è¯• get_stream_writer()
    if writer is None:
        try:
            writer = get_stream_writer()
            logger.info(f"âœ… Got stream writer from get_stream_writer(): {type(writer)}")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to get stream writer: {e}")
            writer = None
    else:
        logger.info(f"âœ… Got stream writer from parameter: {type(writer)}")

    # ğŸ”¥ ç«‹å³å‘é€ä¸€ä¸ªæµ‹è¯•äº‹ä»¶ï¼ŒéªŒè¯ writer æ˜¯å¦å·¥ä½œ
    if writer:
        try:
            writer({
                "type": "thinking_chunk",
                "message_id": f"test_{time.time()}",
                "chunk": "ğŸ¤” DeepSeek Reasoner å¼€å§‹æ€è€ƒ...\n"
            })
            logger.info("âœ… Test thinking_chunk sent successfully")
        except Exception as e:
            logger.error(f"âŒ Failed to send test chunk: {e}")

    logger.info(f"ç”ŸæˆæŠ€èƒ½ JSON: {requirement}")

    # æ ¼å¼åŒ–ç›¸ä¼¼æŠ€èƒ½
    similar_skills_text = "\n\n".join([
        f"æŠ€èƒ½ {i+1}: {skill.get('skill_name', 'Unknown')}\n{json.dumps(skill.get('skill_data', {}), indent=2, ensure_ascii=False)}"
        for i, skill in enumerate(similar_skills[:2])  # åªå–å‰2ä¸ª
    ])

    # ğŸ”¥ æ–°å¢ï¼šæ ¼å¼åŒ– Action Schemaï¼ˆåŒ…å«å‚æ•°å®šä¹‰å’Œçº¦æŸï¼‰
    action_schemas_text = ""
    if action_schemas:
        formatted_actions = []
        for action in action_schemas[:5]:  # åªå–å‰5ä¸ªç›¸å…³action
            action_name = action.get('action_name', 'Unknown')
            action_type = action.get('action_type', 'N/A')
            category = action.get('category', 'N/A')
            description = action.get('description', '')[:200]  # é™åˆ¶æè¿°é•¿åº¦
            parameters = action.get('parameters', [])

            # æ ¼å¼åŒ–å‚æ•°ä¿¡æ¯
            params_info = []
            for param in parameters:
                param_name = param.get('name', 'unknown')
                param_type = param.get('type', 'unknown')
                default_val = param.get('defaultValue', '')
                constraints = param.get('constraints', {})
                is_enum = param.get('isEnum', False)
                enum_values = param.get('enumValues', [])

                # æ„å»ºå‚æ•°çº¦æŸæè¿°
                constraint_desc = []
                if constraints.get('min'):
                    constraint_desc.append(f"min={constraints['min']}")
                if constraints.get('max'):
                    constraint_desc.append(f"max={constraints['max']}")
                if constraints.get('minValue'):
                    constraint_desc.append(f"minValue={constraints['minValue']}")
                if constraints.get('maxValue'):
                    constraint_desc.append(f"maxValue={constraints['maxValue']}")

                param_info = f"  - {param_name}: {param_type}"
                if default_val:
                    param_info += f" = {default_val}"
                if is_enum and enum_values:
                    param_info += f" (æšä¸¾å€¼: {', '.join(enum_values)})"
                elif constraint_desc:
                    param_info += f" ({', '.join(constraint_desc)})"

                params_info.append(param_info)

            params_text = "\n".join(params_info) if params_info else "  æ— å‚æ•°"

            formatted_action = f"""Action: {action_name} ({action_type})
åˆ†ç±»: {category}
æè¿°: {description}
å‚æ•°å®šä¹‰:
{params_text}"""
            formatted_actions.append(formatted_action)

        action_schemas_text = "\n\n".join(formatted_actions)
        logger.info(f"ğŸ“‹ å·²æ ¼å¼åŒ– {len(formatted_actions)} ä¸ªAction schemaç”¨äºprompt")

    # è·å– Prompt
    prompt_mgr = get_prompt_manager()
    prompt = prompt_mgr.get_prompt("skill_generation")

    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
    messages = []

    # æ·»åŠ å¼€å§‹ç”Ÿæˆçš„æ¶ˆæ¯
    messages.append(AIMessage(content="ğŸ¤– æ­£åœ¨è°ƒç”¨ DeepSeek AI ç”ŸæˆæŠ€èƒ½é…ç½®..."))

    # ğŸ”¥ è°ƒç”¨ LLM ä½¿ç”¨ structured output
    llm = get_llm()

    # ğŸ”¥ å…³é”®æ”¹åŠ¨ï¼šç»‘å®š Pydantic Schemaï¼Œå¼ºåˆ¶ DeepSeek æŒ‰æ ¼å¼è¾“å‡º
    # æ³¨æ„ï¼šdeepseek-reasoner å¯èƒ½ä¸å®Œå…¨æ”¯æŒ structured outputï¼Œè¿™é‡Œä½¿ç”¨ method="json_mode"
    try:
        structured_llm = llm.with_structured_output(
            OdinSkillSchema,
            method="json_mode",  # ä½¿ç”¨ JSON modeï¼ˆå…¼å®¹æ€§æ›´å¥½ï¼‰
            include_raw=False
        )
    except Exception as e:
        logger.warning(f"âš ï¸ Structured output åˆå§‹åŒ–å¤±è´¥ï¼Œé™çº§ä½¿ç”¨æ™®é€šæ¨¡å¼: {e}")
        structured_llm = llm

    chain = prompt | structured_llm

    logger.info(f"â³ æ­£åœ¨è°ƒç”¨ DeepSeek API (structured output + æµå¼)...")
    api_start_time = time.time()
    first_chunk_time = None

    # æ”¶é›†æµå¼è¾“å‡ºï¼ˆåˆ†ç¦»æ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆè¾“å‡ºï¼‰
    full_reasoning = ""  # æ€è€ƒè¿‡ç¨‹
    full_content = ""    # æœ€ç»ˆè¾“å‡º
    structured_result = None  # ğŸ”¥ ç»“æ„åŒ–ç»“æœ

    # ğŸ”¥ ç”Ÿæˆå”¯ä¸€çš„ message_id ç”¨äºè·Ÿè¸ªæµå¼æ¶ˆæ¯
    thinking_message_id = f"thinking_{api_start_time}"
    content_message_id = f"content_{api_start_time}"

    # å‡†å¤‡ prompt è¾“å…¥ï¼ˆç”¨äºæµå¼å’Œå¯èƒ½çš„ structured fallbackï¼‰
    prompt_inputs = {
        "requirement": requirement,
        "similar_skills": similar_skills_text or "æ— å‚è€ƒæŠ€èƒ½",
        "action_schemas": action_schemas_text or "æ— Actionå‚è€ƒ"
    }

    # ğŸ”¥ P0æ”¹è¿›ï¼šæ·»åŠ é”™è¯¯è¾¹ç•Œ
    try:
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ OpenAI SDK ç›´æ¥è°ƒç”¨ DeepSeek API
        # LangChain çš„ ChatOpenAI ä¸èƒ½æ­£ç¡®å¤„ç† DeepSeek Reasoner çš„ reasoning_content
        client = get_openai_client()

        # æ¸²æŸ“ prompt æ¨¡æ¿
        prompt_value = prompt.invoke(prompt_inputs)
        # è½¬æ¢ä¸º OpenAI æ ¼å¼çš„ messages
        openai_messages = []
        for msg in prompt_value.to_messages():
            msg_type = msg.__class__.__name__.lower()
            if "system" in msg_type:
                openai_messages.append({"role": "system", "content": msg.content})
            elif "human" in msg_type:
                openai_messages.append({"role": "user", "content": msg.content})
            elif "ai" in msg_type:
                openai_messages.append({"role": "assistant", "content": msg.content})
            else:
                openai_messages.append({"role": "user", "content": msg.content})

        logger.info(f"ğŸ“¤ Sending request to DeepSeek API with {len(openai_messages)} messages")

        # ğŸ”¥ ä½¿ç”¨ OpenAI SDK è¿›è¡Œæµå¼è°ƒç”¨ï¼Œæ­£ç¡®è·å– reasoning_content
        model_name = get_skill_gen_config().llm.model
        response = client.chat.completions.create(
            model=model_name,
            messages=openai_messages,
            stream=True
        )

        # æµå¼å¤„ç†å“åº”
        for chunk in response:
            # è®°å½•é¦–å­—èŠ‚æ—¶é—´ï¼ˆTTFBï¼‰
            if first_chunk_time is None:
                first_chunk_time = time.time()
                ttfb = first_chunk_time - api_start_time
                logger.info(f"âš¡ é¦–å­—èŠ‚å»¶è¿Ÿ (TTFB): {ttfb:.2f}s")

            # ğŸ”¥ æ­£ç¡®æå– reasoning_contentï¼ˆDeepSeek API æ ‡å‡†ä½ç½®ï¼‰
            delta = chunk.choices[0].delta if chunk.choices else None
            if delta is None:
                continue

            # æå– reasoning_contentï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰
            reasoning_chunk = getattr(delta, 'reasoning_content', None)
            if reasoning_chunk:
                full_reasoning += reasoning_chunk
                # é™ä½æ—¥å¿—é¢‘ç‡ï¼Œæ¯ 500 å­—ç¬¦è®°å½•ä¸€æ¬¡
                if len(full_reasoning) % 500 < len(reasoning_chunk):
                    logger.info(f"ğŸ“ Reasoning progress: {len(full_reasoning)} chars")

                # ğŸ”¥ ä½¿ç”¨ LangGraph æ ‡å‡† writer å®æ—¶æ¨é€ thinking chunk
                if writer:
                    try:
                        writer({
                            "type": "thinking_chunk",
                            "message_id": thinking_message_id,
                            "chunk": reasoning_chunk
                        })
                    except Exception as e:
                        logger.error(f"âŒ Failed to send thinking chunk: {e}")

            # æå– contentï¼ˆæœ€ç»ˆè¾“å‡ºï¼‰
            content_chunk = getattr(delta, 'content', None)
            if content_chunk:
                full_content += content_chunk
                # é™ä½æ—¥å¿—é¢‘ç‡
                if len(full_content) % 200 < len(content_chunk):
                    logger.info(f"ğŸ“ Content progress: {len(full_content)} chars")

                # ğŸ”¥ ä½¿ç”¨ LangGraph æ ‡å‡† writer å®æ—¶æ¨é€ content chunk
                if writer:
                    try:
                        writer({
                            "type": "content_chunk",
                            "message_id": content_message_id,
                            "chunk": content_chunk
                        })
                    except Exception as e:
                        logger.error(f"âŒ Failed to send content chunk: {e}")

        # è®°å½•å®Œæ•´å“åº”å’Œæ€§èƒ½æŒ‡æ ‡
        api_total_time = time.time() - api_start_time
        logger.info(f"âœ… DeepSeek API å“åº”å®Œæˆ")
        logger.info(f"â±ï¸ DeepSeek API æ€»è€—æ—¶: {api_total_time:.2f}s")
        logger.info(f"ğŸ§  æ€è€ƒå†…å®¹é•¿åº¦: {len(full_reasoning)} å­—ç¬¦")
        
        # P2-4: è®°å½•æ€§èƒ½æŒ‡æ ‡
        try:
            from ..metrics import record_llm_latency, record_llm_ttfb
            record_llm_latency(api_total_time)
            if first_chunk_time:
                record_llm_ttfb(first_chunk_time - api_start_time)
        except ImportError:
            pass  # æŒ‡æ ‡æ¨¡å—å¯é€‰
        logger.info(f"ğŸ“ è¾“å‡ºå†…å®¹é•¿åº¦: {len(full_content)} å­—ç¬¦")

        if full_reasoning:
            logger.info(f"ğŸ’­ æ€è€ƒè¿‡ç¨‹é¢„è§ˆ:\n{full_reasoning[:300]}...")
        logger.info(f"ğŸ“„ DeepSeek å®Œæ•´è¾“å‡º:\n{full_content}")

        # ğŸ”¥ å¼ºåˆ¶è½¬æ¢ï¼šä½¿ç”¨ç¡®å®šæ€§è½¬æ¢å±‚ä¿è¯æ ¼å¼æ­£ç¡®
        logger.info("ğŸ” ä½¿ç”¨ _enforce_odin_structure å¼ºåˆ¶è½¬æ¢ä¸º OdinSkillSchema...")

        normalized_skill = None
        structured_fallback_used = False

        # æ­¥éª¤1ï¼šå°è¯•ä»æµå¼è¾“å‡ºå¼ºåˆ¶è½¬æ¢
        try:
            normalized_skill = _enforce_odin_structure(full_content, "stream_output")
            logger.info("âœ… æµå¼è¾“å‡ºæˆåŠŸè½¬æ¢ä¸º OdinSkillSchema")
        except Exception as e:
            logger.warning(f"âš ï¸ æµå¼è¾“å‡ºæ— æ³•è½¬æ¢ä¸º Odin schema: {e}")

        # æ­¥éª¤2ï¼šå¦‚æœæµå¼è¾“å‡ºè½¬æ¢å¤±è´¥ä¸” structured LLM å¯ç”¨ï¼Œè§¦å‘ structured fallback
        if normalized_skill is None and structured_llm is not llm:
            logger.info("ğŸ”„ è§¦å‘ structured fallbackï¼šä½¿ç”¨éæµå¼ structured LLM é‡æ–°ç”Ÿæˆ...")
            try:
                # ä½¿ç”¨ structured LLM è¿›è¡Œéæµå¼è°ƒç”¨
                structured_response = chain.invoke(prompt_inputs)

                # å°è¯•å¼ºåˆ¶è½¬æ¢ structured å“åº”
                normalized_skill = _enforce_odin_structure(
                    structured_response,
                    "structured_fallback"
                )
                structured_fallback_used = True
                logger.info("âœ… Structured fallback æˆåŠŸç”Ÿæˆç¬¦åˆ Schema çš„é…ç½®")
            except Exception as e:
                logger.error(f"âŒ Structured fallback ä¹Ÿå¤±è´¥äº†: {e}", exc_info=True)

        # æ­¥éª¤3ï¼šæ ¹æ®è½¬æ¢ç»“æœè®¾ç½® generated_json å’Œæç¤ºæ¶ˆæ¯
        if normalized_skill is not None:
            # æˆåŠŸè½¬æ¢ï¼Œä½¿ç”¨è§„èŒƒåŒ–çš„ JSON
            generated_json = normalized_skill.model_dump_json(indent=2)

            # æ ¹æ®è½¬æ¢æ¥æºç”Ÿæˆä¸åŒçš„æç¤º
            if structured_fallback_used:
                origin_hint = "Structured Fallback æˆåŠŸç”Ÿæˆ"
            else:
                origin_hint = "æµå¼è¾“å‡ºæˆåŠŸè½¬æ¢"

            messages.append(AIMessage(
                content=f"âœ… **Schema éªŒè¯é€šè¿‡**ï¼š{origin_hint}ï¼ŒæŠ€èƒ½é…ç½®ç¬¦åˆå®Œæ•´çš„ tracks/actions åµŒå¥—ç»“æ„"
            ))
        else:
            # æ‰€æœ‰è½¬æ¢å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›åŸå§‹è¾“å‡ºï¼ˆè®© validator/fixer ç»§ç»­å¤„ç†ï¼‰
            logger.warning("âš ï¸ æ‰€æœ‰è½¬æ¢å°è¯•å‡å¤±è´¥ï¼Œè¿”å›åŸå§‹æµå¼è¾“å‡º")
            generated_json = full_content
            messages.append(AIMessage(
                content="âš ï¸ **Schema éªŒè¯è­¦å‘Š**ï¼šæ ¼å¼è½¬æ¢å¤±è´¥ï¼ŒåŸå§‹è¾“å‡ºå°†äº¤ç”± validator/fixer ç»§ç»­å¤„ç†"
            ))

        # å¦‚æœæœ‰æ€è€ƒè¿‡ç¨‹ï¼Œä½œä¸ºå•ç‹¬çš„æ¶ˆæ¯æ·»åŠ ï¼ˆæ ‡è®°ä¸º thinkingï¼‰
        # ğŸ”¥ ä½¿ç”¨ä¸æµå¼chunkç›¸åŒçš„ message_idï¼Œç¡®ä¿å‰ç«¯å¯ä»¥æ­£ç¡®æ›´æ–°æ¶ˆæ¯
        if full_reasoning:
            messages.append(AIMessage(
                content=full_reasoning,
                additional_kwargs={"thinking": True},
                id=thinking_message_id  # ğŸ”¥ ä½¿ç”¨ç›¸åŒçš„ ID
            ))

        # æ·»åŠ  DeepSeek çš„æœ€ç»ˆè¾“å‡º
        # ğŸ”¥ ä½¿ç”¨ä¸æµå¼chunkç›¸åŒçš„ message_id
        messages.append(AIMessage(
            content=full_content,
            id=content_message_id  # ğŸ”¥ ä½¿ç”¨ç›¸åŒçš„ ID
        ))

    except TimeoutError as e:
        # LLMè°ƒç”¨è¶…æ—¶
        logger.error(f"âŒ DeepSeek API è¶…æ—¶: {e}")
        generated_json = ""
        messages.append(AIMessage(content=f"â±ï¸ ç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"))
        return {
            "generated_json": generated_json,
            "messages": messages,
            "validation_errors": ["timeout"]  # æ ‡è®°ä¸ºè¶…æ—¶é”™è¯¯
        }
    except Exception as e:
        # å…¶ä»–é”™è¯¯ï¼ˆç½‘ç»œé”™è¯¯ã€APIé”™è¯¯ç­‰ï¼‰
        logger.error(f"âŒ DeepSeek API è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
        generated_json = ""
        messages.append(AIMessage(content=f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"))
        return {
            "generated_json": generated_json,
            "messages": messages,
            "validation_errors": [f"api_error: {str(e)}"]
        }

    return {
        "generated_json": generated_json,
        "messages": messages
    }


def validator_node(state: SkillGenerationState) -> Dict[str, Any]:
    """
    éªŒè¯ JSON èŠ‚ç‚¹

    éªŒè¯ç”Ÿæˆçš„ JSON æ˜¯å¦ç¬¦åˆ Odin Schema å’Œä¸šåŠ¡è§„åˆ™ã€‚
    ğŸ”¥ æ›´æ–°ï¼šæ”¯æŒtracksåµŒå¥—ç»“æ„éªŒè¯
    """
    from ..schemas import OdinSkillSchema  # ğŸ”¥ å¯¼å…¥ Schema
    from pydantic import ValidationError

    generated_json = state["generated_json"]
    logger.info("éªŒè¯ç”Ÿæˆçš„ JSON")

    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
    messages = []

    # æ·»åŠ å¼€å§‹éªŒè¯çš„æ¶ˆæ¯
    messages.append(AIMessage(content="ğŸ” æ­£åœ¨éªŒè¯æŠ€èƒ½é…ç½®çš„åˆæ³•æ€§..."))

    errors = []

    try:
        # ä» Markdown ä¸­æå– JSON
        json_content = extract_json_from_markdown(generated_json)
        logger.info(f"æå–çš„ JSON é•¿åº¦: {len(json_content)}")
        logger.debug(f"æå–çš„ JSON å†…å®¹é¢„è§ˆ: {json_content[:500]}...")  # åªè®°å½•å‰500å­—ç¬¦

        # ğŸ”¥ ä½¿ç”¨ Pydantic Schema éªŒè¯ï¼ˆPydantic V2 APIï¼‰
        try:
            skill_data = OdinSkillSchema.model_validate_json(json_content)
            logger.info("âœ… Pydantic Schema éªŒè¯é€šè¿‡")

            # ğŸ”¥ ä¸šåŠ¡è§„åˆ™éªŒè¯ï¼ˆè¶…å‡º Pydantic çš„é¢å¤–æ£€æŸ¥ï¼‰
            # 1. æ£€æŸ¥ totalDuration æ˜¯å¦è¦†ç›–æ‰€æœ‰ actions
            max_action_end_frame = 0
            for track in skill_data.tracks:
                for action in track.actions:
                    action_end = action.frame + action.duration
                    if action_end > max_action_end_frame:
                        max_action_end_frame = action_end

            if skill_data.totalDuration < max_action_end_frame:
                errors.append(
                    f"totalDuration ({skill_data.totalDuration}) å°äºæœ€å¤§actionç»“æŸå¸§ ({max_action_end_frame})"
                )

            # 2. æ£€æŸ¥æ¯ä¸ª action çš„ parameters æ˜¯å¦åŒ…å« _odin_type
            for track_idx, track in enumerate(skill_data.tracks):
                for action_idx, action in enumerate(track.actions):
                    if "_odin_type" not in action.parameters:
                        errors.append(
                            f"Track[{track_idx}].Action[{action_idx}] çš„ parameters ç¼ºå°‘ _odin_type å­—æ®µ"
                        )

        except ValidationError as e:
            # P2-3: Pydantic éªŒè¯å¤±è´¥ï¼Œæå–è¯¦ç»†é”™è¯¯ä¿¡æ¯
            for error in e.errors():
                field_path = " -> ".join(str(loc) for loc in error["loc"])
                error_msg = error["msg"]
                error_type = error.get("type", "unknown")
                # è·å–å®é™…å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
                input_value = error.get("input", None)
                input_preview = ""
                if input_value is not None:
                    input_str = str(input_value)
                    input_preview = f" (å®é™…å€¼: {input_str[:50]}{'...' if len(input_str) > 50 else ''})"
                # æ„å»ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
                detailed_error = f"{field_path}: {error_msg} [ç±»å‹: {error_type}]{input_preview}"
                errors.append(detailed_error)

    except json.JSONDecodeError as e:
        errors.append(f"JSON è§£æå¤±è´¥: {str(e)}")
    except Exception as e:
        errors.append(f"éªŒè¯å¼‚å¸¸: {str(e)}")

    if errors:
        logger.warning(f"éªŒè¯å¤±è´¥ï¼Œå‘ç° {len(errors)} ä¸ªé”™è¯¯")
        errors_list = "\n".join([f"â€¢ {err}" for err in errors])
        message = f"âš ï¸ **éªŒè¯å¤±è´¥**ï¼Œå‘ç° {len(errors)} ä¸ªé”™è¯¯ï¼š\n\n{errors_list}"
    else:
        logger.info("éªŒè¯é€šè¿‡")
        message = "âœ… **éªŒè¯é€šè¿‡ï¼** æŠ€èƒ½é…ç½®ç¬¦åˆè§„èŒƒã€‚"

    messages.append(AIMessage(content=message))

    return {
        "validation_errors": errors,
        "messages": messages
    }


def fixer_node(state: SkillGenerationState) -> Dict[str, Any]:
    """
    ä¿®å¤ JSON èŠ‚ç‚¹

    æ ¹æ®éªŒè¯é”™è¯¯ï¼Œä½¿ç”¨ LLM ä¿®å¤ JSONã€‚
    ğŸ”¥ ä½¿ç”¨ structured output + å¼ºåˆ¶è½¬æ¢ç¡®ä¿ä¿®å¤åç¬¦åˆ Schema
    """
    from ..prompts.prompt_manager import get_prompt_manager
    from ..schemas import OdinSkillSchema

    generated_json = state["generated_json"]
    errors = state["validation_errors"]

    logger.info(f"ä¿®å¤ JSONï¼Œé”™è¯¯æ•°: {len(errors)}")

    # æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯
    errors_text = "\n".join([f"{i+1}. {err}" for i, err in enumerate(errors)])

    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
    messages = []

    # æ·»åŠ å¼€å§‹ä¿®å¤çš„æ¶ˆæ¯
    messages.append(AIMessage(content=f"ğŸ” å‘ç° {len(errors)} ä¸ªé”™è¯¯ï¼Œæ­£åœ¨è°ƒç”¨ DeepSeek AI è¿›è¡Œä¿®å¤...\n\né”™è¯¯åˆ—è¡¨ï¼š\n{errors_text}"))

    # è·å– Prompt
    prompt_mgr = get_prompt_manager()
    prompt = prompt_mgr.get_prompt("validation_fix")

    # ğŸ”¥ è°ƒç”¨ LLM å¹¶å°è¯•ä½¿ç”¨ structured output
    llm = get_llm(temperature=0.3)  # ä¿®å¤æ—¶ä½¿ç”¨æ›´ä½æ¸©åº¦

    # å°è¯•åˆå§‹åŒ– structured LLM
    try:
        fixer_llm = llm.with_structured_output(
            OdinSkillSchema,
            method="json_mode",
            include_raw=False
        )
        logger.info("âœ… Fixer ä½¿ç”¨ structured output æ¨¡å¼")
    except Exception as e:
        logger.warning(f"âš ï¸ Fixer structured output ä¸å¯ç”¨ï¼Œä½¿ç”¨æ™®é€šæ¨¡å¼: {e}")
        fixer_llm = llm

    chain = prompt | fixer_llm

    # å‡†å¤‡ prompt è¾“å…¥
    prompt_inputs = {
        "errors": errors_text,
        "json": generated_json
    }

    # è°ƒç”¨ LLM
    response = chain.invoke(prompt_inputs)

    # ğŸ”¥ ä½¿ç”¨å¼ºåˆ¶è½¬æ¢ç¡®ä¿ä¿®å¤åçš„æ ¼å¼æ­£ç¡®
    normalized_skill = None
    try:
        normalized_skill = _enforce_odin_structure(
            response,
            "fixer_structured" if fixer_llm is not llm else "fixer_raw"
        )
        fixed_json = normalized_skill.model_dump_json(indent=2)
        logger.info("âœ… Fixer æˆåŠŸè½¬æ¢ä¸º OdinSkillSchema")

        # æ·»åŠ æˆåŠŸçš„æç¤º
        messages.append(AIMessage(
            content=f"ğŸ’¬ **DeepSeek å›åº”ï¼š**\n\nå·²é’ˆå¯¹ {len(errors)} ä¸ªé”™è¯¯è¿›è¡Œä¿®å¤ (å°è¯• {state['retry_count'] + 1}/{state['max_retries']})ã€‚"
        ))
        messages.append(AIMessage(
            content="âœ… **Schema éªŒè¯é€šè¿‡**ï¼šä¿®å¤åçš„é…ç½®ç¬¦åˆå®Œæ•´çš„ tracks/actions åµŒå¥—ç»“æ„"
        ))

    except Exception as e:
        # å¼ºåˆ¶è½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸå§‹å“åº”å†…å®¹
        logger.error(f"âŒ Fixer è§„èŒƒåŒ–å¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹: {e}", exc_info=True)
        fixed_json = _prepare_payload_text(response)

        # æ·»åŠ è­¦å‘Šæç¤º
        messages.append(AIMessage(
            content=f"ğŸ’¬ **DeepSeek å›åº”ï¼š**\n\nå·²å°è¯•ä¿®å¤ {len(errors)} ä¸ªé”™è¯¯ (å°è¯• {state['retry_count'] + 1}/{state['max_retries']})ã€‚"
        ))
        messages.append(AIMessage(
            content=f"âš ï¸ **Schema éªŒè¯è­¦å‘Š**ï¼šä¿®å¤åä»æ— æ³•å®Œå…¨ç¬¦åˆæ ¼å¼ï¼Œå°†ç»§ç»­é‡è¯•"
        ))

    # æ˜¾ç¤ºä¿®å¤åçš„JSONï¼ˆæˆªå–é¢„è§ˆï¼‰
    preview_json = fixed_json if len(fixed_json) <= 1000 else f"{fixed_json[:1000]}...\n(å·²æˆªæ–­ï¼Œå®Œæ•´å†…å®¹è§æœ€ç»ˆç»“æœ)"
    display_message = f"ğŸ”§ **å·²ä¿®å¤æŠ€èƒ½é…ç½®ï¼š**\n\n```json\n{preview_json}\n```"
    messages.append(AIMessage(content=display_message))

    return {
        "generated_json": fixed_json,
        "retry_count": state["retry_count"] + 1,
        "messages": messages
    }


def finalize_node(state: SkillGenerationState) -> Dict[str, Any]:
    """
    æœ€ç»ˆåŒ–èŠ‚ç‚¹

    å°†ç”Ÿæˆçš„ JSON è§£æä¸ºæœ€ç»ˆç»“æœã€‚
    """
    generated_json = state["generated_json"]

    try:
        # ä» Markdown ä¸­æå– JSON
        json_content = extract_json_from_markdown(generated_json)
        logger.info(f"æœ€ç»ˆåŒ–ï¼šæå–çš„ JSON é•¿åº¦: {len(json_content)}")

        final_result = json.loads(json_content)
        logger.info("æŠ€èƒ½ç”ŸæˆæˆåŠŸ")
    except json.JSONDecodeError as e:
        final_result = {
            "error": f"JSON è§£æå¤±è´¥: {str(e)}",
            "raw_json": generated_json
        }
        logger.error(f"æœ€ç»ˆ JSON è§£æå¤±è´¥: {e}")

    return {
        "final_result": final_result,
        "messages": [HumanMessage(content="æŠ€èƒ½ç”Ÿæˆå®Œæˆ")]
    }


# ==================== æ¡ä»¶åˆ¤æ–­å‡½æ•° ====================

def should_continue(state: SkillGenerationState) -> str:
    """
    åˆ¤æ–­æ˜¯å¦ç»§ç»­ä¿®å¤å¾ªç¯

    Returns:
        "fix" - ç»§ç»­ä¿®å¤
        "finalize" - ç»“æŸï¼Œè¿”å›ç»“æœ
    """
    errors = state.get("validation_errors", [])
    retry_count = state.get("retry_count", 0)
    max_retries = state.get("max_retries", 3)

    # å¦‚æœæ²¡æœ‰é”™è¯¯ï¼Œç»“æŸ
    if not errors:
        return "finalize"

    # å¦‚æœè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç»“æŸ
    if retry_count >= max_retries:
        logger.warning(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° {max_retries}ï¼Œåœæ­¢ä¿®å¤")
        return "finalize"

    # ç»§ç»­ä¿®å¤
    return "fix"
