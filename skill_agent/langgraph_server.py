"""
LangGraph HTTP æœåŠ¡å™¨
ä¸º agent-chat-ui æä¾›å…¼å®¹çš„ HTTP API æ¥å£
æ”¯æŒæŠ€èƒ½åˆ†æã€ç”Ÿæˆã€æœç´¢ç­‰åŠŸèƒ½
"""

import os
import sys
import logging
import asyncio
from typing import Dict, Any, List, Optional, AsyncIterator
from datetime import datetime
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from orchestration import (
    get_skill_generation_graph,
    get_skill_search_graph,
    get_skill_detail_graph,
)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ==================== æ•°æ®æ¨¡å‹ ====================

class Message(BaseModel):
    """æ¶ˆæ¯æ¨¡å‹ï¼ˆå…¼å®¹ LangGraph æ ‡å‡†ï¼‰"""
    role: str = Field(..., description="æ¶ˆæ¯è§’è‰²: human, ai, system")
    content: str = Field(..., description="æ¶ˆæ¯å†…å®¹")
    id: Optional[str] = Field(None, description="æ¶ˆæ¯ID")
    name: Optional[str] = Field(None, description="å‘é€è€…åç§°")


class ThreadState(BaseModel):
    """çº¿ç¨‹çŠ¶æ€æ¨¡å‹"""
    messages: List[Message] = Field(default_factory=list, description="å¯¹è¯å†å²")
    requirement: Optional[str] = Field(None, description="ç”¨æˆ·éœ€æ±‚")
    similar_skills: List[Dict[str, Any]] = Field(default_factory=list)
    generated_json: Optional[str] = Field(None)
    validation_errors: List[str] = Field(default_factory=list)
    retry_count: int = Field(0)
    max_retries: int = Field(3)
    final_result: Optional[Dict[str, Any]] = Field(None)


class StreamInput(BaseModel):
    """æµå¼è¾“å…¥æ¨¡å‹"""
    input: Dict[str, Any] = Field(..., description="è¾“å…¥æ•°æ®")
    config: Optional[Dict[str, Any]] = Field(default_factory=dict)
    stream_mode: str = Field("values", description="æµå¼æ¨¡å¼")


class RunsStreamRequest(BaseModel):
    """è¿è¡Œæµè¯·æ±‚ï¼ˆå…¼å®¹ LangGraph APIï¼‰"""
    input: Dict[str, Any]
    config: Optional[Dict[str, Any]] = None
    stream_mode: Optional[List[str]] = ["values"]
    assistant_id: Optional[str] = None


# ==================== åº”ç”¨ç”Ÿå‘½å‘¨æœŸ ====================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ LangGraph Server starting...")
    
    # é¢„åŠ è½½å›¾
    try:
        get_skill_generation_graph()
        get_skill_search_graph()
        get_skill_detail_graph()
        logger.info("âœ… All graphs loaded successfully")
    except Exception as e:
        logger.error(f"âŒ Failed to load graphs: {e}")
    
    yield
    
    logger.info("ğŸ›‘ LangGraph Server shutting down...")


# ==================== FastAPI åº”ç”¨ ====================

app = FastAPI(
    title="SkillRAG LangGraph Server",
    description="æŠ€èƒ½åˆ†æä¸ç”Ÿæˆçš„ LangGraph æœåŠ¡å™¨",
    version="1.0.0",
    lifespan=lifespan
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ==================== è¾…åŠ©å‡½æ•° ====================

def convert_to_langgraph_messages(messages: List[Message]) -> List[Dict[str, Any]]:
    """å°†æ¶ˆæ¯è½¬æ¢ä¸º LangGraph æ ¼å¼"""
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    
    result = []
    for msg in messages:
        if msg.role == "human":
            result.append(HumanMessage(content=msg.content))
        elif msg.role == "ai":
            result.append(AIMessage(content=msg.content))
        elif msg.role == "system":
            result.append(SystemMessage(content=msg.content))
    return result


def convert_from_langgraph_messages(messages: List[Any]) -> List[Dict[str, str]]:
    """å°† LangGraph æ¶ˆæ¯è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
    result = []
    for msg in messages:
        msg_type = msg.__class__.__name__.lower()
        role = "human" if "human" in msg_type else "ai" if "ai" in msg_type else "system"
        result.append({
            "role": role,
            "content": msg.content,
            "id": getattr(msg, "id", None)
        })
    return result


async def stream_graph_updates(
    graph,
    initial_state: Dict[str, Any]
) -> AsyncIterator[str]:
    """
    æµå¼è¾“å‡ºå›¾çš„æ›´æ–°
    
    Args:
        graph: LangGraph å›¾å®ä¾‹
        initial_state: åˆå§‹çŠ¶æ€
        
    Yields:
        SSE æ ¼å¼çš„äº‹ä»¶æ•°æ®
    """
    try:
        # ä½¿ç”¨ astream è¿›è¡Œæµå¼å¤„ç†
        async for event in graph.astream(initial_state):
            # æ ¼å¼åŒ–ä¸º SSE äº‹ä»¶
            event_data = {
                "event": "values",
                "data": event
            }
            
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼
            if "messages" in event:
                event_data["data"]["messages"] = convert_from_langgraph_messages(
                    event["messages"]
                )
            
            # å‘é€äº‹ä»¶
            yield f"data: {str(event_data)}\n\n"
            
            # æ·»åŠ å°å»¶è¿Ÿä»¥ç¡®ä¿æµå¼ä¼ è¾“
            await asyncio.sleep(0.01)
        
        # å‘é€ç»“æŸäº‹ä»¶
        yield f"data: {str({'event': 'end'})}\n\n"
        
    except Exception as e:
        logger.error(f"Stream error: {e}", exc_info=True)
        error_event = {
            "event": "error",
            "data": {"error": str(e)}
        }
        yield f"data: {str(error_event)}\n\n"


# ==================== API ç«¯ç‚¹ ====================

@app.get("/")
async def root():
    """æ ¹ç«¯ç‚¹"""
    return {
        "service": "SkillRAG LangGraph Server",
        "version": "1.0.0",
        "status": "running",
        "timestamp": datetime.now().isoformat(),
        "endpoints": {
            "threads": "/threads/{thread_id}/runs/stream",
            "assistants": "/assistants",
            "health": "/health"
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }


@app.get("/assistants")
async def list_assistants():
    """åˆ—å‡ºå¯ç”¨çš„åŠ©æ‰‹ï¼ˆå›¾ï¼‰"""
    return {
        "assistants": [
            {
                "assistant_id": "skill-generation",
                "name": "æŠ€èƒ½ç”ŸæˆåŠ©æ‰‹",
                "description": "æ ¹æ®éœ€æ±‚æè¿°ç”ŸæˆæŠ€èƒ½é…ç½®JSON",
                "graph_id": "skill_generation"
            },
            {
                "assistant_id": "skill-search",
                "name": "æŠ€èƒ½æœç´¢åŠ©æ‰‹",
                "description": "è¯­ä¹‰æœç´¢æŠ€èƒ½åº“",
                "graph_id": "skill_search"
            },
            {
                "assistant_id": "skill-detail",
                "name": "æŠ€èƒ½è¯¦æƒ…åŠ©æ‰‹",
                "description": "æŸ¥è¯¢æŠ€èƒ½è¯¦ç»†ä¿¡æ¯",
                "graph_id": "skill_detail"
            }
        ]
    }


@app.post("/threads/{thread_id}/runs/stream")
async def create_run_stream(
    thread_id: str,
    request: RunsStreamRequest
):
    """
    åˆ›å»ºæµå¼è¿è¡Œï¼ˆå…¼å®¹ agent-chat-uiï¼‰
    
    è¿™æ˜¯ agent-chat-ui è°ƒç”¨çš„ä¸»è¦ç«¯ç‚¹
    """
    try:
        logger.info(f"Stream request for thread {thread_id}: {request.input}")
        
        # è·å–åŠ©æ‰‹IDï¼ˆé»˜è®¤ä½¿ç”¨æŠ€èƒ½ç”Ÿæˆï¼‰
        assistant_id = request.assistant_id or request.config.get("configurable", {}).get("assistant_id", "skill-generation")
        
        # æ ¹æ®åŠ©æ‰‹IDé€‰æ‹©å›¾
        if assistant_id == "skill-generation":
            graph = get_skill_generation_graph()
        elif assistant_id == "skill-search":
            graph = get_skill_search_graph()
        elif assistant_id == "skill-detail":
            graph = get_skill_detail_graph()
        else:
            raise HTTPException(status_code=404, detail=f"Assistant '{assistant_id}' not found")
        
        # å‡†å¤‡åˆå§‹çŠ¶æ€
        input_data = request.input
        
        # ä» messages ä¸­æå–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯ä½œä¸ºéœ€æ±‚
        messages = input_data.get("messages", [])
        if messages:
            last_message = messages[-1]
            requirement = last_message.get("content", "")
        else:
            requirement = input_data.get("requirement", "")
        
        # æ„å»ºåˆå§‹çŠ¶æ€
        initial_state = {
            "requirement": requirement,
            "similar_skills": [],
            "generated_json": "",
            "validation_errors": [],
            "retry_count": 0,
            "max_retries": 3,
            "final_result": {},
            "messages": convert_to_langgraph_messages([Message(**msg) for msg in messages]) if messages else [],
        }
        
        # è¿”å›æµå¼å“åº”
        return StreamingResponse(
            stream_graph_updates(graph, initial_state),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
        
    except Exception as e:
        logger.error(f"Error in stream endpoint: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/threads/{thread_id}/runs")
async def create_run(
    thread_id: str,
    request: RunsStreamRequest
):
    """
    åˆ›å»ºéæµå¼è¿è¡Œ
    """
    try:
        logger.info(f"Run request for thread {thread_id}: {request.input}")
        
        # è·å–åŠ©æ‰‹ID
        assistant_id = request.assistant_id or request.config.get("configurable", {}).get("assistant_id", "skill-generation")
        
        # æ ¹æ®åŠ©æ‰‹IDé€‰æ‹©å›¾
        if assistant_id == "skill-generation":
            graph = get_skill_generation_graph()
        elif assistant_id == "skill-search":
            graph = get_skill_search_graph()
        elif assistant_id == "skill-detail":
            graph = get_skill_detail_graph()
        else:
            raise HTTPException(status_code=404, detail=f"Assistant '{assistant_id}' not found")
        
        # å‡†å¤‡åˆå§‹çŠ¶æ€
        input_data = request.input
        messages = input_data.get("messages", [])
        
        if messages:
            last_message = messages[-1]
            requirement = last_message.get("content", "")
        else:
            requirement = input_data.get("requirement", "")
        
        initial_state = {
            "requirement": requirement,
            "similar_skills": [],
            "generated_json": "",
            "validation_errors": [],
            "retry_count": 0,
            "max_retries": 3,
            "final_result": {},
            "messages": convert_to_langgraph_messages([Message(**msg) for msg in messages]) if messages else [],
        }
        
        # æ‰§è¡Œå›¾
        result = await graph.ainvoke(initial_state)
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        result["messages"] = convert_from_langgraph_messages(result.get("messages", []))
        
        return {
            "thread_id": thread_id,
            "run_id": f"run_{datetime.now().timestamp()}",
            "status": "completed",
            "result": result
        }
        
    except Exception as e:
        logger.error(f"Error in run endpoint: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/threads/{thread_id}")
async def get_thread(thread_id: str):
    """è·å–çº¿ç¨‹ä¿¡æ¯"""
    return {
        "thread_id": thread_id,
        "created_at": datetime.now().isoformat(),
        "metadata": {}
    }


# ==================== ä¸»å‡½æ•° ====================

def main():
    """å¯åŠ¨æœåŠ¡å™¨"""
    host = os.getenv("LANGGRAPH_HOST", "0.0.0.0")
    port = int(os.getenv("LANGGRAPH_PORT", "2024"))
    
    logger.info(f"Starting LangGraph server on {host}:{port}")
    
    uvicorn.run(
        app,
        host=host,
        port=port,
        log_level="info"
    )


if __name__ == "__main__":
    main()
