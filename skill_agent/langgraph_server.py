"""
LangGraph HTTP æœåŠ¡å™¨
ä¸º agent-chat-ui æä¾›å…¼å®¹çš„ HTTP API æ¥å£
æ”¯æŒæŠ€èƒ½åˆ†æã€ç”Ÿæˆã€æœç´¢ç­‰åŠŸèƒ½
"""

import os
import sys
import logging
import asyncio
from typing import Dict, Any, List, Optional, AsyncIterator
from datetime import datetime
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from orchestration import (
    get_skill_generation_graph,
    get_skill_search_graph,
    get_skill_detail_graph,
)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ==================== æ•°æ®æ¨¡å‹ ====================

class Message(BaseModel):
    """æ¶ˆæ¯æ¨¡å‹ï¼ˆå…¼å®¹ LangGraph æ ‡å‡†ï¼‰"""
    role: str = Field(..., description="æ¶ˆæ¯è§’è‰²: human, ai, system")
    content: str = Field(..., description="æ¶ˆæ¯å†…å®¹")
    id: Optional[str] = Field(None, description="æ¶ˆæ¯ID")
    name: Optional[str] = Field(None, description="å‘é€è€…åç§°")


class ThreadState(BaseModel):
    """çº¿ç¨‹çŠ¶æ€æ¨¡å‹"""
    messages: List[Message] = Field(default_factory=list, description="å¯¹è¯å†å²")
    requirement: Optional[str] = Field(None, description="ç”¨æˆ·éœ€æ±‚")
    similar_skills: List[Dict[str, Any]] = Field(default_factory=list)
    generated_json: Optional[str] = Field(None)
    validation_errors: List[str] = Field(default_factory=list)
    retry_count: int = Field(0)
    max_retries: int = Field(3)
    final_result: Optional[Dict[str, Any]] = Field(None)


class StreamInput(BaseModel):
    """æµå¼è¾“å…¥æ¨¡å‹"""
    input: Dict[str, Any] = Field(..., description="è¾“å…¥æ•°æ®")
    config: Optional[Dict[str, Any]] = Field(default_factory=dict)
    stream_mode: str = Field("values", description="æµå¼æ¨¡å¼")


class RunsStreamRequest(BaseModel):
    """è¿è¡Œæµè¯·æ±‚ï¼ˆå…¼å®¹ LangGraph APIï¼‰"""
    input: Dict[str, Any]
    config: Optional[Dict[str, Any]] = None
    stream_mode: Optional[List[str]] = ["values"]
    assistant_id: Optional[str] = None


# ==================== åº”ç”¨ç”Ÿå‘½å‘¨æœŸ ====================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ğŸš€ LangGraph Server starting...")
    
    # é¢„åŠ è½½å›¾
    try:
        get_skill_generation_graph()
        get_skill_search_graph()
        get_skill_detail_graph()
        logger.info("âœ… All graphs loaded successfully")
    except Exception as e:
        logger.error(f"âŒ Failed to load graphs: {e}")
    
    yield
    
    logger.info("ğŸ›‘ LangGraph Server shutting down...")


# ==================== FastAPI åº”ç”¨ ====================

app = FastAPI(
    title="SkillRAG LangGraph Server",
    description="æŠ€èƒ½åˆ†æä¸ç”Ÿæˆçš„ LangGraph æœåŠ¡å™¨",
    version="1.0.0",
    lifespan=lifespan
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ==================== è¾…åŠ©å‡½æ•° ====================

def convert_to_langgraph_messages(messages: List[Message]) -> List[Dict[str, Any]]:
    """å°†æ¶ˆæ¯è½¬æ¢ä¸º LangGraph æ ¼å¼"""
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    
    result = []
    for msg in messages:
        if msg.role == "human":
            result.append(HumanMessage(content=msg.content))
        elif msg.role == "ai":
            result.append(AIMessage(content=msg.content))
        elif msg.role == "system":
            result.append(SystemMessage(content=msg.content))
    return result


def convert_from_langgraph_messages(messages: List[Any]) -> List[Dict[str, str]]:
    """å°† LangGraph æ¶ˆæ¯è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
    result = []
    for msg in messages:
        msg_type = msg.__class__.__name__.lower()
        role = "human" if "human" in msg_type else "ai" if "ai" in msg_type else "system"
        result.append({
            "role": role,
            "content": msg.content,
            "id": getattr(msg, "id", None)
        })
    return result


async def stream_graph_updates(
    graph,
    initial_state: Dict[str, Any]
) -> AsyncIterator[str]:
    """
    æµå¼è¾“å‡ºå›¾çš„æ›´æ–°
    
    Args:
        graph: LangGraph å›¾å®ä¾‹
        initial_state: åˆå§‹çŠ¶æ€
        
    Yields:
        SSE æ ¼å¼çš„äº‹ä»¶æ•°æ®
    """
    try:
        # ä½¿ç”¨ astream è¿›è¡Œæµå¼å¤„ç†
        async for event in graph.astream(initial_state):
            # æ ¼å¼åŒ–ä¸º SSE äº‹ä»¶
            event_data = {
                "event": "values",
                "data": event
            }
            
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼
            if "messages" in event:
                event_data["data"]["messages"] = convert_from_langgraph_messages(
                    event["messages"]
                )
            
            # å‘é€äº‹ä»¶
            yield f"data: {str(event_data)}\n\n"
            
            # æ·»åŠ å°å»¶è¿Ÿä»¥ç¡®ä¿æµå¼ä¼ è¾“
            await asyncio.sleep(0.01)
        
        # å‘é€ç»“æŸäº‹ä»¶
        yield f"data: {str({'event': 'end'})}\n\n"
        
    except Exception as e:
        logger.error(f"Stream error: {e}", exc_info=True)
        error_event = {
            "event": "error",
            "data": {"error": str(e)}
        }
        yield f"data: {str(error_event)}\n\n"


# ==================== API ç«¯ç‚¹ ====================

@app.get("/")
async def root():
    """æ ¹ç«¯ç‚¹"""
    return {
        "service": "SkillRAG LangGraph Server",
        "version": "1.0.0",
        "status": "running",
        "timestamp": datetime.now().isoformat(),
        "endpoints": {
            "threads": "/threads/{thread_id}/runs/stream",
            "assistants": "/assistants",
            "health": "/health",
            "rag": {
                "search": "/rag/search",
                "recommend_actions": "/rag/recommend-actions",
                "recommend_parameters": "/rag/recommend-parameters",
                "rebuild_index": "/rag/index/rebuild",
                "stats": "/rag/index/stats",
                "clear_cache": "/rag/cache",
                "health": "/rag/health"
            }
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }


@app.get("/assistants")
async def list_assistants():
    """åˆ—å‡ºå¯ç”¨çš„åŠ©æ‰‹ï¼ˆå›¾ï¼‰"""
    return {
        "assistants": [
            {
                "assistant_id": "skill-generation",
                "name": "æŠ€èƒ½ç”ŸæˆåŠ©æ‰‹",
                "description": "æ ¹æ®éœ€æ±‚æè¿°ç”ŸæˆæŠ€èƒ½é…ç½®JSON",
                "graph_id": "skill_generation"
            },
            {
                "assistant_id": "skill-search",
                "name": "æŠ€èƒ½æœç´¢åŠ©æ‰‹",
                "description": "è¯­ä¹‰æœç´¢æŠ€èƒ½åº“",
                "graph_id": "skill_search"
            },
            {
                "assistant_id": "skill-detail",
                "name": "æŠ€èƒ½è¯¦æƒ…åŠ©æ‰‹",
                "description": "æŸ¥è¯¢æŠ€èƒ½è¯¦ç»†ä¿¡æ¯",
                "graph_id": "skill_detail"
            }
        ]
    }


@app.post("/threads/{thread_id}/runs/stream")
async def create_run_stream(
    thread_id: str,
    request: RunsStreamRequest
):
    """
    åˆ›å»ºæµå¼è¿è¡Œï¼ˆå…¼å®¹ agent-chat-uiï¼‰
    
    è¿™æ˜¯ agent-chat-ui è°ƒç”¨çš„ä¸»è¦ç«¯ç‚¹
    """
    try:
        logger.info(f"Stream request for thread {thread_id}: {request.input}")
        
        # è·å–åŠ©æ‰‹IDï¼ˆé»˜è®¤ä½¿ç”¨æŠ€èƒ½ç”Ÿæˆï¼‰
        assistant_id = request.assistant_id or request.config.get("configurable", {}).get("assistant_id", "skill-generation")
        
        # æ ¹æ®åŠ©æ‰‹IDé€‰æ‹©å›¾
        if assistant_id == "skill-generation":
            graph = get_skill_generation_graph()
        elif assistant_id == "skill-search":
            graph = get_skill_search_graph()
        elif assistant_id == "skill-detail":
            graph = get_skill_detail_graph()
        else:
            raise HTTPException(status_code=404, detail=f"Assistant '{assistant_id}' not found")
        
        # å‡†å¤‡åˆå§‹çŠ¶æ€
        input_data = request.input
        
        # ä» messages ä¸­æå–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯ä½œä¸ºéœ€æ±‚
        messages = input_data.get("messages", [])
        if messages:
            last_message = messages[-1]
            requirement = last_message.get("content", "")
        else:
            requirement = input_data.get("requirement", "")
        
        # æ„å»ºåˆå§‹çŠ¶æ€
        initial_state = {
            "requirement": requirement,
            "similar_skills": [],
            "generated_json": "",
            "validation_errors": [],
            "retry_count": 0,
            "max_retries": 3,
            "final_result": {},
            "messages": convert_to_langgraph_messages([Message(**msg) for msg in messages]) if messages else [],
        }
        
        # è¿”å›æµå¼å“åº”
        return StreamingResponse(
            stream_graph_updates(graph, initial_state),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
        
    except Exception as e:
        logger.error(f"Error in stream endpoint: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/threads/{thread_id}/runs")
async def create_run(
    thread_id: str,
    request: RunsStreamRequest
):
    """
    åˆ›å»ºéæµå¼è¿è¡Œ
    """
    try:
        logger.info(f"Run request for thread {thread_id}: {request.input}")
        
        # è·å–åŠ©æ‰‹ID
        assistant_id = request.assistant_id or request.config.get("configurable", {}).get("assistant_id", "skill-generation")
        
        # æ ¹æ®åŠ©æ‰‹IDé€‰æ‹©å›¾
        if assistant_id == "skill-generation":
            graph = get_skill_generation_graph()
        elif assistant_id == "skill-search":
            graph = get_skill_search_graph()
        elif assistant_id == "skill-detail":
            graph = get_skill_detail_graph()
        else:
            raise HTTPException(status_code=404, detail=f"Assistant '{assistant_id}' not found")
        
        # å‡†å¤‡åˆå§‹çŠ¶æ€
        input_data = request.input
        messages = input_data.get("messages", [])
        
        if messages:
            last_message = messages[-1]
            requirement = last_message.get("content", "")
        else:
            requirement = input_data.get("requirement", "")
        
        initial_state = {
            "requirement": requirement,
            "similar_skills": [],
            "generated_json": "",
            "validation_errors": [],
            "retry_count": 0,
            "max_retries": 3,
            "final_result": {},
            "messages": convert_to_langgraph_messages([Message(**msg) for msg in messages]) if messages else [],
        }
        
        # æ‰§è¡Œå›¾
        result = await graph.ainvoke(initial_state)
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        result["messages"] = convert_from_langgraph_messages(result.get("messages", []))
        
        return {
            "thread_id": thread_id,
            "run_id": f"run_{datetime.now().timestamp()}",
            "status": "completed",
            "result": result
        }
        
    except Exception as e:
        logger.error(f"Error in run endpoint: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/threads/{thread_id}")
async def get_thread(thread_id: str):
    """è·å–çº¿ç¨‹ä¿¡æ¯"""
    return {
        "thread_id": thread_id,
        "created_at": datetime.now().isoformat(),
        "metadata": {}
    }


# ==================== RAG ä¸“ç”¨ç«¯ç‚¹ ====================

class RAGSearchRequest(BaseModel):
    """RAGæœç´¢è¯·æ±‚"""
    query: str = Field(..., description="æœç´¢æŸ¥è¯¢æ–‡æœ¬")
    top_k: int = Field(5, description="è¿”å›ç»“æœæ•°é‡")
    filters: Optional[Dict[str, Any]] = Field(None, description="è¿‡æ»¤æ¡ä»¶")


class RAGActionRecommendRequest(BaseModel):
    """Actionæ¨èè¯·æ±‚"""
    context: str = Field(..., description="ä¸Šä¸‹æ–‡æè¿°")
    top_k: int = Field(3, description="æ¨èæ•°é‡")


class RAGParameterRecommendRequest(BaseModel):
    """å‚æ•°æ¨èè¯·æ±‚"""
    action_type: str = Field(..., description="Actionç±»å‹åç§°")
    skill_context: Optional[str] = Field(None, description="æŠ€èƒ½ä¸Šä¸‹æ–‡")
    parameter_name: Optional[str] = Field(None, description="å‚æ•°åç§°")


@app.post("/rag/search")
async def rag_search(request: RAGSearchRequest):
    """
    æŠ€èƒ½è¯­ä¹‰æœç´¢

    æ ¹æ®è‡ªç„¶è¯­è¨€æŸ¥è¯¢æœç´¢ç›¸ä¼¼çš„æŠ€èƒ½é…ç½®
    """
    try:
        from orchestration.tools.rag_tools import get_rag_engine

        logger.info(f"RAG search: query='{request.query}', top_k={request.top_k}")

        engine = get_rag_engine()
        results = engine.search_skills(
            query=request.query,
            top_k=request.top_k,
            filters=request.filters,
            return_details=True
        )

        return {
            "success": True,
            "query": request.query,
            "results": results,
            "count": len(results)
        }

    except Exception as e:
        logger.error(f"RAG search error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/rag/recommend-actions")
async def rag_recommend_actions(request: RAGActionRecommendRequest):
    """
    Actionç±»å‹æ™ºèƒ½æ¨è

    æ ¹æ®ä¸Šä¸‹æ–‡æè¿°æ¨èåˆé€‚çš„Actionç±»å‹
    """
    try:
        from orchestration.tools.rag_tools import get_rag_engine

        logger.info(f"Action recommendation: context='{request.context}'")

        engine = get_rag_engine()
        recommendations = engine.recommend_actions(
            context=request.context,
            top_k=request.top_k
        )

        return {
            "success": True,
            "context": request.context,
            "recommendations": recommendations,
            "count": len(recommendations)
        }

    except Exception as e:
        logger.error(f"Action recommendation error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/rag/recommend-parameters")
async def rag_recommend_parameters(request: RAGParameterRecommendRequest):
    """
    å‚æ•°æ™ºèƒ½æ¨èï¼ˆåŸUnity InspectoråŠŸèƒ½ï¼‰

    ä¸ºæŒ‡å®šActionç±»å‹æ¨èåˆé€‚çš„å‚æ•°é…ç½®
    """
    try:
        from orchestration.tools.rag_tools import get_rag_engine

        logger.info(f"Parameter recommendation: action_type='{request.action_type}'")

        engine = get_rag_engine()

        # æœç´¢åŒ…å«è¯¥Actionç±»å‹çš„æŠ€èƒ½
        action_search_results = engine.search_actions(
            query=request.action_type,
            top_k=5
        )

        # æå–å‚æ•°ç¤ºä¾‹
        parameter_examples = []
        for result in action_search_results:
            if 'action_data' in result:
                action_data = result['action_data']
                if 'parameters' in action_data:
                    parameter_examples.append({
                        "action_type": result.get('actionType', request.action_type),
                        "parameters": action_data['parameters'],
                        "source_skill": result.get('skill_name', 'Unknown'),
                        "similarity": result.get('similarity', 0.0)
                    })

        return {
            "success": True,
            "action_type": request.action_type,
            "parameter_examples": parameter_examples,
            "count": len(parameter_examples)
        }

    except Exception as e:
        logger.error(f"Parameter recommendation error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/rag/index/rebuild")
async def rag_rebuild_index():
    """
    é‡å»ºRAGç´¢å¼•

    é‡æ–°ç´¢å¼•æ‰€æœ‰æŠ€èƒ½é…ç½®æ–‡ä»¶
    """
    try:
        from orchestration.tools.rag_tools import get_rag_engine

        logger.info("Rebuilding RAG index...")

        engine = get_rag_engine()

        # é‡å»ºæŠ€èƒ½ç´¢å¼•
        skill_result = engine.index_skills(force_rebuild=True)

        # é‡å»ºActionç´¢å¼•
        action_result = engine.index_actions(force_rebuild=True)

        # é‡å»ºç»“æ„åŒ–ç´¢å¼•
        structured_result = engine.rebuild_structured_index(force=True)

        return {
            "success": True,
            "skill_index": skill_result,
            "action_index": action_result,
            "structured_index": structured_result,
            "timestamp": datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"Index rebuild error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/rag/index/stats")
async def rag_index_stats():
    """
    è·å–RAGç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        from orchestration.tools.rag_tools import get_rag_engine
        import os

        engine = get_rag_engine()
        stats = engine.get_statistics()

        # æå–å…³é”®ç»Ÿè®¡æ•°æ®
        vector_stats = stats.get('vector_store', {})
        action_stats = stats.get('action_stats', {})

        # è®¡ç®—ç´¢å¼•å¤§å°ï¼ˆä¼°ç®—ï¼‰
        persist_dir = vector_stats.get('persist_directory', '')
        index_size_mb = 0.0
        if persist_dir and os.path.exists(persist_dir):
            total_size = 0
            for dirpath, dirnames, filenames in os.walk(persist_dir):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    if os.path.exists(filepath):
                        total_size += os.path.getsize(filepath)
            index_size_mb = total_size / (1024 * 1024)  # è½¬æ¢ä¸º MB

        # è¿”å›å‰ç«¯æœŸæœ›çš„æ ¼å¼
        return {
            "total_skills": vector_stats.get('total_documents', 0),
            "total_actions": action_stats.get('total_actions', 0),
            "total_parameters": int(action_stats.get('avg_params_per_action', 0) * action_stats.get('total_actions', 0)),
            "index_size_mb": round(index_size_mb, 2)
        }

    except Exception as e:
        logger.error(f"Stats retrieval error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/rag/cache")
async def rag_clear_cache():
    """
    æ¸…ç©ºRAGæŸ¥è¯¢ç¼“å­˜
    """
    try:
        from orchestration.tools.rag_tools import get_rag_engine

        engine = get_rag_engine()

        # æ¸…ç©ºæŸ¥è¯¢ç¼“å­˜
        if hasattr(engine, '_query_cache') and engine._query_cache is not None:
            cache_size = len(engine._query_cache)
            engine._query_cache.clear()
            logger.info(f"Cleared {cache_size} cached queries")
        else:
            cache_size = 0
            logger.info("Query cache is disabled or empty")

        return {
            "success": True,
            "cleared_entries": cache_size,
            "timestamp": datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"Cache clear error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/rag/health")
async def rag_health_check():
    """
    RAGæœåŠ¡å¥åº·æ£€æŸ¥

    ä¸ webui/src/app/rag/page.tsx HealthStatus æ¥å£å¯¹æ¥
    """
    try:
        from orchestration.tools.rag_tools import get_rag_engine

        engine = get_rag_engine()
        stats = engine.get_statistics()

        # æå–åµŒå¥—ç»Ÿè®¡æ•°æ®
        vector_stats = stats.get('vector_store', {})
        action_stats = stats.get('action_stats', {})

        return {
            "status": "healthy",
            "skill_count": vector_stats.get('total_documents', 0),
            "action_count": action_stats.get('total_actions', 0),
            "last_updated": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

    except Exception as e:
        logger.warning(f"RAG health check failed: {e}")
        return {
            "status": "unhealthy",
            "skill_count": 0,
            "action_count": 0,
            "last_updated": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }


# ==================== ä¸»å‡½æ•° ====================

def main():
    """å¯åŠ¨æœåŠ¡å™¨"""
    host = os.getenv("LANGGRAPH_HOST", "0.0.0.0")
    port = int(os.getenv("LANGGRAPH_PORT", "2024"))

    logger.info(f"Starting LangGraph server on {host}:{port}")

    uvicorn.run(
        app,
        host=host,
        port=port,
        log_level="info"
    )


if __name__ == "__main__":
    main()
